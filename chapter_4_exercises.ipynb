{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viny2030/NLP/blob/main/chapter_4_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOfolHBlnq3f"
      },
      "source": [
        "**Exercise 1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXrDCIjMnq3h",
        "outputId": "b432cce1-b32e-482b-eaba-3911028f9f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class str in module builtins:\n",
            "\n",
            "class str(object)\n",
            " |  str(object='') -> str\n",
            " |  str(bytes_or_buffer[, encoding[, errors]]) -> str\n",
            " |  \n",
            " |  Create a new string object from the given object. If encoding or\n",
            " |  errors is specified, then the object must expose a data buffer\n",
            " |  that will be decoded using the given encoding and error handler.\n",
            " |  Otherwise, returns the result of object.__str__() (if defined)\n",
            " |  or repr(object).\n",
            " |  encoding defaults to sys.getdefaultencoding().\n",
            " |  errors defaults to 'strict'.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __add__(self, value, /)\n",
            " |      Return self+value.\n",
            " |  \n",
            " |  __contains__(self, key, /)\n",
            " |      Return key in self.\n",
            " |  \n",
            " |  __eq__(self, value, /)\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __format__(self, format_spec, /)\n",
            " |      Return a formatted version of the string as described by format_spec.\n",
            " |  \n",
            " |  __ge__(self, value, /)\n",
            " |      Return self>=value.\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __getitem__(self, key, /)\n",
            " |      Return self[key].\n",
            " |  \n",
            " |  __getnewargs__(...)\n",
            " |  \n",
            " |  __gt__(self, value, /)\n",
            " |      Return self>value.\n",
            " |  \n",
            " |  __hash__(self, /)\n",
            " |      Return hash(self).\n",
            " |  \n",
            " |  __iter__(self, /)\n",
            " |      Implement iter(self).\n",
            " |  \n",
            " |  __le__(self, value, /)\n",
            " |      Return self<=value.\n",
            " |  \n",
            " |  __len__(self, /)\n",
            " |      Return len(self).\n",
            " |  \n",
            " |  __lt__(self, value, /)\n",
            " |      Return self<value.\n",
            " |  \n",
            " |  __mod__(self, value, /)\n",
            " |      Return self%value.\n",
            " |  \n",
            " |  __mul__(self, value, /)\n",
            " |      Return self*value.\n",
            " |  \n",
            " |  __ne__(self, value, /)\n",
            " |      Return self!=value.\n",
            " |  \n",
            " |  __repr__(self, /)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __rmod__(self, value, /)\n",
            " |      Return value%self.\n",
            " |  \n",
            " |  __rmul__(self, value, /)\n",
            " |      Return value*self.\n",
            " |  \n",
            " |  __sizeof__(self, /)\n",
            " |      Return the size of the string in memory, in bytes.\n",
            " |  \n",
            " |  __str__(self, /)\n",
            " |      Return str(self).\n",
            " |  \n",
            " |  capitalize(self, /)\n",
            " |      Return a capitalized version of the string.\n",
            " |      \n",
            " |      More specifically, make the first character have upper case and the rest lower\n",
            " |      case.\n",
            " |  \n",
            " |  casefold(self, /)\n",
            " |      Return a version of the string suitable for caseless comparisons.\n",
            " |  \n",
            " |  center(self, width, fillchar=' ', /)\n",
            " |      Return a centered string of length width.\n",
            " |      \n",
            " |      Padding is done using the specified fill character (default is a space).\n",
            " |  \n",
            " |  count(...)\n",
            " |      S.count(sub[, start[, end]]) -> int\n",
            " |      \n",
            " |      Return the number of non-overlapping occurrences of substring sub in\n",
            " |      string S[start:end].  Optional arguments start and end are\n",
            " |      interpreted as in slice notation.\n",
            " |  \n",
            " |  encode(self, /, encoding='utf-8', errors='strict')\n",
            " |      Encode the string using the codec registered for encoding.\n",
            " |      \n",
            " |      encoding\n",
            " |        The encoding in which to encode the string.\n",
            " |      errors\n",
            " |        The error handling scheme to use for encoding errors.\n",
            " |        The default is 'strict' meaning that encoding errors raise a\n",
            " |        UnicodeEncodeError.  Other possible values are 'ignore', 'replace' and\n",
            " |        'xmlcharrefreplace' as well as any other name registered with\n",
            " |        codecs.register_error that can handle UnicodeEncodeErrors.\n",
            " |  \n",
            " |  endswith(...)\n",
            " |      S.endswith(suffix[, start[, end]]) -> bool\n",
            " |      \n",
            " |      Return True if S ends with the specified suffix, False otherwise.\n",
            " |      With optional start, test S beginning at that position.\n",
            " |      With optional end, stop comparing S at that position.\n",
            " |      suffix can also be a tuple of strings to try.\n",
            " |  \n",
            " |  expandtabs(self, /, tabsize=8)\n",
            " |      Return a copy where all tab characters are expanded using spaces.\n",
            " |      \n",
            " |      If tabsize is not given, a tab size of 8 characters is assumed.\n",
            " |  \n",
            " |  find(...)\n",
            " |      S.find(sub[, start[, end]]) -> int\n",
            " |      \n",
            " |      Return the lowest index in S where substring sub is found,\n",
            " |      such that sub is contained within S[start:end].  Optional\n",
            " |      arguments start and end are interpreted as in slice notation.\n",
            " |      \n",
            " |      Return -1 on failure.\n",
            " |  \n",
            " |  format(...)\n",
            " |      S.format(*args, **kwargs) -> str\n",
            " |      \n",
            " |      Return a formatted version of S, using substitutions from args and kwargs.\n",
            " |      The substitutions are identified by braces ('{' and '}').\n",
            " |  \n",
            " |  format_map(...)\n",
            " |      S.format_map(mapping) -> str\n",
            " |      \n",
            " |      Return a formatted version of S, using substitutions from mapping.\n",
            " |      The substitutions are identified by braces ('{' and '}').\n",
            " |  \n",
            " |  index(...)\n",
            " |      S.index(sub[, start[, end]]) -> int\n",
            " |      \n",
            " |      Return the lowest index in S where substring sub is found,\n",
            " |      such that sub is contained within S[start:end].  Optional\n",
            " |      arguments start and end are interpreted as in slice notation.\n",
            " |      \n",
            " |      Raises ValueError when the substring is not found.\n",
            " |  \n",
            " |  isalnum(self, /)\n",
            " |      Return True if the string is an alpha-numeric string, False otherwise.\n",
            " |      \n",
            " |      A string is alpha-numeric if all characters in the string are alpha-numeric and\n",
            " |      there is at least one character in the string.\n",
            " |  \n",
            " |  isalpha(self, /)\n",
            " |      Return True if the string is an alphabetic string, False otherwise.\n",
            " |      \n",
            " |      A string is alphabetic if all characters in the string are alphabetic and there\n",
            " |      is at least one character in the string.\n",
            " |  \n",
            " |  isascii(self, /)\n",
            " |      Return True if all characters in the string are ASCII, False otherwise.\n",
            " |      \n",
            " |      ASCII characters have code points in the range U+0000-U+007F.\n",
            " |      Empty string is ASCII too.\n",
            " |  \n",
            " |  isdecimal(self, /)\n",
            " |      Return True if the string is a decimal string, False otherwise.\n",
            " |      \n",
            " |      A string is a decimal string if all characters in the string are decimal and\n",
            " |      there is at least one character in the string.\n",
            " |  \n",
            " |  isdigit(self, /)\n",
            " |      Return True if the string is a digit string, False otherwise.\n",
            " |      \n",
            " |      A string is a digit string if all characters in the string are digits and there\n",
            " |      is at least one character in the string.\n",
            " |  \n",
            " |  isidentifier(self, /)\n",
            " |      Return True if the string is a valid Python identifier, False otherwise.\n",
            " |      \n",
            " |      Call keyword.iskeyword(s) to test whether string s is a reserved identifier,\n",
            " |      such as \"def\" or \"class\".\n",
            " |  \n",
            " |  islower(self, /)\n",
            " |      Return True if the string is a lowercase string, False otherwise.\n",
            " |      \n",
            " |      A string is lowercase if all cased characters in the string are lowercase and\n",
            " |      there is at least one cased character in the string.\n",
            " |  \n",
            " |  isnumeric(self, /)\n",
            " |      Return True if the string is a numeric string, False otherwise.\n",
            " |      \n",
            " |      A string is numeric if all characters in the string are numeric and there is at\n",
            " |      least one character in the string.\n",
            " |  \n",
            " |  isprintable(self, /)\n",
            " |      Return True if the string is printable, False otherwise.\n",
            " |      \n",
            " |      A string is printable if all of its characters are considered printable in\n",
            " |      repr() or if it is empty.\n",
            " |  \n",
            " |  isspace(self, /)\n",
            " |      Return True if the string is a whitespace string, False otherwise.\n",
            " |      \n",
            " |      A string is whitespace if all characters in the string are whitespace and there\n",
            " |      is at least one character in the string.\n",
            " |  \n",
            " |  istitle(self, /)\n",
            " |      Return True if the string is a title-cased string, False otherwise.\n",
            " |      \n",
            " |      In a title-cased string, upper- and title-case characters may only\n",
            " |      follow uncased characters and lowercase characters only cased ones.\n",
            " |  \n",
            " |  isupper(self, /)\n",
            " |      Return True if the string is an uppercase string, False otherwise.\n",
            " |      \n",
            " |      A string is uppercase if all cased characters in the string are uppercase and\n",
            " |      there is at least one cased character in the string.\n",
            " |  \n",
            " |  join(self, iterable, /)\n",
            " |      Concatenate any number of strings.\n",
            " |      \n",
            " |      The string whose method is called is inserted in between each given string.\n",
            " |      The result is returned as a new string.\n",
            " |      \n",
            " |      Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'\n",
            " |  \n",
            " |  ljust(self, width, fillchar=' ', /)\n",
            " |      Return a left-justified string of length width.\n",
            " |      \n",
            " |      Padding is done using the specified fill character (default is a space).\n",
            " |  \n",
            " |  lower(self, /)\n",
            " |      Return a copy of the string converted to lowercase.\n",
            " |  \n",
            " |  lstrip(self, chars=None, /)\n",
            " |      Return a copy of the string with leading whitespace removed.\n",
            " |      \n",
            " |      If chars is given and not None, remove characters in chars instead.\n",
            " |  \n",
            " |  partition(self, sep, /)\n",
            " |      Partition the string into three parts using the given separator.\n",
            " |      \n",
            " |      This will search for the separator in the string.  If the separator is found,\n",
            " |      returns a 3-tuple containing the part before the separator, the separator\n",
            " |      itself, and the part after it.\n",
            " |      \n",
            " |      If the separator is not found, returns a 3-tuple containing the original string\n",
            " |      and two empty strings.\n",
            " |  \n",
            " |  removeprefix(self, prefix, /)\n",
            " |      Return a str with the given prefix string removed if present.\n",
            " |      \n",
            " |      If the string starts with the prefix string, return string[len(prefix):].\n",
            " |      Otherwise, return a copy of the original string.\n",
            " |  \n",
            " |  removesuffix(self, suffix, /)\n",
            " |      Return a str with the given suffix string removed if present.\n",
            " |      \n",
            " |      If the string ends with the suffix string and that suffix is not empty,\n",
            " |      return string[:-len(suffix)]. Otherwise, return a copy of the original\n",
            " |      string.\n",
            " |  \n",
            " |  replace(self, old, new, count=-1, /)\n",
            " |      Return a copy with all occurrences of substring old replaced by new.\n",
            " |      \n",
            " |        count\n",
            " |          Maximum number of occurrences to replace.\n",
            " |          -1 (the default value) means replace all occurrences.\n",
            " |      \n",
            " |      If the optional argument count is given, only the first count occurrences are\n",
            " |      replaced.\n",
            " |  \n",
            " |  rfind(...)\n",
            " |      S.rfind(sub[, start[, end]]) -> int\n",
            " |      \n",
            " |      Return the highest index in S where substring sub is found,\n",
            " |      such that sub is contained within S[start:end].  Optional\n",
            " |      arguments start and end are interpreted as in slice notation.\n",
            " |      \n",
            " |      Return -1 on failure.\n",
            " |  \n",
            " |  rindex(...)\n",
            " |      S.rindex(sub[, start[, end]]) -> int\n",
            " |      \n",
            " |      Return the highest index in S where substring sub is found,\n",
            " |      such that sub is contained within S[start:end].  Optional\n",
            " |      arguments start and end are interpreted as in slice notation.\n",
            " |      \n",
            " |      Raises ValueError when the substring is not found.\n",
            " |  \n",
            " |  rjust(self, width, fillchar=' ', /)\n",
            " |      Return a right-justified string of length width.\n",
            " |      \n",
            " |      Padding is done using the specified fill character (default is a space).\n",
            " |  \n",
            " |  rpartition(self, sep, /)\n",
            " |      Partition the string into three parts using the given separator.\n",
            " |      \n",
            " |      This will search for the separator in the string, starting at the end. If\n",
            " |      the separator is found, returns a 3-tuple containing the part before the\n",
            " |      separator, the separator itself, and the part after it.\n",
            " |      \n",
            " |      If the separator is not found, returns a 3-tuple containing two empty strings\n",
            " |      and the original string.\n",
            " |  \n",
            " |  rsplit(self, /, sep=None, maxsplit=-1)\n",
            " |      Return a list of the substrings in the string, using sep as the separator string.\n",
            " |      \n",
            " |        sep\n",
            " |          The separator used to split the string.\n",
            " |      \n",
            " |          When set to None (the default value), will split on any whitespace\n",
            " |          character (including \\\\n \\\\r \\\\t \\\\f and spaces) and will discard\n",
            " |          empty strings from the result.\n",
            " |        maxsplit\n",
            " |          Maximum number of splits (starting from the left).\n",
            " |          -1 (the default value) means no limit.\n",
            " |      \n",
            " |      Splitting starts at the end of the string and works to the front.\n",
            " |  \n",
            " |  rstrip(self, chars=None, /)\n",
            " |      Return a copy of the string with trailing whitespace removed.\n",
            " |      \n",
            " |      If chars is given and not None, remove characters in chars instead.\n",
            " |  \n",
            " |  split(self, /, sep=None, maxsplit=-1)\n",
            " |      Return a list of the substrings in the string, using sep as the separator string.\n",
            " |      \n",
            " |        sep\n",
            " |          The separator used to split the string.\n",
            " |      \n",
            " |          When set to None (the default value), will split on any whitespace\n",
            " |          character (including \\\\n \\\\r \\\\t \\\\f and spaces) and will discard\n",
            " |          empty strings from the result.\n",
            " |        maxsplit\n",
            " |          Maximum number of splits (starting from the left).\n",
            " |          -1 (the default value) means no limit.\n",
            " |      \n",
            " |      Note, str.split() is mainly useful for data that has been intentionally\n",
            " |      delimited.  With natural text that includes punctuation, consider using\n",
            " |      the regular expression module.\n",
            " |  \n",
            " |  splitlines(self, /, keepends=False)\n",
            " |      Return a list of the lines in the string, breaking at line boundaries.\n",
            " |      \n",
            " |      Line breaks are not included in the resulting list unless keepends is given and\n",
            " |      true.\n",
            " |  \n",
            " |  startswith(...)\n",
            " |      S.startswith(prefix[, start[, end]]) -> bool\n",
            " |      \n",
            " |      Return True if S starts with the specified prefix, False otherwise.\n",
            " |      With optional start, test S beginning at that position.\n",
            " |      With optional end, stop comparing S at that position.\n",
            " |      prefix can also be a tuple of strings to try.\n",
            " |  \n",
            " |  strip(self, chars=None, /)\n",
            " |      Return a copy of the string with leading and trailing whitespace removed.\n",
            " |      \n",
            " |      If chars is given and not None, remove characters in chars instead.\n",
            " |  \n",
            " |  swapcase(self, /)\n",
            " |      Convert uppercase characters to lowercase and lowercase characters to uppercase.\n",
            " |  \n",
            " |  title(self, /)\n",
            " |      Return a version of the string where each word is titlecased.\n",
            " |      \n",
            " |      More specifically, words start with uppercased characters and all remaining\n",
            " |      cased characters have lower case.\n",
            " |  \n",
            " |  translate(self, table, /)\n",
            " |      Replace each character in the string using the given translation table.\n",
            " |      \n",
            " |        table\n",
            " |          Translation table, which must be a mapping of Unicode ordinals to\n",
            " |          Unicode ordinals, strings, or None.\n",
            " |      \n",
            " |      The table must implement lookup/indexing via __getitem__, for instance a\n",
            " |      dictionary or list.  If this operation raises LookupError, the character is\n",
            " |      left untouched.  Characters mapped to None are deleted.\n",
            " |  \n",
            " |  upper(self, /)\n",
            " |      Return a copy of the string converted to uppercase.\n",
            " |  \n",
            " |  zfill(self, width, /)\n",
            " |      Pad a numeric string with zeros on the left, to fill a field of the given width.\n",
            " |      \n",
            " |      The string is never truncated.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  maketrans(...)\n",
            " |      Return a translation table usable for str.translate().\n",
            " |      \n",
            " |      If there is only one argument, it must be a dictionary mapping Unicode\n",
            " |      ordinals (integers) or characters to Unicode ordinals, strings or None.\n",
            " |      Character keys will be then converted to ordinals.\n",
            " |      If there are two arguments, they must be strings of equal length, and\n",
            " |      in the resulting dictionary, each character in x will be mapped to the\n",
            " |      character at the same position in y. If there is a third argument, it\n",
            " |      must be a string, whose characters will be mapped to None in the result.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYuI9o8Bnq3i",
        "outputId": "f95555a8-6ba5-4570-e9fc-52eddecce151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class list in module builtins:\n",
            "\n",
            "class list(object)\n",
            " |  list(iterable=(), /)\n",
            " |  \n",
            " |  Built-in mutable sequence.\n",
            " |  \n",
            " |  If no argument is given, the constructor creates a new empty list.\n",
            " |  The argument must be an iterable if specified.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __add__(self, value, /)\n",
            " |      Return self+value.\n",
            " |  \n",
            " |  __contains__(self, key, /)\n",
            " |      Return key in self.\n",
            " |  \n",
            " |  __delitem__(self, key, /)\n",
            " |      Delete self[key].\n",
            " |  \n",
            " |  __eq__(self, value, /)\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __ge__(self, value, /)\n",
            " |      Return self>=value.\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __getitem__(...)\n",
            " |      x.__getitem__(y) <==> x[y]\n",
            " |  \n",
            " |  __gt__(self, value, /)\n",
            " |      Return self>value.\n",
            " |  \n",
            " |  __iadd__(self, value, /)\n",
            " |      Implement self+=value.\n",
            " |  \n",
            " |  __imul__(self, value, /)\n",
            " |      Implement self*=value.\n",
            " |  \n",
            " |  __init__(self, /, *args, **kwargs)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  __iter__(self, /)\n",
            " |      Implement iter(self).\n",
            " |  \n",
            " |  __le__(self, value, /)\n",
            " |      Return self<=value.\n",
            " |  \n",
            " |  __len__(self, /)\n",
            " |      Return len(self).\n",
            " |  \n",
            " |  __lt__(self, value, /)\n",
            " |      Return self<value.\n",
            " |  \n",
            " |  __mul__(self, value, /)\n",
            " |      Return self*value.\n",
            " |  \n",
            " |  __ne__(self, value, /)\n",
            " |      Return self!=value.\n",
            " |  \n",
            " |  __repr__(self, /)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __reversed__(self, /)\n",
            " |      Return a reverse iterator over the list.\n",
            " |  \n",
            " |  __rmul__(self, value, /)\n",
            " |      Return value*self.\n",
            " |  \n",
            " |  __setitem__(self, key, value, /)\n",
            " |      Set self[key] to value.\n",
            " |  \n",
            " |  __sizeof__(self, /)\n",
            " |      Return the size of the list in memory, in bytes.\n",
            " |  \n",
            " |  append(self, object, /)\n",
            " |      Append object to the end of the list.\n",
            " |  \n",
            " |  clear(self, /)\n",
            " |      Remove all items from list.\n",
            " |  \n",
            " |  copy(self, /)\n",
            " |      Return a shallow copy of the list.\n",
            " |  \n",
            " |  count(self, value, /)\n",
            " |      Return number of occurrences of value.\n",
            " |  \n",
            " |  extend(self, iterable, /)\n",
            " |      Extend list by appending elements from the iterable.\n",
            " |  \n",
            " |  index(self, value, start=0, stop=9223372036854775807, /)\n",
            " |      Return first index of value.\n",
            " |      \n",
            " |      Raises ValueError if the value is not present.\n",
            " |  \n",
            " |  insert(self, index, object, /)\n",
            " |      Insert object before index.\n",
            " |  \n",
            " |  pop(self, index=-1, /)\n",
            " |      Remove and return item at index (default last).\n",
            " |      \n",
            " |      Raises IndexError if list is empty or index is out of range.\n",
            " |  \n",
            " |  remove(self, value, /)\n",
            " |      Remove first occurrence of value.\n",
            " |      \n",
            " |      Raises ValueError if the value is not present.\n",
            " |  \n",
            " |  reverse(self, /)\n",
            " |      Reverse *IN PLACE*.\n",
            " |  \n",
            " |  sort(self, /, *, key=None, reverse=False)\n",
            " |      Sort the list in ascending order and return None.\n",
            " |      \n",
            " |      The sort is in-place (i.e. the list itself is modified) and stable (i.e. the\n",
            " |      order of two equal elements is maintained).\n",
            " |      \n",
            " |      If a key function is given, apply it once to each list item and sort them,\n",
            " |      ascending or descending, according to their function values.\n",
            " |      \n",
            " |      The reverse flag can be set to sort in descending order.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  __class_getitem__(...) from builtins.type\n",
            " |      See PEP 585\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __hash__ = None\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OzX6DHdnq3j",
        "outputId": "1e534ffc-09c9-4dae-ee39-ad91fe332e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class tuple in module builtins:\n",
            "\n",
            "class tuple(object)\n",
            " |  tuple(iterable=(), /)\n",
            " |  \n",
            " |  Built-in immutable sequence.\n",
            " |  \n",
            " |  If no argument is given, the constructor returns an empty tuple.\n",
            " |  If iterable is specified the tuple is initialized from iterable's items.\n",
            " |  \n",
            " |  If the argument is a tuple, the return value is the same object.\n",
            " |  \n",
            " |  Built-in subclasses:\n",
            " |      asyncgen_hooks\n",
            " |      UnraisableHookArgs\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __add__(self, value, /)\n",
            " |      Return self+value.\n",
            " |  \n",
            " |  __contains__(self, key, /)\n",
            " |      Return key in self.\n",
            " |  \n",
            " |  __eq__(self, value, /)\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __ge__(self, value, /)\n",
            " |      Return self>=value.\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __getitem__(self, key, /)\n",
            " |      Return self[key].\n",
            " |  \n",
            " |  __getnewargs__(self, /)\n",
            " |  \n",
            " |  __gt__(self, value, /)\n",
            " |      Return self>value.\n",
            " |  \n",
            " |  __hash__(self, /)\n",
            " |      Return hash(self).\n",
            " |  \n",
            " |  __iter__(self, /)\n",
            " |      Implement iter(self).\n",
            " |  \n",
            " |  __le__(self, value, /)\n",
            " |      Return self<=value.\n",
            " |  \n",
            " |  __len__(self, /)\n",
            " |      Return len(self).\n",
            " |  \n",
            " |  __lt__(self, value, /)\n",
            " |      Return self<value.\n",
            " |  \n",
            " |  __mul__(self, value, /)\n",
            " |      Return self*value.\n",
            " |  \n",
            " |  __ne__(self, value, /)\n",
            " |      Return self!=value.\n",
            " |  \n",
            " |  __repr__(self, /)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __rmul__(self, value, /)\n",
            " |      Return value*self.\n",
            " |  \n",
            " |  count(self, value, /)\n",
            " |      Return number of occurrences of value.\n",
            " |  \n",
            " |  index(self, value, start=0, stop=9223372036854775807, /)\n",
            " |      Return first index of value.\n",
            " |      \n",
            " |      Raises ValueError if the value is not present.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  __class_getitem__(...) from builtins.type\n",
            " |      See PEP 585\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tuple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBjfsZn1nq3j"
      },
      "source": [
        "**Exercise 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cE9IDOUnq3j",
        "outputId": "e59e42e6-563a-4233-b0dc-1d50541598aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-3550055125485641917"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# tuples + lists: slicing, concatination, indexing\n",
        "# only lists: reverse, sort, pop\n",
        "# only tuple: hash\n",
        "hash((1,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJZ0hjognq3k"
      },
      "source": [
        "**Exercise 3)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKwJEOAfnq3k",
        "outputId": "bd7d79a2-3b2d-4a29-d7d8-639881da45f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "myTuple = tuple([1])\n",
        "print (myTuple)\n",
        "type(myTuple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VZOllaPunq3l",
        "outputId": "95ed1cd8-4ca8-44ee-b715-4235d89e9c88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "myTuple = (1,)\n",
        "print (myTuple)\n",
        "type(myTuple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk9f335lnq3l"
      },
      "source": [
        "**Exercise 4)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BaXDyG7wnq3l",
        "outputId": "a1e3e5ac-daeb-4e02-83f5-b8aeb31ed930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'is', 'fun', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "words = ['is', 'NLP', 'fun', '?']\n",
        "tmp = words[0]\n",
        "words[0] = words[1]\n",
        "words[1] = tmp\n",
        "words[3] = '!'\n",
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2OT9obF2nq3m",
        "outputId": "e279f274-dc42-473d-88e8-3e6feacd2a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'is', 'fun', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "words = ['is', 'NLP', 'fun', '?']\n",
        "words[0], words[1], words[3] = words[1], words[0], '!'\n",
        "words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k_FHyqNnq3m"
      },
      "source": [
        "**Exercise 5)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y60uVfBSpEPR",
        "outputId": "ae076009-4d96-425e-bf74-30c00b9d7fe0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cmp= \"hello\""
      ],
      "metadata": {
        "id": "sYDIBu0JpG1D"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o06BceRhnq3m",
        "outputId": "966a1ad9-03b4-4751-d57a-328ce770ccfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Python documentation found for 'hello'.\n",
            "Use help() to get the interactive help utility.\n",
            "Use help(str) for help on the str class.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(cmp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cmp(a, b):\n",
        "    # Implement comparison logic here\n",
        "    pass\n",
        "\n",
        "cmp(3, 9)"
      ],
      "metadata": {
        "id": "9sOYXH98paYg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "def compare(a, b):\n",
        "    # Implement comparison logic here\n",
        "    pass\n",
        "\n",
        "cmp = functools.cmp_to_key(compare)\n",
        "\n",
        "# This line will now work as intended\n",
        "cmp(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSlqu_sbp0Tm",
        "outputId": "c008a10d-7596-488a-c07b-82b22dbc79e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<functools.KeyWrapper at 0x79bb5c396650>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Jz--LxFUnq3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5c696a-82df-474d-cc2a-d7a7bd25547e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<functools.KeyWrapper at 0x79bb5cde8610>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "cmp(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nBrjGqAlnq3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b854114-8b9e-4ceb-af40-e1a1436a86b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<functools.KeyWrapper at 0x79bb5c394190>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "cmp(9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "UVZ-Ziu-nq3n"
      },
      "outputs": [],
      "source": [
        "# can differentiate 3 cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szS-mO5nnq3n"
      },
      "source": [
        "**Exercise 6)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "frWKhkGYnq3n",
        "outputId": "cff3a715-2f88-480a-e6cb-b9e14cad854b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'dog', 'gave'],\n",
              " ['dog', 'gave', 'John'],\n",
              " ['gave', 'John', 'the'],\n",
              " ['John', 'the', 'newspaper']]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
        "n = 3\n",
        "[sent[i:i+n] for i in range(len(sent)-n+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-OMgxUPwnq3n",
        "outputId": "0373a122-7325-4e41-ee28-8e8e4f7f5f63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The'], ['dog'], ['gave'], ['John'], ['the'], ['newspaper']]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
        "n = 1\n",
        "[sent[i:i+n] for i in range(len(sent)-n+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-jhzBERNnq3n",
        "outputId": "fb38ed8b-dc37-4d86-de8c-854b6a513b23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'dog', 'gave', 'John', 'the', 'newspaper']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
        "n = len(sent)\n",
        "[sent[i:i+n] for i in range(len(sent)-n+1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_o6rb88nq3n"
      },
      "source": [
        "**Exercise 7)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "id": "kAqwesqynq3o"
      },
      "outputs": [],
      "source": [
        "if 0:\n",
        "    print('true!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aSMHvccTnq3o",
        "outputId": "63164b04-2d92-41f2-c370-df61506ba9ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true!\n"
          ]
        }
      ],
      "source": [
        "if 1:\n",
        "    print('true!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HBW_Jo8fnq3o",
        "outputId": "15600b39-30af-4555-a4e4-5c5d9c1b51a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true!\n"
          ]
        }
      ],
      "source": [
        "if ('foo'):\n",
        "    print ('true!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "MgKg0GeKnq3o"
      },
      "outputs": [],
      "source": [
        "if (()):\n",
        "    print ('true!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "k6iGFk3nnq3o",
        "outputId": "a9531a0f-2efc-4b95-8b17-61155a21c848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true!\n"
          ]
        }
      ],
      "source": [
        "if (1, 2):\n",
        "    print('true!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "x1aYvPqZnq3o",
        "outputId": "0d8dc873-5560-49f1-ae3f-cd1dfe6c5506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true!\n"
          ]
        }
      ],
      "source": [
        "if (-1):\n",
        "    print ('true!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDqX5VNUnq3o"
      },
      "source": [
        "**Exercise 8)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TqAOUNBxnq3p",
        "outputId": "3cc35e92-219e-43f9-f9a0-73658bcc093a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "'Monty' < 'Python'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hj7ARelWnq3p",
        "outputId": "ca5dc7ee-6402-4042-81dc-3a9f79659e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "'Z' < 'a'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3AKxSkDDnq3p",
        "outputId": "3e9b121e-2767-4ab7-fe34-359083462323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "'z' < 'a'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tnAPvKvKnq3p",
        "outputId": "4b6164aa-1105-4818-922e-b98df31396e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "'Monty' < 'Montague'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "r0nm9YE6nq3p",
        "outputId": "a5a35e03-d8d6-41a6-eeed-cb5302383b06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "('Monty', 1) < ('Monty', 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "d8bUlr0pnq3p",
        "outputId": "2e11e209-c909-4a97-9847-0e71c2801df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "('Monty', 1) < ('Montague', 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "fogWh6w3nq3q",
        "outputId": "fbb3d612-736d-4361-9fdb-3b98039fae60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "(1, 'Monty') < (2, 'Montague')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cn57mFanq3q"
      },
      "source": [
        "**Exercise 9)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "HGIsFggonq3q",
        "outputId": "747a5ee1-3293-436f-a952-658d38efdec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'some whitespaced string'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# a\n",
        "myStr = '  some    whitespaced string  '\n",
        "' '.join(myStr.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "bOl49WCtnq3q",
        "outputId": "1b6e1615-cb00-47bc-fb3c-a275219ba923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'some whitespaced string'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# b\n",
        "import re\n",
        "re.sub(r'\\s+', ' ', re.sub(r'^\\s+|\\s+$', '', myStr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L80udoFnq3u"
      },
      "source": [
        "**Exercise 10)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sortWords(words):\n",
        "    def cmp_len(word):  # Modified to accept only one argument\n",
        "        return len(word)  # Directly return the length of the word\n",
        "    return sorted(words, key=cmp_len)\n",
        "\n",
        "sortWords(['The', 'dog', 'gave', 'John', 'the', 'newspaper'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW5i8pzigoyf",
        "outputId": "4514b6e9-2b72-49e6-c4df-20b70bbc4e02"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'dog', 'the', 'gave', 'John', 'newspaper']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt4BZZ2lnq3u"
      },
      "source": [
        "**Exercise 11)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "o0ckbzJFnq3u",
        "outputId": "2841417e-7fbb-41e8-a05f-cd0994b0a1df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'cat', 'gave', 'John', 'the', 'newspaper']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "sent1 = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
        "sent2 = sent1\n",
        "sent1[1] = 'cat'\n",
        "sent2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "07JmPjX5nq3u",
        "outputId": "e30e0e2e-68d8-4738-e9aa-fcf65f56af49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'dog', 'gave', 'John', 'the', 'newspaper']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# a\n",
        "sent1 = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
        "sent2 = sent1[:]\n",
        "sent1[1] = 'cat'\n",
        "sent2\n",
        "# [:] -> copy list items, instead of creating reference to same list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "f1HnT0FGnq3u",
        "outputId": "7aff2621-8a54-4ce5-f40a-bc67763c5c61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'monkey', 'gave', 'John', 'the', 'newspaper'],\n",
              " ['The', 'cat', 'miowed']]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# b\n",
        "text1 = [['The', 'dog', 'gave', 'John', 'the', 'newspaper'], ['The', 'cat', 'miowed']]\n",
        "text2 = text1[:]\n",
        "text1[0][1] = 'monkey'\n",
        "text2\n",
        "# did not copy inner lists, but references to them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "_99eZJfVnq3u",
        "outputId": "9f33962b-d9bb-4d56-e2db-0a22bfc021fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function deepcopy in module copy:\n",
            "\n",
            "deepcopy(x, memo=None, _nil=[])\n",
            "    Deep copy operation on arbitrary Python objects.\n",
            "    \n",
            "    See the module's __doc__ string for more info.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# c\n",
        "from copy import deepcopy\n",
        "help(deepcopy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "pxGYdl7Gnq3v",
        "outputId": "d8691449-54ee-4b52-fff5-f9078304ce80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'dog', 'gave', 'John', 'the', 'newspaper'], ['The', 'cat', 'miowed']]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "text1 = [['The', 'dog', 'gave', 'John', 'the', 'newspaper'], ['The', 'cat', 'miowed']]\n",
        "text3 = deepcopy(text1)\n",
        "text1[0][1] = 'monkey'\n",
        "text3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5EWQMbInq3v"
      },
      "source": [
        "**Exercise 12)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "oOqhNcUknq3v",
        "outputId": "6491e900-b17e-45a0-9ed2-0cdf340d034a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['', '', 'hello'], ['', '', 'hello'], ['', '', 'hello'], ['', '', 'hello']]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "word_table = [[''] * 3] * 4\n",
        "word_table[1][2] = \"hello\"\n",
        "word_table\n",
        "# multiplication adds references to the same list, not copies of it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vmRD6-HTnq3v",
        "outputId": "092b0d25-b46d-4f6e-e1a6-7b32b8b9e209",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['', '', ''], ['', '', 'hello'], ['', '', ''], ['', '', '']]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "word_table = [['' for count1 in range(3)] for count2 in range(4)]\n",
        "word_table[1][2] = \"hello\"\n",
        "word_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glIPuctRnq3v"
      },
      "source": [
        "**Exercise 13)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "RaN8KPv6nq3v",
        "outputId": "55410b00-b9b2-4b35-bf27-ef79539926f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dog', 'The', 'the', 'cat'}\n",
            "{'newspaper'}\n"
          ]
        }
      ],
      "source": [
        "word_vowels = [[]]\n",
        "words = ['The', 'dog', 'gave', 'John', 'the', 'newspaper', 'The', 'cat', 'miowed']\n",
        "for word in words:\n",
        "    if (len(word) > len(word_vowels)-1):\n",
        "        for index in range(len(word_vowels), len(word)+1):\n",
        "            word_vowels.append([])\n",
        "    num_vowels = len(re.findall(r'[aeiouAEIOU]', word))\n",
        "    if (num_vowels > len(word_vowels[len(word)])-1):\n",
        "        for index in range(len(word_vowels[len(word)]), num_vowels+1):\n",
        "            word_vowels[len(word)].append(set())\n",
        "    word_vowels[len(word)][num_vowels].add(word)\n",
        "print ( word_vowels[3][1])\n",
        "print (word_vowels[9][3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCzXaPSSnq3v"
      },
      "source": [
        "**Exercise 14)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "##from nltk.book import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB34edq8s0bk",
        "outputId": "6e7c3556-633d-4289-f33e-f6407d5bddc3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('genesis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xrJGsK6st4r",
        "outputId": "4aac9283-cfbe-4809-d0db-e1fdb9210c71"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "QpgMKhdanq3w",
        "outputId": "6d3dbc7c-dfd6-4f21-e70c-8a2127db6d67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['The', 'dog', 'gave', 'John', 'the', 'newspaper'], ['The', 'cat', 'miowed']]\n"
          ]
        }
      ],
      "source": [
        "def novel10(text):\n",
        "    splitIndex = int(len(text) / 10)\n",
        "    return [w for w in text[-splitIndex:] if w not in text[:-splitIndex]]\n",
        "\n",
        "##from nltk.book import *\n",
        "text10 = novel10(text3)\n",
        "print(text10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh_T6ylfnq3w"
      },
      "source": [
        "**Exercise 15)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent9 = \"The dog gave John the bone.\""
      ],
      "metadata": {
        "id": "xpIgWxnFtxu7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def countWords(sent):\n",
        "    sent = sent.split()\n",
        "    fdist = nltk.FreqDist(w.lower() for w in sent)\n",
        "    return fdist\n",
        "\n",
        "fdist = countWords(' '.join(sent9))\n",
        "\n",
        "for key in sorted(fdist.keys()):\n",
        "    print('%s: %d' % (key, fdist[key]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nxksfmfthnx",
        "outputId": "4e91b3b0-821d-44ee-ba7b-fad56419e00c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".: 1\n",
            "a: 1\n",
            "b: 1\n",
            "d: 1\n",
            "e: 4\n",
            "g: 2\n",
            "h: 3\n",
            "j: 1\n",
            "n: 2\n",
            "o: 3\n",
            "t: 2\n",
            "v: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def countWords(sent):\n",
        "    sent = sent.split()\n",
        "    fdist = nltk.FreqDist(w.lower() for w in sent)\n",
        "for key in sorted(fdist.keys()):  # Fix indentation\n",
        "        print('%s: %d' % (key, fdist[key]))\n",
        "countWords(' '.join(sent9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtTdHqD8tYxx",
        "outputId": "babbc0d0-f1ee-4c3e-a5e2-cb3501ec4583"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".: 1\n",
            "a: 1\n",
            "b: 1\n",
            "d: 1\n",
            "e: 4\n",
            "g: 2\n",
            "h: 3\n",
            "j: 1\n",
            "n: 2\n",
            "o: 3\n",
            "t: 2\n",
            "v: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "def countWords(sent):\n",
        "    sent = sent.split()\n",
        "    fdist = nltk.FreqDist(w.lower() for w in sent)\n",
        "\n",
        "    for key in sorted(fdist.keys()):\n",
        "        print('%s: %d' % (key, fdist[key]))\n",
        "\n",
        "countWords(' '.join(sent9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZxwZDjwt5zN",
        "outputId": "7b153ad8-b140-4213-842b-426d3ce6848a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".: 1\n",
            "a: 1\n",
            "b: 1\n",
            "d: 1\n",
            "e: 4\n",
            "g: 2\n",
            "h: 3\n",
            "j: 1\n",
            "n: 2\n",
            "o: 3\n",
            "t: 2\n",
            "v: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wKrY0SOnq3w"
      },
      "source": [
        "**Exercise 16)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "3SJgNv6znq3w",
        "outputId": "ef31350c-6579-45aa-fca2-eef27bd1ef05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "660"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# a\n",
        "def gematria(word):\n",
        "    letter_vals = {'a':1, 'b':2, 'c':3, 'd':4, 'e':5, 'f':80, 'g':3, 'h':8, 'i':10, 'j':10, 'k':20, 'l':30, 'm':40, 'n':50, 'o':70, 'p':80, 'q':100, 'r':200, 's':300, 't':400, 'u':6, 'v':6, 'w':800, 'x':60, 'y':10, 'z':7}\n",
        "    return sum(letter_vals[l] for l in word if len(re.findall(r'[a-z]', l)) > 0)\n",
        "gematria('gematria')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('state_union')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv8PHrnzuDHf",
        "outputId": "122afe83-ccae-49d9-fb37-e6848a021c4c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/state_union.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "XeRM7c0Qnq3w",
        "outputId": "caef2b17-f6ef-41ac-9ab5-266b0d3f66ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1945-Truman.txt: 2\n",
            "{'outlook', 'eloquent'}\n",
            "\n",
            "1946-Truman.txt: 13\n",
            "{'outlook', 'retain', 'market'}\n",
            "\n",
            "1947-Truman.txt: 0\n",
            "set()\n",
            "\n",
            "1948-Truman.txt: 2\n",
            "{'market'}\n",
            "\n",
            "1949-Truman.txt: 2\n",
            "{'market'}\n",
            "\n",
            "1950-Truman.txt: 1\n",
            "{'outlook'}\n",
            "\n",
            "1951-Truman.txt: 0\n",
            "set()\n",
            "\n",
            "1953-Eisenhower.txt: 1\n",
            "{'market'}\n",
            "\n",
            "1954-Eisenhower.txt: 6\n",
            "{'retain', 'market'}\n",
            "\n",
            "1955-Eisenhower.txt: 3\n",
            "{'outlook', 'market'}\n",
            "\n",
            "1956-Eisenhower.txt: 1\n",
            "{'outlook'}\n",
            "\n",
            "1957-Eisenhower.txt: 2\n",
            "{'retain', 'market'}\n",
            "\n",
            "1958-Eisenhower.txt: 5\n",
            "{'extra', 'retain'}\n",
            "\n",
            "1959-Eisenhower.txt: 1\n",
            "{'outlook'}\n",
            "\n",
            "1960-Eisenhower.txt: 5\n",
            "{'miraculous', 'outlook', 'eloquent', 'philosophy'}\n",
            "\n",
            "1961-Kennedy.txt: 0\n",
            "set()\n",
            "\n",
            "1962-Kennedy.txt: 11\n",
            "{'retain', 'market'}\n",
            "\n",
            "1963-Johnson.txt: 0\n",
            "set()\n",
            "\n",
            "1963-Kennedy.txt: 5\n",
            "{'extra', 'market'}\n",
            "\n",
            "1964-Johnson.txt: 1\n",
            "{'market'}\n",
            "\n",
            "1965-Johnson-1.txt: 0\n",
            "set()\n",
            "\n",
            "1965-Johnson-2.txt: 0\n",
            "set()\n",
            "\n",
            "1966-Johnson.txt: 0\n",
            "set()\n",
            "\n",
            "1967-Johnson.txt: 2\n",
            "{'extra', 'outlook'}\n",
            "\n",
            "1968-Johnson.txt: 3\n",
            "{'outlook', 'market'}\n",
            "\n",
            "1969-Johnson.txt: 0\n",
            "set()\n",
            "\n",
            "1970-Nixon.txt: 0\n",
            "set()\n",
            "\n",
            "1971-Nixon.txt: 1\n",
            "{'extra'}\n",
            "\n",
            "1972-Nixon.txt: 0\n",
            "set()\n",
            "\n",
            "1973-Nixon.txt: 1\n",
            "{'philosophy'}\n",
            "\n",
            "1974-Nixon.txt: 0\n",
            "set()\n",
            "\n",
            "1975-Ford.txt: 0\n",
            "set()\n",
            "\n",
            "1976-Ford.txt: 3\n",
            "{'extra', 'eloquent'}\n",
            "\n",
            "1977-Ford.txt: 0\n",
            "set()\n",
            "\n",
            "1978-Carter.txt: 1\n",
            "{'retain'}\n",
            "\n",
            "1979-Carter.txt: 2\n",
            "{'extra', 'retain'}\n",
            "\n",
            "1980-Carter.txt: 0\n",
            "set()\n",
            "\n",
            "1981-Reagan.txt: 4\n",
            "{'market'}\n",
            "\n",
            "1982-Reagan.txt: 0\n",
            "set()\n",
            "\n",
            "1983-Reagan.txt: 2\n",
            "{'market'}\n",
            "\n",
            "1984-Reagan.txt: 1\n",
            "{'market'}\n",
            "\n",
            "1985-Reagan.txt: 1\n",
            "{'market'}\n",
            "\n",
            "1986-Reagan.txt: 1\n",
            "{'squander'}\n",
            "\n",
            "1987-Reagan.txt: 1\n",
            "{'market'}\n",
            "\n",
            "1988-Reagan.txt: 2\n",
            "{'extra', 'market'}\n",
            "\n",
            "1989-Bush.txt: 1\n",
            "{'retain'}\n",
            "\n",
            "1990-Bush.txt: 2\n",
            "{'extra', 'market'}\n",
            "\n",
            "1991-Bush-1.txt: 0\n",
            "set()\n",
            "\n",
            "1991-Bush-2.txt: 0\n",
            "set()\n",
            "\n",
            "1992-Bush.txt: 3\n",
            "{'extra', 'papers', 'market'}\n",
            "\n",
            "1993-Clinton.txt: 1\n",
            "{'market'}\n",
            "\n",
            "1994-Clinton.txt: 2\n",
            "{'market'}\n",
            "\n",
            "1995-Clinton.txt: 1\n",
            "{'market'}\n",
            "\n",
            "1996-Clinton.txt: 2\n",
            "{'market'}\n",
            "\n",
            "1997-Clinton.txt: 1\n",
            "{'market'}\n",
            "\n",
            "1998-Clinton.txt: 4\n",
            "{'competency', 'market'}\n",
            "\n",
            "1999-Clinton.txt: 1\n",
            "{'extra'}\n",
            "\n",
            "2000-Clinton.txt: 3\n",
            "{'miraculous', 'extra', 'retina'}\n",
            "\n",
            "2001-GWBush-1.txt: 1\n",
            "{'philosophy'}\n",
            "\n",
            "2001-GWBush-2.txt: 0\n",
            "set()\n",
            "\n",
            "2002-GWBush.txt: 0\n",
            "set()\n",
            "\n",
            "2003-GWBush.txt: 3\n",
            "{'miraculous', 'extra', 'market'}\n",
            "\n",
            "2004-GWBush.txt: 2\n",
            "{'extra', 'papers'}\n",
            "\n",
            "2005-GWBush.txt: 2\n",
            "{'extra', 'market'}\n",
            "\n",
            "2006-GWBush.txt: 0\n",
            "set()\n"
          ]
        }
      ],
      "source": [
        "# b\n",
        "for fileid in nltk.corpus.state_union.fileids():\n",
        "    words666 = [w.lower() for w in nltk.corpus.state_union.words(fileid) if w.isalpha() and gematria(w.lower()) == 666]\n",
        "    print(\"\\n%s: %d\" % (fileid, len(words666)))\n",
        "    print(set(words666))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'text4' in globals():\n",
        "    result = decode(text4)\n",
        "else:\n",
        "    print(\"Variable 'text4' is not defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSFQF4mruQ6I",
        "outputId": "48fa7cc6-2b6d-40da-caff-d668f9ed3f36"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable 'text4' is not defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the variable 'text4' with some value\n",
        "text4 = \"Some text...\"\n",
        "\n",
        "# Import the necessary library if 'decode' is from an external module\n",
        "import codecs # Or 'base64' if it's a base64 decoding function\n",
        "\n",
        "# Instead of decoding, perform an encoding IF necessary\n",
        "result = codecs.encode(text4, 'utf-8')  # Encode to 'utf-8' if needed\n",
        "# To decode, 'text4' should have been a bytes-like object\n",
        "# If text4 was a bytes-like object, this line would work\n",
        "# result = codecs.decode(text4, 'utf-8')  # Replace 'utf-8' with the correct encoding if needed\n",
        "\n",
        "# The rest of the code can remain the same..."
      ],
      "metadata": {
        "id": "DDyOYxcMhne0"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "0fbBxM2vnq3w",
        "outputId": "90e37d15-642a-480b-d5bf-1c2249c5f9b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "720\n",
            "set()\n"
          ]
        }
      ],
      "source": [
        "# c\n",
        "import random\n",
        "def decode(text):\n",
        "    num = random.randint(1, 1000)\n",
        "    return num, set([w.lower() for w in text if w.isalpha() and gematria(w.lower()) == num])\n",
        "result = decode(text4)\n",
        "print(result[0])\n",
        "print(result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEaudeUenq3x"
      },
      "source": [
        "**Exercise 17)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shorten(text, n=20):\n",
        "    most_freq = nltk.FreqDist(text).most_common(n)\n",
        "    most_freq = [w for (w, num) in most_freq]\n",
        "    return ' '.join(most_freq)[:100]"
      ],
      "metadata": {
        "id": "GZeFaZcauhmy"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shorten(text, n=20):\n",
        "    most_freq = nltk.FreqDist(text).most_common(n)\n",
        "    most_freq = [w for (w, num) in most_freq]\n",
        "    return ' '.join(most_freq)[:100]\n",
        "\n",
        "text3 = \"This is a string instead of a list\"\n",
        "print(' '.join(shorten(text3, 50))[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6esjBJBUusZj",
        "outputId": "ee3663ef-483d-4d08-95e2-35a647d53aa9"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    i   s   a   t   n   T   h   r   g   e   d   o   f   l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "kvyXBu47nq3x",
        "outputId": "b224ac67-a975-41f9-e8e8-4c945ea24111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T h i s   i s     s t r i n g   i n s t e d   o f     l i s t\n"
          ]
        }
      ],
      "source": [
        "def shorten(text, n=20):\n",
        "    most_freq = nltk.FreqDist(text).most_common(n)\n",
        "    most_freq = [w for (w, num) in most_freq]\n",
        "    print( most_freq)\n",
        "def shorten(text, n):\n",
        "    most_freq = ['the', 'a', 'an', 'in', 'on']\n",
        "    return [w for w in text if w not in most_freq]\n",
        "\n",
        "print(' '.join(shorten(text3, 50))[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr61idjDnq3x"
      },
      "source": [
        "**Exercise 18)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Y5wKN2hLnq3x",
        "outputId": "8db470e1-7bc6-4c53-a791-ace6e504d42d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fish', 'whale']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "def getWords(prop, value):\n",
        "    lexicon = [('fish', 'water animal', 'fish'), ('house', 'building', 'haus'), ('whale', 'water animal', 'wejl')]\n",
        "    if prop == 'meaning':\n",
        "        return [w for (w, m, p) in lexicon if m == value]\n",
        "    if prop == 'pronunciation':\n",
        "        return [w for (w, m, p) in lexicon if p == value]\n",
        "\n",
        "getWords('meaning', 'water animal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "pcJF_pkpnq3x",
        "outputId": "95d43157-0f04-469c-aeb1-4c9f7e46fbc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['house']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "getWords('pronunciation', 'haus')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaOOh8dSnq3x"
      },
      "source": [
        "**Exercise 19)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeZnW_l6uz41",
        "outputId": "0b542846-e896-480b-f6c6-559d8dca3b8b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# You likely intended to use a WordNet synset.\n",
        "# Here's an example of how you might obtain one:\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Get a synset for the word \"dog\"\n",
        "comp = wn.synset('dog.n.01')\n",
        "\n",
        "# Now you can check its type:\n",
        "if not isinstance(comp, nltk.corpus.reader.wordnet.Synset):\n",
        "    raise ValueError(\"The comp variable must be a WordNet synset object.\")\n",
        "else:\n",
        "    print(\"comp is a valid WordNet synset object.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPAf8sIliBFI",
        "outputId": "33f6bfac-3e66-49af-f7da-1c3204fa6485"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp is a valid WordNet synset object.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "comp = wn.synset('dog.n.01')\n",
        "\n",
        "# Assuming 'haus' is the word for which you want to find synonyms\n",
        "word = 'haus'\n",
        "list_syns = wn.synsets(word)  # Get synsets for the word 'haus'\n",
        "\n",
        "# Now you can sort the list of synonyms:\n",
        "sorted_syns = sorted(list_syns, key=lambda x: comp.shortest_path_distance(x))\n",
        "print(sorted_syns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkyzTO4Eila0",
        "outputId": "c1fbc37b-66f5-4c24-ea54-49e8bba47b7c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(list_syns, key=lambda x: comp.shortest_path_distance(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y5gVObJvtuL",
        "outputId": "78047454-1938-417b-c74e-e79631080c95"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "69XvDJUznq3x",
        "outputId": "b74f505a-e029-467f-ae93-0b0034cccb80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('lesser_rorqual.n.01'),\n",
              " Synset('killer_whale.n.01'),\n",
              " Synset('tortoise.n.01'),\n",
              " Synset('novel.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "list_syns = [wn.synset('minke_whale.n.01'), wn.synset('orca.n.01'), wn.synset('novel.n.01'), wn.synset('tortoise.n.01')]\n",
        "comp = wn.synset('right_whale.n.01')\n",
        "sorted(list_syns, key=lambda x: comp.shortest_path_distance(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMnmP-eznq3x"
      },
      "source": [
        "**Exercise 20)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "TxWdDzN5nq3y",
        "outputId": "63d326b5-7abe-44cd-e254-19631f7d2c23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['one', 'two', 'four', 'three'])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "def sortWords(wordList):\n",
        "    fdist = nltk.FreqDist(wordList)\n",
        "    return fdist.keys()\n",
        "sortWords(['one', 'two', 'two', 'four', 'four', 'four', 'four', 'three', 'three', 'three'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEkyCCH3nq3y"
      },
      "source": [
        "**Exercise 21)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR9qjblPwhM6",
        "outputId": "76f13a5b-5614-42cd-e45e-9fd2353d30c8"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "ESPfhWfKnq3y",
        "outputId": "3c63126c-93a5-421a-cb7c-e7a926ddd6fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' '}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "def unknownWords(text, vocab):\n",
        "    return set(text).difference(set(vocab))\n",
        "unknownWords(text3, nltk.corpus.words.words())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOQNI9xknq3y"
      },
      "source": [
        "**Exercise 22)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "b2FwomeCnq3y"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "sent3 = [('the', 0.008450704225352112), ('cat', 0.08683473388671875), ('sat', 0.07843137288188934), ('on', 0.1360948977470398), ('the', 0.0084507042253521)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuHgpykWwzTN",
        "outputId": "12c4c723-73c1-47ff-e8bf-3b7e11f3355b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 0.008450704225352112),\n",
              " ('cat', 0.08683473388671875),\n",
              " ('sat', 0.07843137288188934),\n",
              " ('on', 0.1360948977470398),\n",
              " ('the', 0.0084507042253521)]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "wS3mSOsNnq3y",
        "outputId": "b35e5db8-8828-431e-f8a3-18b814f10cca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class itemgetter in module operator:\n",
            "\n",
            "class itemgetter(builtins.object)\n",
            " |  itemgetter(item, ...) --> itemgetter object\n",
            " |  \n",
            " |  Return a callable object that fetches the given item(s) from its operand.\n",
            " |  After f = itemgetter(2), the call f(r) returns r[2].\n",
            " |  After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3])\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __call__(self, /, *args, **kwargs)\n",
            " |      Call self as a function.\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __reduce__(...)\n",
            " |      Return state information for pickling\n",
            " |  \n",
            " |  __repr__(self, /)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(itemgetter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "eZe_PuZKnq3y",
        "outputId": "bdeee64e-bcd9-4c7b-fa7c-2f24087cfbb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h\n",
            "hallo\n"
          ]
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "i = itemgetter(0)\n",
        "print(i('hallo'))\n",
        "print(i(['hallo', 'welt']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9yasVFjnq3z"
      },
      "source": [
        "**Exercise 23)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "tcO5b6fJnq3z",
        "outputId": "15ea76f2-f93b-438b-ec4c-3f94ff7bd1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "import nltk\n",
        "def insert(trie, key, value):\n",
        "    if key:\n",
        "        first, rest = key[0], key[1:]\n",
        "        if first not in trie:\n",
        "            trie[first] = {}\n",
        "        insert(trie[first], rest, value)\n",
        "    else:\n",
        "        trie['value'] = value\n",
        "\n",
        "trie = nltk.defaultdict(dict)\n",
        "insert(trie, 'chat', 'cat')\n",
        "insert(trie, 'chien', 'dog')\n",
        "insert(trie, 'chair', 'flesh')\n",
        "trie['c']['h']['a']['t']['value']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lookup(trie, key):\n",
        "    if len(key) == 0:\n",
        "        if 'value' in trie:\n",
        "            result = trie['value']\n",
        "            return result\n",
        "        elif (len(trie) == 1):\n",
        "            keys = trie.keys()\n",
        "            return lookup(trie[keys[0]], '')\n",
        "        else:\n",
        "            return 'no value found'\n",
        "    else:\n",
        "        if (key[0] in trie):\n",
        "            return lookup(trie[key[0]], key[1:])\n",
        "        else:\n",
        "            return 'no value found'"
      ],
      "metadata": {
        "id": "07cXBjWNxLnf"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lookup(trie, 'ch'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDmFdGe4xVRZ",
        "outputId": "1603cdaa-db6d-4c8f-e9c8-879f91c5c6ad"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no value found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "def lookup(trie, key):\n",
        "    if len(key) == 0:\n",
        "        if 'value' in trie:\n",
        "            result = trie['value']\n",
        "            return result\n",
        "        elif (len(trie) == 1):\n",
        "            keys = trie.keys()  # using list(trie.keys()) for Python 3 compatibility\n",
        "            return lookup(trie[keys[0]], '')\n",
        "        else:\n",
        "            return 'no value found'\n",
        "    else:\n",
        "        if (key[0] in trie):\n",
        "            return lookup(trie[key[0]], key[1:])\n",
        "        else:\n",
        "            return 'no value found'  # Added the missing indented block for the first lookup function's else statement\n",
        "\n",
        "\n",
        "def lookup2(trie, key):  # Renamed the second lookup function to avoid conflict\n",
        "    node = trie\n",
        "    for char in key:\n",
        "        if char not in node:\n",
        "            return 'no value found'\n",
        "        node = node[char]\n",
        "    return node.get('value', 'no value found')\n",
        "\n",
        "print(lookup(trie, 'ch'))  # Calling the first lookup function\n",
        "# print(lookup2(trie, 'ch')) # Uncomment to call the second lookup function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDqIPX3zjBii",
        "outputId": "c80d5b01-5086-4250-a5a0-bbb5c7e599e4"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no value found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx5Iq_s_nq3z"
      },
      "source": [
        "**Exercise 24)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "collapsed": true,
        "id": "LNafCVQ6nq3z"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqDLzjZFnq3z"
      },
      "source": [
        "**Exercise 25)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "MFhSN5L9nq3z",
        "outputId": "af005b23-42bc-4a90-af2c-1ce8ac858cfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function edit_distance in module nltk.metrics.distance:\n",
            "\n",
            "edit_distance(s1, s2, substitution_cost=1, transpositions=False)\n",
            "    Calculate the Levenshtein edit-distance between two strings.\n",
            "    The edit distance is the number of characters that need to be\n",
            "    substituted, inserted, or deleted, to transform s1 into s2.  For\n",
            "    example, transforming \"rain\" to \"shine\" requires three steps,\n",
            "    consisting of two substitutions and one insertion:\n",
            "    \"rain\" -> \"sain\" -> \"shin\" -> \"shine\".  These operations could have\n",
            "    been done in other orders, but at least three steps are needed.\n",
            "    \n",
            "    Allows specifying the cost of substitution edits (e.g., \"a\" -> \"b\"),\n",
            "    because sometimes it makes sense to assign greater penalties to\n",
            "    substitutions.\n",
            "    \n",
            "    This also optionally allows transposition edits (e.g., \"ab\" -> \"ba\"),\n",
            "    though this is disabled by default.\n",
            "    \n",
            "    :param s1, s2: The strings to be analysed\n",
            "    :param transpositions: Whether to allow transposition edits\n",
            "    :type s1: str\n",
            "    :type s2: str\n",
            "    :type substitution_cost: int\n",
            "    :type transpositions: bool\n",
            "    :rtype: int\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(nltk.edit_distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "bq_EO6qEnq30",
        "outputId": "45bc2d95-df1e-48e9-affb-662ca87c06f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "nltk.edit_distance('kitten', 'sitting', True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB9QH0H5nq30"
      },
      "source": [
        "**Exercise 26)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Aredtytcnq30",
        "outputId": "d975d8e0-8527-40dd-ea99-2f89a801a6d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# a\n",
        "def catalan_recursive(n):\n",
        "    if (n == 0):\n",
        "        return 1\n",
        "    i = 0\n",
        "    result = 0\n",
        "    original_n = n\n",
        "    while i < original_n:\n",
        "        result += catalan_recursive(i) * catalan_recursive(n-1)\n",
        "        n -= 1\n",
        "        i += 1\n",
        "    return result\n",
        "\n",
        "catalan_recursive(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "qAIYqiNRnq30",
        "outputId": "35ab9dcb-4b27-4d2a-90c9-c2c6e0c443ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "# b\n",
        "def catalan_dynamic(n, lookup={0:1}):\n",
        "    result = 0\n",
        "    if n == 0:\n",
        "        return 1\n",
        "    for i in range(n):\n",
        "        if i not in lookup:\n",
        "            lookup[i] = catalan_dynamic(i, lookup)\n",
        "        if n-1 not in lookup:\n",
        "            lookup[n-1] = catalan_dynamic(n-1, lookup)\n",
        "        result += lookup[i] * lookup[n-1]\n",
        "        n -= 1\n",
        "    return result\n",
        "\n",
        "catalan_dynamic(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "PEWn1A-hnq30",
        "outputId": "a5423a8e-ac76-486e-ce46-c443ba0e3e4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11681192800006102\n",
            "4.83540000004723e-05\n"
          ]
        }
      ],
      "source": [
        "# c\n",
        "from timeit import Timer\n",
        "t = Timer(lambda: catalan_recursive(10))\n",
        "print(t.timeit(number=10))\n",
        "t = Timer(lambda: catalan_dynamic(10))\n",
        "print(t.timeit(number=10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa0L92g4nq30"
      },
      "source": [
        "**Exercise 27)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "collapsed": true,
        "id": "Bd2_EqLanq31"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIZ771zwnq31"
      },
      "source": [
        "**Exercise 28)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "collapsed": true,
        "id": "0MSZggfRnq31"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoS4ov5tnq31"
      },
      "source": [
        "**Exercise 29)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "nNf-bGxxnq31",
        "outputId": "05fcabf0-a091-4b65-af7f-ca5258b06a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "import nltk\n",
        "trie = nltk.defaultdict(dict)\n",
        "insert(trie, 'chat', 'cat')\n",
        "insert(trie, 'chien', 'dog')\n",
        "insert(trie, 'chair', 'flesh')\n",
        "insert(trie, 'chic', 'stylish')\n",
        "trie['c']['h']['a']['t']['value']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "lkyRZ1Rxnq31",
        "outputId": "e663f6c3-8345-42da-fdc7-6119c327b644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".0.0.0.0.0: 'flesh'\n",
            ".0.0.0.0r: 'flesh'\n",
            ".0.0.0i.0: 'flesh'\n",
            ".0.0.0ir: 'flesh'\n",
            ".0.0.0.1: 'cat'\n",
            "------t: 'cat'\n",
            ".0.0a.0.0: 'flesh'\n",
            ".0.0a.0r: 'flesh'\n",
            ".0.0ai.0: 'flesh'\n",
            ".0.0air: 'flesh'\n",
            ".0.0a.1: 'cat'\n",
            "-----t: 'cat'\n",
            ".0.0.1.0: 'stylish'\n",
            ".0.0.1c: 'stylish'\n",
            ".0.0.1.1.0: 'dog'\n",
            ".0.0.1.1n: 'dog'\n",
            "------e.0: 'dog'\n",
            "------en: 'dog'\n",
            "----i.0: 'stylish'\n",
            "----ic: 'stylish'\n",
            "----i.1.0: 'dog'\n",
            "----i.1n: 'dog'\n",
            "-----e.0: 'dog'\n",
            "-----en: 'dog'\n",
            ".0h.0.0.0: 'flesh'\n",
            ".0h.0.0r: 'flesh'\n",
            ".0h.0i.0: 'flesh'\n",
            ".0h.0ir: 'flesh'\n",
            ".0h.0.1: 'cat'\n",
            "-----t: 'cat'\n",
            ".0ha.0.0: 'flesh'\n",
            ".0ha.0r: 'flesh'\n",
            ".0hai.0: 'flesh'\n",
            ".0hair: 'flesh'\n",
            ".0ha.1: 'cat'\n",
            "----t: 'cat'\n",
            ".0h.1.0: 'stylish'\n",
            ".0h.1c: 'stylish'\n",
            ".0h.1.1.0: 'dog'\n",
            ".0h.1.1n: 'dog'\n",
            "-----e.0: 'dog'\n",
            "-----en: 'dog'\n",
            "---i.0: 'stylish'\n",
            "---ic: 'stylish'\n",
            "---i.1.0: 'dog'\n",
            "---i.1n: 'dog'\n",
            "----e.0: 'dog'\n",
            "----en: 'dog'\n",
            "c.0.0.0.0: 'flesh'\n",
            "c.0.0.0r: 'flesh'\n",
            "c.0.0i.0: 'flesh'\n",
            "c.0.0ir: 'flesh'\n",
            "c.0.0.1: 'cat'\n",
            "-----t: 'cat'\n",
            "c.0a.0.0: 'flesh'\n",
            "c.0a.0r: 'flesh'\n",
            "c.0ai.0: 'flesh'\n",
            "c.0air: 'flesh'\n",
            "c.0a.1: 'cat'\n",
            "----t: 'cat'\n",
            "c.0.1.0: 'stylish'\n",
            "c.0.1c: 'stylish'\n",
            "c.0.1.1.0: 'dog'\n",
            "c.0.1.1n: 'dog'\n",
            "-----e.0: 'dog'\n",
            "-----en: 'dog'\n",
            "---i.0: 'stylish'\n",
            "---ic: 'stylish'\n",
            "---i.1.0: 'dog'\n",
            "---i.1n: 'dog'\n",
            "----e.0: 'dog'\n",
            "----en: 'dog'\n",
            "ch.0.0.0: 'flesh'\n",
            "ch.0.0r: 'flesh'\n",
            "ch.0i.0: 'flesh'\n",
            "ch.0ir: 'flesh'\n",
            "ch.0.1: 'cat'\n",
            "----t: 'cat'\n",
            "cha.0.0: 'flesh'\n",
            "cha.0r: 'flesh'\n",
            "chai.0: 'flesh'\n",
            "chair: 'flesh'\n",
            "cha.1: 'cat'\n",
            "---t: 'cat'\n",
            "ch.1.0: 'stylish'\n",
            "ch.1c: 'stylish'\n",
            "ch.1.1.0: 'dog'\n",
            "ch.1.1n: 'dog'\n",
            "----e.0: 'dog'\n",
            "----en: 'dog'\n",
            "--i.0: 'stylish'\n",
            "--ic: 'stylish'\n",
            "--i.1.0: 'dog'\n",
            "--i.1n: 'dog'\n",
            "---e.0: 'dog'\n",
            "---en: 'dog'\n"
          ]
        }
      ],
      "source": [
        "def pprint_trie(trie, line=''):\n",
        "    if 'value' in trie:\n",
        "        print(line + ': \\'' + trie['value'] + '\\'')\n",
        "        return\n",
        "    for index, key in enumerate(sorted(trie.keys())):\n",
        "        pprint_trie(trie[key], line + '.' + str(index))\n",
        "        if (index == 0):\n",
        "            pprint_trie(trie[key], line + key)\n",
        "        else:\n",
        "            pprint_trie(trie[key], ('-' * len(line)) + key)\n",
        "\n",
        "pprint_trie(trie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUGkjg6qnq31"
      },
      "source": [
        "**Exercise 30)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "return [lookup_unique(w, trie) for w in text.split() if w]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "zxhbgqUyxq9L",
        "outputId": "1d2ed30c-1a63-4865-8f60-aa207e84b055"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'return' outside function (<ipython-input-100-8d5c22ecd380>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-100-8d5c22ecd380>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    return [lookup_unique(w, trie) for w in text.split() if w]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lookup_unique(key, trie, unique='', buffer_unique=''):\n",
        "    if len(key) == 0:\n",
        "        if len(buffer_unique) > 0:\n",
        "            return buffer_unique\n",
        "        else:\n",
        "            return unique\n",
        "    if key[0] in trie and len(trie[key[0]]) == 1: # Check if key[0] is in trie\n",
        "        if len(buffer_unique) > 0:\n",
        "            new_buffer_unique = buffer_unique\n",
        "        else:\n",
        "            new_buffer_unique = unique + key[0]\n",
        "        return lookup_unique(key[1:], trie[key[0]], unique + key[0], new_buffer_unique)\n",
        "    return lookup_unique(key[1:], trie.get(key[0], {}), unique + key[0]) # Handle missing keys\n",
        "\n",
        "\n",
        "def compress(text):\n",
        "    trie = nltk.defaultdict(dict)\n",
        "    for word in text:\n",
        "        insert(trie, word, word)\n",
        "def lookup_unique(key, trie, unique='', buffer_unique=''):\n",
        "    if len(key) == 0:\n",
        "        if len(buffer_unique) > 0:\n",
        "            return buffer_unique\n",
        "        else:\n",
        "            return unique\n",
        "    if key[0] in trie and len(trie[key[0]]) == 1: # Check if key[0] is in trie\n",
        "        if len(buffer_unique) > 0:\n",
        "            new_buffer_unique = buffer_unique\n",
        "        else:\n",
        "            new_buffer_unique = unique + key[0]\n",
        "        return lookup_unique(key[1:], trie[key[0]], unique + key[0], new_buffer_unique)\n",
        "    return lookup_unique(key[1:], trie.get(key[0], {}), unique + key[0]) # Handle missing keys\n",
        "\n",
        "\n",
        "def compress(text):\n",
        "    trie = nltk.defaultdict(dict)\n",
        "    for word in text:\n",
        "        insert(trie, word, word)\n",
        "    return [lookup_unique(w, trie) for w in text]\n",
        "\n",
        "compressed = compress([word for sentence in text1 for word in sentence])"
      ],
      "metadata": {
        "id": "Him3cAP5jaCO"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk --quiet\n",
        "import nltk\n",
        "from nltk import defaultdict\n",
        "\n",
        "def insert(trie, key, value):\n",
        "    if key:\n",
        "        first, rest = key[0], key[1:]\n",
        "        if first not in trie:\n",
        "            trie[first] = {}\n",
        "        insert(trie[first], rest, value)\n",
        "    else:\n",
        "        trie['value'] = value\n",
        "\n",
        "def lookup_unique(key, trie, unique='', buffer_unique=''):\n",
        "    if len(key) == 0:\n",
        "        if len(buffer_unique) > 0:\n",
        "            return buffer_unique\n",
        "        else:\n",
        "            return unique\n",
        "    if key[0] in trie and len(trie[key[0]]) == 1:  # Check if key[0] is in trie\n",
        "        if len(buffer_unique) > 0:\n",
        "            new_buffer_unique = buffer_unique\n",
        "        else:\n",
        "            new_buffer_unique = unique + key[0]\n",
        "        return lookup_unique(key[1:], trie[key[0]], unique + key[0], new_buffer_unique)\n",
        "    return lookup_unique(key[1:], trie.get(key[0], {}), unique + key[0])  # Handle missing keys\n",
        "\n",
        "\n",
        "def compress(text):\n",
        "    trie = nltk.defaultdict(dict)\n",
        "    # Extract only the words from the list of tuples in text\n",
        "    words = [word for word, freq in text]\n",
        "    for word in words:\n",
        "        insert(trie, word, word)\n",
        "    # Apply lookup_unique to the extracted words\n",
        "    return [lookup_unique(w, trie) for w in words]"
      ],
      "metadata": {
        "id": "R6xOufOKj8v4"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AbXCytanq34"
      },
      "source": [
        "**Exercise 31)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('corpus.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv_-VWaJkCqk",
        "outputId": "2440c56c-5c36-4093-cc47-734044f2fb18"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading corpus.txt: Package 'corpus.txt' not found\n",
            "[nltk_data]     in index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load(fileName):\n",
        "    \"\"\"\n",
        "    This function loads the contents of a file into a string.\n",
        "\n",
        "    Args:\n",
        "        fileName (str): The name of the file to load.\n",
        "\n",
        "    Returns:\n",
        "        str: The contents of the file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(fileName + '.txt', 'r') as f:\n",
        "            return f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{fileName}.txt' not found.\")\n",
        "        return None\n",
        "\n",
        "raw = load('corpus')\n",
        "\n",
        "if raw is not None:\n",
        "    import textwrap\n",
        "    wrapped = textwrap.wrap(raw)\n",
        "    print(wrapped[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waItsjWZyWHK",
        "outputId": "20a137fa-7028-4d4c-dad9-1a2fb64d3ff1"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'corpus.txt' not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'wrapped' is defined before calling 'justify'\n",
        "if raw is not None:\n",
        "    import textwrap\n",
        "    wrapped = textwrap.wrap(raw)\n",
        "    justify(wrapped[:30])"
      ],
      "metadata": {
        "id": "WWE88m-ZyloJ"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def justify(wrapped_text):\n",
        "    line_length = max(len(line) for line in wrapped_text)\n",
        "    for line in wrapped_text:\n",
        "        words = line.split()\n",
        "        num_chars = sum(len(word) for word in words)\n",
        "        num_spaces = line_length - num_chars\n",
        "        num_slots = len(words) - 1\n",
        "        fixed_spaces = int(num_spaces / num_slots)\n",
        "        spaces = 0\n",
        "        for index, word in enumerate(words[:-1]):\n",
        "            word += ' ' * fixed_spaces\n",
        "            spaces += fixed_spaces\n",
        "            words[index] = word\n",
        "\n",
        "        while num_spaces - spaces > 0:\n",
        "            remainder = (num_spaces - spaces) % num_slots\n",
        "            chunk_size = int(len(words) / (remainder + 1))\n",
        "            chunk = 0\n",
        "            for index, word in enumerate(words[:-1]):\n",
        "                if remainder and chunk == chunk_size:\n",
        "                    word += ' '\n",
        "                    spaces += 1\n",
        "                    chunk = 0\n",
        "                else:\n",
        "                    chunk += 1\n",
        "                words[index] = word #This line was not indented correctly\n",
        "\n",
        "        print(''.join(words))\n"
      ],
      "metadata": {
        "id": "RyQzxPrdkVPy"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYkKlKJOnq36"
      },
      "source": [
        "**Exercise 32)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nVPQ2MnkiEB",
        "outputId": "3e583130-e5e9-48fe-d119-3905663f4c4b"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from operator import itemgetter\n",
        "\n",
        "def summarize(text_sents, n):\n",
        "    freqDist = nltk.FreqDist([w.lower() for sent in text_sents for w in sent])\n",
        "    scoresSents = [(sum(freqDist[word] for word in sent), index, sent) for (index, sent) in enumerate(text_sents)]\n",
        "    sortByFreq = sorted(scoresSents, key=itemgetter(0), reverse=True)[:n]\n",
        "    # Indentation corrected: sortByIndex is now defined within the function's scope\n",
        "    sortByIndex = sorted(sortByFreq, key=itemgetter(1))\n",
        "    for freq, index, sent in sortByIndex:\n",
        "        print(index, ': ', sent, '\\n')\n",
        "\n",
        "from nltk.corpus import brown\n",
        "summarize(brown.sents(categories='religion'), 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CGFqy5TkfFn",
        "outputId": "b17080c3-f30a-4e97-ec70-56b8252e54f4"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "274 :  ['``', 'So', 'that', 'the', 'man', 'should', 'not', 'have', 'thoughts', 'of', 'grandeur', ',', 'and', 'become', 'lifted', 'up', ',', 'as', 'if', 'he', 'had', 'no', 'lord', ',', 'because', 'of', 'the', 'dominion', 'that', 'had', 'been', 'given', 'to', 'him', ',', 'and', 'the', 'freedom', ',', 'fall', 'into', 'sin', 'against', 'God', 'his', 'Creator', ',', 'overstepping', 'his', 'bounds', ',', 'and', 'take', 'up', 'an', 'attitude', 'of', 'self-conceited', 'arrogance', 'towards', 'God', ',', 'a', 'law', 'was', 'given', 'him', 'by', 'God', ',', 'that', 'he', 'might', 'know', 'that', 'he', 'had', 'for', 'lord', 'the', 'lord', 'of', 'all', '.'] \n",
            "\n",
            "304 :  ['But', 'He', 'set', 'a', 'bound', 'to', 'his', '(', 'state', 'of', ')', 'sin', ',', 'by', 'interposing', 'death', ',', 'and', 'thus', 'causing', 'sin', 'to', 'cease', ',', 'putting', 'an', 'end', 'to', 'it', 'by', 'the', 'dissolution', 'of', 'the', 'flesh', ',', 'which', 'should', 'take', 'place', 'in', 'the', 'earth', ',', 'so', 'that', 'man', ',', 'ceasing', 'at', 'length', 'to', 'live', 'in', 'sin', ',', 'and', 'dying', 'to', 'it', ',', 'might', 'live', 'to', 'God', \"''\", '.'] \n",
            "\n",
            "383 :  ['What', 'otherwise', 'could', '``', 'the', 'lawyer', ',', 'doctor', ',', 'minister', ',', 'the', 'men', 'of', 'science', 'and', 'letters', \"''\", 'do', 'when', 'told', 'that', 'they', 'had', '``', 'become', 'the', 'cherubim', 'and', 'seraphim', 'and', 'the', 'three', 'archangels', 'who', 'stood', 'before', 'the', 'golden', 'throne', 'of', 'the', 'merchant', ',', 'and', 'continually', 'cried', ',', \"'\", 'Holy', ',', 'holy', ',', 'holy', 'is', 'the', 'Almighty', 'Dollar', \"'\", '``', '?', '?'] \n",
            "\n",
            "401 :  ['We', 'have', 'not', 'the', 'leisure', ',', 'or', 'the', 'patience', ',', 'or', 'the', 'skill', ',', 'to', 'comprehend', 'what', 'was', 'working', 'in', 'the', 'mind', 'and', 'heart', 'of', 'a', 'then', 'recent', 'graduate', 'from', 'the', 'Harvard', 'Divinity', 'School', 'who', 'would', 'muster', 'the', 'audacity', 'to', 'contradict', 'his', 'most', 'formidable', 'instructor', ',', 'the', 'majesterial', 'Andrews', 'Norton', ',', 'by', 'saying', 'that', ',', 'while', 'he', 'believed', 'Jesus', '``', 'like', 'other', 'religious', 'teachers', \"''\", ',', 'worked', 'miracles', ',', '``', 'I', 'see', 'not', 'how', 'a', 'miracle', 'proves', 'a', 'doctrine', \"''\", '.'] \n",
            "\n",
            "406 :  ['At', 'one', 'time', 'I', 'became', 'disturbed', 'in', 'the', 'faith', 'in', 'which', 'I', 'had', 'grown', 'up', 'by', 'the', 'apparent', 'inroads', 'being', 'made', 'upon', 'both', 'Old', 'and', 'New', 'Testaments', 'by', 'a', '``', 'Higher', 'Criticism', \"''\", 'of', 'the', 'Bible', ',', 'to', 'refute', 'which', 'I', 'felt', 'the', 'need', 'of', 'a', 'better', 'knowledge', 'of', 'Hebrew', 'and', 'of', 'archaeology', ',', 'for', 'it', 'seemed', 'to', 'me', 'that', 'to', 'pull', 'out', 'some', 'of', 'the', 'props', 'of', 'our', 'faith', 'was', 'to', 'weaken', 'the', 'entire', 'structure', '.'] \n",
            "\n",
            "417 :  ['The', 'outcome', 'of', 'such', 'an', 'experiment', 'has', 'been', 'in', 'due', 'time', 'the', 'acceptance', 'of', 'the', 'Bible', 'as', 'the', 'Word', 'of', 'God', 'inspired', 'in', 'a', 'sense', 'utterly', 'different', 'from', 'any', 'merely', 'human', 'book', ',', 'and', 'with', 'it', 'the', 'acceptance', 'of', 'our', 'Lord', 'Jesus', 'Christ', 'as', 'the', 'only', 'begotten', 'Son', 'of', 'God', ',', 'Son', 'of', 'Man', 'by', 'the', 'Virgin', 'Mary', ',', 'the', 'Saviour', 'of', 'the', 'world', '.'] \n",
            "\n",
            "418 :  ['I', 'believe', ',', 'therefore', ',', 'that', 'we', 'are', 'without', 'exception', 'sinners', ',', 'by', 'nature', 'alienated', 'from', 'God', ',', 'and', 'that', 'Jesus', 'Christ', ',', 'the', 'Son', 'of', 'God', ',', 'came', 'to', 'earth', ',', 'the', 'representative', 'Head', 'of', 'a', 'new', 'race', ',', 'to', 'die', 'upon', 'the', 'cross', 'and', 'pay', 'the', 'penalty', 'of', 'the', 'sin', 'of', 'the', 'world', ',', 'and', 'that', 'he', 'who', 'thus', 'receives', 'Christ', 'as', 'his', 'personal', 'Saviour', 'is', '``', 'born', 'again', \"''\", 'spiritually', ',', 'with', 'new', 'privileges', ',', 'appetites', ',', 'and', 'affections', ',', 'destined', 'to', 'live', 'and', 'grow', 'in', 'His', 'likeness', 'forever', '.'] \n",
            "\n",
            "657 :  ['Although', 'the', 'primary', 'mathematical', 'properties', 'of', 'the', 'middle', 'number', 'at', 'the', 'center', 'of', 'the', 'Lo', 'Shu', ',', 'and', 'the', 'interrelation', 'of', 'all', 'the', 'other', 'numbers', 'to', 'it', ',', 'might', 'seem', 'enough', 'to', 'account', 'for', 'the', 'deep', 'fascination', 'which', 'the', 'Lo', 'Shu', 'held', 'for', 'the', 'Old', 'Chinese', 'philosophers', ',', 'this', 'was', 'actually', 'only', 'a', 'beginning', 'of', 'wonders', '.'] \n",
            "\n",
            "964 :  ['Presumably', ',', 'if', 'the', 'reverse', 'is', 'the', 'case', 'and', 'the', 'good', 'effect', 'is', 'more', 'certain', 'than', 'the', 'evil', 'result', 'that', 'may', 'be', 'forthcoming', ',', 'not', 'only', 'must', 'the', 'good', 'and', 'the', 'evil', 'be', 'prudentially', 'weighed', 'and', 'found', 'proportionate', ',', 'but', 'also', 'calculation', 'of', 'the', 'probabilities', 'and', 'of', 'the', 'degree', 'of', 'certainty', 'or', 'uncertainty', 'in', 'the', 'good', 'or', 'evil', 'effect', 'must', 'be', 'taken', 'into', 'account', '.'] \n",
            "\n",
            "1258 :  ['We', 'should', 'recall', 'the', 'number', 'of', 'movements', 'for', 'the', 'service', 'of', 'mankind', 'which', 'arose', 'from', 'the', 'kindred', 'Evangelicalism', 'of', 'the', 'British', 'Isles', 'and', 'the', 'Pietism', 'of', 'the', 'Continent', 'of', 'Europe', '--', 'among', 'them', 'prison', 'reform', ',', 'anti-slavery', 'measures', ',', 'legislation', 'for', 'the', 'alleviation', 'of', 'conditions', 'of', 'labour', ',', 'the', 'Inner', 'Mission', ',', 'and', 'the', 'Red', 'Cross', '.'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "vbU9QGULnq36"
      },
      "source": [
        "**Exercise 33)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kZxQ3AV1nq36"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtVILLlinq37"
      },
      "source": [
        "**Exercise 34)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TbADrttvnq37"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_tyfpH7nq37"
      },
      "source": [
        "**Exercise 35)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "odPEUj_1nq37"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k37diSCQnq37"
      },
      "source": [
        "**Exercise 36)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "YqTeLhr2nq37",
        "outputId": "aa7f2a50-0a3b-40ea-f7bc-47aea5efd301",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AANI\n",
            "ABAC\n",
            "NACE\n",
            "ICED\n"
          ]
        }
      ],
      "source": [
        "def word_square(n):\n",
        "    # works only if n < 5, with 5 exceeds maximum recursion callstack\n",
        "    # TODO: Do this iteratively to avoid the callstack issue?\n",
        "    from nltk.corpus import words\n",
        "    myWords = [word.upper() for word in filter(lambda w: len(w) == n, words.words())] # get all words of length n\n",
        "\n",
        "    square = []\n",
        "    skipWords = [[] for i in range(n)] # cache for words that have already been tested at position i\n",
        "\n",
        "    def check_against_square(word): # checks if current state of square would allow to add word to it\n",
        "        if word in square:\n",
        "            return False\n",
        "        for (index, square_word) in enumerate(square):\n",
        "            if (word[index] != square_word[len(square)]):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def add_word(): # recursively adds / removes words from square until solution is found\n",
        "        if len(square) == n:\n",
        "            return True\n",
        "        for word in myWords:\n",
        "            if len(square) == n:\n",
        "                return True\n",
        "            if (word not in skipWords[len(square)]) and check_against_square(word): # add the word to square if it hasn't been tested unsuccessfully already and if it fits\n",
        "                square.append(word)\n",
        "                add_word()\n",
        "        if len(square) != n and len(square) != 0:\n",
        "            skipWords[len(square) - 1].append(square.pop()) # add word to cache\n",
        "            for i in range(len(square) + 1, n): # reset the following parts of the cache\n",
        "                skipWords[i] = []\n",
        "            add_word()\n",
        "        return False\n",
        "\n",
        "\n",
        "    if add_word():\n",
        "        for word in square:\n",
        "            print ( word)\n",
        "    else:\n",
        "        print( 'No square found :/')\n",
        "\n",
        "word_square(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "DIIgmwpMnq37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373eb00c-bfeb-4839-f672-2ecda45f725f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAL\n",
            "ABA\n",
            "LAB\n"
          ]
        }
      ],
      "source": [
        "word_square(3)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}