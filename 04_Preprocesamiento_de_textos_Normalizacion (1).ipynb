{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SkM4QxRZyTPm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ERAzFTniao"
      },
      "source": [
        "# 03 - Conceptos para el Procesamiento del Lenguaje Natural con spaCy\n",
        "\n",
        "* ***spaCy*** es una librería de código abierto en python para el Procesamiento del Lenguaje natural que posee modelos entrenados para varios idiomas, entre ellos el Español.\n",
        "\n",
        "\n",
        "* Es una librería pensada para funcionar en entornos productivos y es una librería con mejor rendimiento que **NLTK**.\n",
        "\n",
        "\n",
        "* Dispone de una web y de una documentación muy buena, incluso se pueden ejecutar ciertos ejemplos en la propia web: https://spacy.io/\n",
        "\n",
        "\n",
        "* Dispone también de un curso online (https://course.spacy.io/) bastante interesante.\n",
        "\n",
        "\n",
        "* Entre otras cosas con ***spaCy*** podemos hacer:\n",
        "    1. Tokenización\n",
        "    2. Lematización\n",
        "    3. Detección de Stop Words\n",
        "    4. Part of Speech (PoS)\n",
        "    5. Named Entity Recognition (NER)\n",
        "\n",
        "\n",
        "* ***spaCy*** puede ser instalado tanto con \"pip\" como con \"conda\" de la siguiente manera respectivamente:\n",
        "\n",
        "```\n",
        ">> pip install spacy\n",
        ">> conda install spacy\n",
        "```\n",
        "\n",
        "\n",
        "* Como se ha comentado anteriormente la ventaja que tiene ***spaCy*** frente a ***NLTK*** en lo que a idiomas se refiere es que permite trabajar con varior idiomas gracias a los modelos que tiene entrenados.\n",
        "\n",
        "\n",
        "* En particular para el Español ***spaCy*** tiene entrenados dos modelos (con Redes Neuronales Convolucionales según su documentación) de pequeño y mediano tamaño con los corpus de **AnCora** (http://clic.ub.edu/corpus/es/ancora) y **WikiNER**.\n",
        "\n",
        "\n",
        "* Estos dos modelos de pequeño y mediano tamaño los podemos encontrar en la web de ***spaCy*** (https://spacy.io/models/es) y son los siguiente:\n",
        "    - es_core_news_md (93 MiB)\n",
        "    - es_core_news_sm (35 MiB)\n",
        "\n",
        "\n",
        "* ***spaCy*** hace uso de estos modelos y tienen que ser descargados, para ello debemos de abrir un terminal en python y ejecutar lo siguiente para descargar el modelo en Español (*NOTA: los que uséis conda, tener activado el entorno*).\n",
        "\n",
        "\n",
        "```\n",
        ">> python3 -m spacy download es\n",
        "```\n",
        "\n",
        "\n",
        "<img src=\"./imgs/005_spacy_es_download.png\" style=\"width: 500px;\"/>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK-JbiWvyZNm",
        "outputId": "c9f60c19-96e3-4a89-dc89-c733c6a4c586"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vlK5jvusyc6f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r86XXKvtniar"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "# spaCy - Arquitectura:\n",
        "\n",
        "* ***spaCy*** utiliza dos tipos de estructuras (objetos) llamados **Doc** y **Vocab**:\n",
        "<span></span><br><br>\n",
        "    - ***Doc***: Este objeto esta formado por una secuencia de Tokens (objetos de la clase ***Token***).\n",
        "<span></span><br><br>\n",
        "    - ***Vocab***: Este objeto posee un conjunto de Look-up tables (tablas de consulta) que hacen que la información común esté disponible en todos los documentos (Lemas, Stop Words, PoS, etc.).\n",
        "\n",
        "<img src=\"./imgs/006_spacy_architecture.png\" style=\"width: 600px;\"/>\n",
        "\n",
        "\n",
        "* Una forma sencilla de trabajar con ***spaCy*** es:\n",
        "    1. Cargar un modelo de lenguaje (por ejemplo el Español)\n",
        "    2. Dado un texto plano, crear un objeto de la clase \"Doc\" y pasarle el texto plano. El texto ya quedará tokenizado dentro del objeto \"Doc\".\n",
        "    3. Trabajar sobre las palabras del documento.\n",
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "\n",
        "# Ejemplos con spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iImHEZlWyfpo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI-oGZbcniar"
      },
      "source": [
        "## -Tokenización\n",
        "\n",
        "\n",
        "* Divide las cadenas de texto del documento en piezas más pequeñas o tokens.\n",
        "\n",
        "\n",
        "* Pasos:\n",
        "    1. Importar la librería.\n",
        "    2. Cargar un modelo de lenguaje (el Español).\n",
        "    3. Crear un documento (de la clase \"Doc\") pasándole un texto plano.\n",
        "    4. El objeto de la clase \"Doc\" ya esta tokenizado por palabras y podemos iterar sobre él."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaUFv2v1zKhM",
        "outputId": "7acb2403-5008-49f7-c1ef-ed53a5d84a89"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: es_core_news_sm in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from es_core_news_sm) (3.1.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.0.12)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.0.10)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (4.66.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.25.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (24.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->es_core_news_sm) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2024.2.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!spacy validate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWdh_ZYXzNOk",
        "outputId": "1e114e89-bc56-40e1-f556-dab530737b4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-25 15:08:57.564749: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-25 15:08:57.564829: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-25 15:08:57.566989: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-25 15:08:57.579646: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-25 15:08:59.275127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
            "\u001b[1m\n",
            "================= Installed pipeline packages (spaCy v3.1.7) =================\u001b[0m\n",
            "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.10/dist-packages/spacy\u001b[0m\n",
            "\n",
            "NAME              SPACY            VERSION                            \n",
            "es_core_news_sm   >=3.1.0,<3.2.0   \u001b[38;5;2m3.1.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "en_core_web_sm    >=3.7.2,<3.8.0   \u001b[38;5;3m3.7.1\u001b[0m   --> 3.1.0     \n",
            "\n",
            "\u001b[1m\n",
            "============================== Install updates ==============================\u001b[0m\n",
            "Use the following commands to update the packages:\n",
            "python -m spacy download en_core_web_sm\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "doc = nlp(\"Las multas de transito en la Ciudad de Buenos Aires son onerosas\")\n",
        "print('Tipo de dato: ' + str(type(doc)))\n",
        "print([w.text for w in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcEfGNzDy66S",
        "outputId": "84f52ffc-29be-4deb-e156-d81db30f059d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de dato: <class 'spacy.tokens.doc.Doc'>\n",
            "['Las', 'multas', 'de', 'transito', 'en', 'la', 'Ciudad', 'de', 'Buenos', 'Aires', 'son', 'onerosas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W2E97zidy-xy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg4AhUqJnias"
      },
      "source": [
        "## -Segmentación\n",
        "\n",
        "\n",
        "* La ***segmentación*** divide las cadenas de texto en frases o párrafos.\n",
        "\n",
        "\n",
        "* Para la segmentación en spaCy hay que usar un componente llamado \"**sentencier**\" que divide los textos por simbolos como puntos, interrogantes, etc."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.pipeline import Sentencizer\n",
        "sentencizer = Sentencizer()\n",
        "doc = nlp(\"Frase numero 1. Frase número 2? Frase 3\")\n",
        "print([s.text for s in doc.sents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDqXMIGRzEIL",
        "outputId": "0b61836a-55d0-4686-92b3-73fda75e07c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Frase numero 1.', 'Frase número 2?', 'Frase 3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XAbGg1hpzgqp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oASFOMXwniat"
      },
      "source": [
        "## -Lematización\n",
        "\n",
        "\n",
        "* Proceso lingüístico que sustituye una palabra con forma flexionada (plurales, femeninos, verbos conjugados, etc.) por su lema; es decir, por una palabra válida en el idioma.\n",
        "\n",
        "\n",
        "* ***spaCy*** hace una lematización muy buena en Español.\n",
        "\n",
        "\n",
        "* Los objetos de la clase ***Token*** tienen la propiedad (o atributo) ***lema_*** que nos devuelve el lema del token (o la palabra)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Las multas de transito en la Ciudad de Buenos Aires son onerosas\")\n",
        "for word in doc:\n",
        "    print(word.text + ' - ' + word.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhzBh4COzkY-",
        "outputId": "d23c3f6c-0565-49bf-bd96-8c6923654e85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Las - el\n",
            "multas - multa\n",
            "de - de\n",
            "transito - transito\n",
            "en - en\n",
            "la - el\n",
            "Ciudad - Ciudad\n",
            "de - de\n",
            "Buenos - Buenos\n",
            "Aires - Aires\n",
            "son - ser\n",
            "onerosas - oneroso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ut_r1EanzoXY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb0bWqjJniau"
      },
      "source": [
        "## -Stop words\n",
        "\n",
        "* Son las palabras que no aportan nada al significado de la frase.\n",
        "\n",
        "\n",
        "* spaCy dispone de más de 500 stop words en Español.\n",
        "\n",
        "\n",
        "* Veamos a continuación las Stop Words en Español."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = spacy.lang.es.stop_words.STOP_WORDS\n",
        "print('Número de stop words: ' + str(len(stopwords)))\n",
        "print('Stop words: ' + str(list(stopwords)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-0_71bnzqyf",
        "outputId": "b5eae331-a5d5-42a8-e8a7-c18c63a23421"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de stop words: 551\n",
            "Stop words: ['sabeis', 'podrian', 'te', 'está', 'mencionó', 'eran', 'verdadera', 'podrán', 'tienen', 'de', 'nuestro', 'aquella', 'mas', 'segun', 'proximo', 'casi', 'realizó', 'señaló', 'podriais', 'tus', 'cuántas', 'propias', 'cuantos', 'teneis', 'conseguir', 'mi', 'quiere', 'tras', 'aunque', 'sería', 'aseguró', 'trabajo', 'conseguimos', 'en', 'diferente', 'nos', 'mío', 'poder', 'las', 'ambos', 'trabajas', 'cerca', 'adrede', 'qeu', 'principalmente', 'general', 'parece', 'suyas', 'me', 'intentais', 'sabes', 'pocas', 'solo', 'ex', 'del', 'cuándo', 'ustedes', 'estaba', 'hacer', 'ha', 'estas', 'haceis', 'era', 'quedó', 'esas', 'están', 'manifestó', 'sois', 'dijeron', 'tambien', 'buenas', 'mientras', 'sino', 'cuánto', 'tenía', 'ése', 'raras', 'ya', 'qué', 'última', 'valor', 'pudo', 'ningunos', 'vaya', 'más', 'estaban', 'algunas', 'uno', 'aquélla', 'buen', 'cuanto', 'cuales', 'todos', 'yo', 'gran', 'siguiente', 'tuyos', 'propio', 'realizado', 'aproximadamente', 'trabajan', 'estuvo', 'grandes', 'cierto', 'alli', 'lleva', 'éstas', 'luego', 'sus', 'usar', 'vuestras', 'podrá', 'será', 'van', 'todavía', 'despues', 'tuvo', 'aquello', 'entonces', 'dieron', 'usamos', 'peor', 'dia', 'posible', 'tal', 'trabajamos', 'hay', 'medio', 'hace', 'embargo', 'voy', 'pues', 'pronto', 'estar', 'ejemplo', 'tuyas', 'podría', 'haya', 'hizo', 'usa', 'no', 'dio', 'ésas', 'esos', 'si', 'durante', 'haber', 'podriamos', 'sido', 'unas', 'arriba', 'claro', 'nosotras', 'ser', 'dan', 'empleas', 'manera', 'consigue', 'donde', 'éste', 'decir', 'encuentra', 'mías', 'ir', 'hacemos', 'mis', 'tú', 'supuesto', 'antes', 'todavia', 'mio', 'expresó', 'hubo', 'alguna', 'puede', 'misma', 'temprano', 'tiene', 'cuáles', 'mal', 'mediante', 'aquéllas', 'horas', 'cuánta', 'sean', 'nuevo', 'contra', 'trabajar', 'pais', 'vuestra', 'cinco', 'largo', 'podrían', 'dijo', 'consigo', 'sólo', 'trabaja', 'unos', 'hemos', 'ver', 'intentamos', 'ésos', 'dicho', 'empleais', 'tenga', 'habla', 'vez', 'poca', 'por', 'partir', 'le', 'sin', 'dejó', 'nuevas', 'intentas', 'tuya', 'afirmó', 'diferentes', 'suya', 'sola', 'debe', 'pasada', 'va', 'veces', 'entre', 'mios', 'muchas', 'una', 'final', 'debajo', 'otras', 'siendo', 'cómo', 'apenas', 'ello', 'serán', 'al', 'ellos', 'anterior', 'ayer', 'quizás', 'uso', 'éstos', 'también', 'hasta', 'que', 'cuenta', 'sobre', 'quiénes', 'saber', 'próximo', 'cualquier', 'ningún', 'nuestra', 'considera', 'quizas', 'primeros', 'les', 'tiempo', 'acuerdo', 'mismos', 'nadie', 'primera', 'su', 'deprisa', 'cuando', 'además', 'ella', 'despacio', 'allí', 'demás', 'lado', 'cada', 'adelante', 'gueno', 'llegó', 'hablan', 'primero', 'nueva', 'mucha', 'ante', 'mismas', 'bueno', 'cierta', 'mayor', 'ciertas', 'un', 'nada', 'nunca', 'sí', 'intentar', 'conmigo', 'emplean', 'dónde', 'igual', 'bastante', 'cuatro', 'vosotras', 'haciendo', 'suyo', 'detras', 'sabemos', 'fueron', 'vamos', 'excepto', 'alguno', 'quiza', 'la', 'comentó', 'nuevos', 'consiguen', 'bien', 'bajo', 'indicó', 'vais', 'estados', 'estos', 'aquéllos', 'mí', 'podeis', 'tanto', 'nosotros', 'estan', 'he', 'estoy', 'propios', 'tengo', 'ciertos', 'antano', 'mia', 'pueden', 'repente', 'sea', 'lugar', 'según', 'aquí', 'alrededor', 'ninguna', 'parte', 'tener', 'antaño', 'asi', 'fin', 'agregó', 'solos', 'toda', 'usais', 'muchos', 'incluso', 'aquellos', 'somos', 'sé', 'otra', 'eso', 'aun', 'junto', 'día', 'son', 'ellas', 'demasiado', 'aqui', 'había', 'como', 'menos', 'ahi', 'cosas', 'cuantas', 'lejos', 'ampleamos', 'después', 'varias', 'menudo', 'se', 'lo', 'respecto', 'os', 'poco', 'quién', 'habían', 'estado', 'tu', 'ningunas', 'últimas', 'ahora', 'dado', 'cuanta', 'tercera', 'trabajais', 'creo', 'debido', 'podemos', 'hago', 'paìs', 'pocos', 'esta', 'buenos', 'es', 'mía', 'muy', 'ésta', 'conocer', 'esto', 'ninguno', 'total', 'fue', 'dentro', 'han', 'solamente', 'tendrán', 'puedo', 'algún', 'fuimos', 'último', 'explicó', 'míos', 'seis', 'hacen', 'intento', 'mucho', 'solas', 'delante', 'eras', 'soyos', 'cuántos', 'consigues', 'dicen', 'hacerlo', 'quien', 'aún', 'fuera', 'ti', 'usted', 'verdadero', 'aquel', 'nuestros', 'llevar', 'mias', 'tres', 'fui', 'encima', 'verdad', 'para', 'consideró', 'próximos', 'algo', 'intentan', 'propia', 'mejor', 'estamos', 'enfrente', 'podria', 'varios', 'los', 'existen', 'ni', 'añadió', 'sabe', 'segunda', 'podrias', 'él', 'habia', 'vosotros', 'aquellas', 'vuestros', 'informó', 'quienes', 'este', 'nuestras', 'tampoco', 'tendrá', 'enseguida', 'da', 'mismo', 'tenido', 'primer', 'ese', 'algunos', 'quizá', 'realizar', 'pesar', 'estais', 'soy', 'tan', 'otros', 'pueda', 'hacia', 'hecho', 'arribaabajo', 'sera', 'trata', 'haces', 'dice', 'informo', 'sigue', 'queremos', 'momento', 'atras', 'pero', 'ésa', 'salvo', 'eramos', 'habrá', 'breve', 'cuál', 'saben', 'tuyo', 'el', 'modo', 'detrás', 'contigo', 'dias', 'actualmente', 'ahí', 'ultimo', 'así', 'emplear', 'segundo', 'intenta', 'todo', 'poner', 'esa', 'aquél', 'con', 'desde', 'dos', 'cual', 'últimos', 'dar', 'ademas', 'deben', 'través', 'usan', 'eres', 'porque', 'siete', 'buena', 'vuestro', 'tarde', 'usas', 'pasado', 'estará', 'hicieron', 'otro', 'ocho', 'hoy', 'días', 'existe', 'empleo', 'tenemos', 'todas', 'siempre']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_RAqnZI7ztxB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N88P8anzniau"
      },
      "source": [
        "* Los objetos de la clase ***Token*** tienen la propiedad ***is_stop*** que devuelve en Boolean indicando si el token es o no una stop word; es decir, si el ***Token*** (o palabra) esta dentro de la lista antes mostrada.\n",
        "\n",
        "\n",
        "* Veamos a continuación como obtener las stop words de una frase con spaCy:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Las multas de transito en la Ciudad de Buenos Aires son onerosas\")\n",
        "for word in doc:\n",
        "    if word.is_stop:\n",
        "        print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On3Bsv7Y1oXm",
        "outputId": "bff4720b-46f8-49c5-e0c6-5823d0d5b861"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Las\n",
            "de\n",
            "en\n",
            "la\n",
            "de\n",
            "Buenos\n",
            "son\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YDA5D_0r1tiH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_YXUxyrniau"
      },
      "source": [
        "## -Part of Speech (PoS)\n",
        "\n",
        "* En ***spaCy*** el PoS lo divide en 3 tipos de tags que son:\n",
        "    1. **pos**: etiqueta simple de alto nivel (verbo, nombre, adjetivo, etc).\n",
        "    2. **tag**: etiqueta con más nivel de detalle que el pos.\n",
        "    3. **dep**: dependencia sintáctica para ver la relación entre tokens.\n",
        "\n",
        "\n",
        "* Estos 3 tipos son propiedades de la clase ***Token***:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Las multas de transito en la Ciudad de Buenos Aires son onerosas\")\n",
        "pos = [[tk.text, tk.pos_, tk.tag_, tk.dep_] for tk in doc]\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(pos, columns=[\"Text\", \"PoS\", \"TAG\", \"DEP\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "_rtG653u1wQ_",
        "outputId": "9ad73402-d08e-49e1-a835-67d0cc1046ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Text    PoS    TAG    DEP\n",
              "0        Las    DET    DET    det\n",
              "1     multas   NOUN   NOUN  nsubj\n",
              "2         de    ADP    ADP   case\n",
              "3   transito   NOUN   NOUN   nmod\n",
              "4         en    ADP    ADP   case\n",
              "5         la    DET    DET    det\n",
              "6     Ciudad  PROPN  PROPN   nmod\n",
              "7         de    ADP    ADP   case\n",
              "8     Buenos  PROPN  PROPN   flat\n",
              "9      Aires  PROPN  PROPN   flat\n",
              "10       son    AUX    AUX    cop\n",
              "11  onerosas    ADJ    ADJ   ROOT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c9fd2f7-5666-466b-8b96-7e594e558d8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>PoS</th>\n",
              "      <th>TAG</th>\n",
              "      <th>DEP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Las</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>multas</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>nsubj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>transito</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>nmod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>en</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>la</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ciudad</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nmod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>de</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Buenos</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>flat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Aires</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>flat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>son</td>\n",
              "      <td>AUX</td>\n",
              "      <td>AUX</td>\n",
              "      <td>cop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>onerosas</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ROOT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c9fd2f7-5666-466b-8b96-7e594e558d8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c9fd2f7-5666-466b-8b96-7e594e558d8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c9fd2f7-5666-466b-8b96-7e594e558d8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cddea4b5-cbdb-4432-a40c-d8486f9a676e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cddea4b5-cbdb-4432-a40c-d8486f9a676e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cddea4b5-cbdb-4432-a40c-d8486f9a676e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"la\",\n          \"Las\",\n          \"son\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PoS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"DET\",\n          \"NOUN\",\n          \"ADJ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TAG\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"DET\",\n          \"NOUN\",\n          \"ADJ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DEP\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"det\",\n          \"nsubj\",\n          \"cop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ygg3peZ81zJ4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPlEfIu4niav"
      },
      "source": [
        "## -Named Entity Recognition (NER)\n",
        "\n",
        "* Named Entity Recognition (Reconocimiento de Entidades Nombradas) es una tarea de extracción de información que busca localizar y clasificar en categorías predefinidas, como personas, organizaciones, lugares, expresiones de tiempo y cantidades, las entidades nombradas encontradas en un texto."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Leo Messi jugador del FC Barcelona marco 34 en La Liga 2017-18\")\n",
        "for entity in doc.ents:\n",
        "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7WK__y424I5",
        "outputId": "5f53555d-efc2-4102-9c64-b455605f7532"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leo Messi - PER - Named person or family.\n",
            "FC Barcelona - ORG - Companies, agencies, institutions, etc.\n",
            "La Liga 2017-18 - MISC - Miscellaneous entities, e.g. events, nationalities, products or works of art\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s4np0lTE27HR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66zbwHAoniav"
      },
      "source": [
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "# -Resumen\n",
        "\n",
        "* Una vez creado el documento a partir del texto plano, tenemos ese texto tokenizado.\n",
        "\n",
        "\n",
        "* Los objetos de la clase ***Token*** tienen una serie de propiedades que permiten obtener mucha información relativa a los tokens (o palabras).\n",
        "\n",
        "\n",
        "* Haciendo un resumen de lo visto anteriormente podemos obtener la siguiente información de las palabras de un texto:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "doc = nlp(\"Las multas de transito en la Ciudad de Buenos Aires son onerosas\")\n",
        "\n",
        "result = [[tk.text, tk.lemma_, tk.pos_, tk.tag_, tk.dep_, tk.shape_, tk.is_alpha, tk.is_stop] for tk in doc]\n",
        "pd.DataFrame(result, columns=[\"Text\", \"Lema\", \"PoS\", \"TAG\", \"DEP\", \"Shape\", \"Alpha\", \"is Stop word\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "2KATT7aP3AFR",
        "outputId": "af316374-6e8c-40cf-95ce-48cd9a3dd360"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Text      Lema    PoS    TAG    DEP  Shape  Alpha  is Stop word\n",
              "0        Las        el    DET    DET    det    Xxx   True          True\n",
              "1     multas     multa   NOUN   NOUN  nsubj   xxxx   True         False\n",
              "2         de        de    ADP    ADP   case     xx   True          True\n",
              "3   transito  transito   NOUN   NOUN   nmod   xxxx   True         False\n",
              "4         en        en    ADP    ADP   case     xx   True          True\n",
              "5         la        el    DET    DET    det     xx   True          True\n",
              "6     Ciudad    Ciudad  PROPN  PROPN   nmod  Xxxxx   True         False\n",
              "7         de        de    ADP    ADP   case     xx   True          True\n",
              "8     Buenos    Buenos  PROPN  PROPN   flat  Xxxxx   True          True\n",
              "9      Aires     Aires  PROPN  PROPN   flat  Xxxxx   True         False\n",
              "10       son       ser    AUX    AUX    cop    xxx   True          True\n",
              "11  onerosas   oneroso    ADJ    ADJ   ROOT   xxxx   True         False"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0569d63-d584-40d3-8b99-bdd760a352e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Lema</th>\n",
              "      <th>PoS</th>\n",
              "      <th>TAG</th>\n",
              "      <th>DEP</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>is Stop word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Las</td>\n",
              "      <td>el</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "      <td>Xxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>multas</td>\n",
              "      <td>multa</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>nsubj</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>de</td>\n",
              "      <td>de</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "      <td>xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>transito</td>\n",
              "      <td>transito</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>nmod</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "      <td>xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>la</td>\n",
              "      <td>el</td>\n",
              "      <td>DET</td>\n",
              "      <td>DET</td>\n",
              "      <td>det</td>\n",
              "      <td>xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ciudad</td>\n",
              "      <td>Ciudad</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>nmod</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>de</td>\n",
              "      <td>de</td>\n",
              "      <td>ADP</td>\n",
              "      <td>ADP</td>\n",
              "      <td>case</td>\n",
              "      <td>xx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Buenos</td>\n",
              "      <td>Buenos</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>flat</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Aires</td>\n",
              "      <td>Aires</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>flat</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>son</td>\n",
              "      <td>ser</td>\n",
              "      <td>AUX</td>\n",
              "      <td>AUX</td>\n",
              "      <td>cop</td>\n",
              "      <td>xxx</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>onerosas</td>\n",
              "      <td>oneroso</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0569d63-d584-40d3-8b99-bdd760a352e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0569d63-d584-40d3-8b99-bdd760a352e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0569d63-d584-40d3-8b99-bdd760a352e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e2e86bc-b7c2-45f9-a559-532ae85efb26\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e2e86bc-b7c2-45f9-a559-532ae85efb26')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e2e86bc-b7c2-45f9-a559-532ae85efb26 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"la\",\n          \"Las\",\n          \"son\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lema\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"ser\",\n          \"multa\",\n          \"Ciudad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PoS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"DET\",\n          \"NOUN\",\n          \"ADJ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TAG\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"DET\",\n          \"NOUN\",\n          \"ADJ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DEP\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"det\",\n          \"nsubj\",\n          \"cop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shape\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"xxxx\",\n          \"xxx\",\n          \"xx\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alpha\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is Stop word\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW2jzPkQwuGH"
      },
      "source": [
        "# 04 - Preprocesamiento de textos (Normalización)\n",
        "\n",
        "* Antes de procesar los texto con cualquier algoritmo de aprendizaje automático (supervisado o no supervisado) es necesario realizar un preporcesamiento con el objetivo de limpiar, normalizar y estructurar el texto.\n",
        "\n",
        "\n",
        "* Para ello se propone el siguiente framework:\n",
        "\n",
        "\n",
        "<img src=\"./imgs/007_framework_preprocesamiento_texto.png\" style=\"width: 500px;\"/>\n",
        "\n",
        "\n",
        "* Los pasos propuestos en este framework pueden abordarse en el orden que se quiera e incluso alguno de estas etapas no sería necesario realizarse en función de como tengamos los textos.\n",
        "\n",
        "\n",
        "* Definamos a continuación lo que hay que realizar en cada uno de estos pasos:\n",
        "\n",
        "\n",
        "1.- ***Eliminación de ruido***:\n",
        "\n",
        "   * Este paso tiene como objetivo eliminar todos aquellos símbolos o caracteres que no aportan nada en el significado de las frases (ojo no confundir con las stop-words), como por ejemplo etiquetas HTML (para el caso del scraping), parseos de XML, JSON, etc.\n",
        "    \n",
        "2.- ***Tokenización***:\n",
        "   * Este paso tiene como objetivo dividir las cadenas de texto del documento en piezas más pequeñas o tokens.\n",
        "   * Aunque la tokenización es el proceso de dividir grandes cadenas de texto en cadenas más pequeñas, se suele diferenciar la:\n",
        "       * ***Segmentation***: Tarea de dividir grandes cadenas de texto en piezas más pequeñas como oraciones o párrafos.\n",
        "       * ***Tokenization***: Tarea de dividir grandes cadenas de texto solo y exclusivamente en palabras.\n",
        "    \n",
        "3.- ***Normalización***:\n",
        "\n",
        "   * La normalización es una tarea que tiene como objetivo poner todo el texto en igualdad de condiciones:\n",
        "        * Convertir todo el texto en mayúscula o minúsculas\n",
        "        * Eliminar, puntos, comas, comillas, etc.\n",
        "        * Convertir los números a su equivalente a palabras\n",
        "        * Quitar las Stop-words\n",
        "        * etc.\n",
        "        \n",
        "<hr>\n",
        "\n",
        "## Ejemplo de Preprocesamiento de Texto.\n",
        "\n",
        "\n",
        "* Aunque no hay una norma o guía de como realizar una normalización de texto ya que esta depende del problema a resolver y de la naturaleza del texto, vamos a mostrar a continuación algunas operaciones más o menos comúnes para la tokenización y normalización de los textos.\n",
        "\n",
        "\n",
        "* Si bien este ejemplo esta hecho utilizando la librería de ***spaCy*** (ya que lo vamos a aplicar sobre un texto en Español) puede realizarse tambien con la librería de ***NLTK*** e incluso determinadas funcionalidades de tratamiento de strings lo podemos hacer con otras librerías.\n",
        "\n",
        "\n",
        "* En el siguiente ejemplo vamos a tokenizar y normalizar un texto:\n",
        "    1. Transformar un texto en tokens\n",
        "    2. Eliminar los tokens que son signos (puntuación, exclamación, etc.)\n",
        "    3. Eliminar las palabras que tienen menos de 'N' caracteres\n",
        "    4. Eliminar las palabras que son Stop Words\n",
        "    5. Pasar el texto a minúsculas\n",
        "    6. Lematización\n",
        "    \n",
        "    \n",
        "* **Nota**: *la normalización de texto que se va a codificar a continuación puede codificarse de forma más optimizada sin la necesidad de recorrer tantas veces la lista de tokens. Ya que este es un ejemplo con fines didácticos, este se centra en los conceptos y no en la optimización*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEpHOMCswuGK"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('es_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU2h7hOFwuGL"
      },
      "outputs": [],
      "source": [
        "def get_tokens(text):\n",
        "    \"\"\"\n",
        "    Función que dado un texto devuelve una lista con las palabras del texto no vacias\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [word.text.strip() for word in doc if len(word.text.strip()) > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMnagYi1wuGM"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(words):\n",
        "    \"\"\"\n",
        "    Función que dada una lista de palabras, elimina los signos de puntuación\n",
        "    \"\"\"\n",
        "    doc = spacy.tokens.doc.Doc(nlp.vocab, words=words)\n",
        "    return [word.text for word in doc if not word.is_punct]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhddDB5DwuGM"
      },
      "outputs": [],
      "source": [
        "def remove_short_words(words, num_chars):\n",
        "    \"\"\"\n",
        "    Función que dada una lista de palabras y un número mínimo de caracteres que tienen que tener\n",
        "    las palabras, elimina todas las palabras que tengan menos caracteres que los indicados\n",
        "    \"\"\"\n",
        "    return [word for word in words if len(word) > num_chars]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_i3el03wuGM"
      },
      "outputs": [],
      "source": [
        "def remove_stop_words(words):\n",
        "    \"\"\"\n",
        "    Función que dada una lista de palabras, elimina las Stop Words\n",
        "    \"\"\"\n",
        "    doc = nlp(\" \".join(words))\n",
        "    return [word.text for word in doc if not word.is_stop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGHtFi0iwuGM"
      },
      "outputs": [],
      "source": [
        "def to_lowercase(words):\n",
        "    \"\"\"\n",
        "    Función que dada una lista de palabras, las transforma a minúsculas\n",
        "    \"\"\"\n",
        "    return [word.lower() for word in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzMsh2_vwuGM"
      },
      "outputs": [],
      "source": [
        "def lemmatizer(words):\n",
        "    \"\"\"\n",
        "    Función que dada una lista de palabras, devuelve esa lista con el lema de cada una de esas palabras\n",
        "    \"\"\"\n",
        "    doc = nlp(\" \".join(words))\n",
        "    return [word.lemma_ for word in doc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WRtY6xIwuGM"
      },
      "outputs": [],
      "source": [
        "def normalize(text):\n",
        "    \"\"\"\n",
        "    Dado un texto, devuelve el texto tokenizado y normalizado\n",
        "    \"\"\"\n",
        "    words = get_tokens(text=text)\n",
        "    words = remove_punctuation(words=words)\n",
        "    words = remove_short_words(words=words, num_chars=3)\n",
        "    words = remove_stop_words(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = lemmatizer(words)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72_HXY1iwuGN"
      },
      "source": [
        "#### Pasamos a tokenizar y normalizar el siguiente texto usando la función de normalización realizada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TKhVxM2wuGN",
        "outputId": "4812cc98-ddd3-48ea-d117-9faaf107efb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['fernar', 'alonso', 'vuelto', 'sacar', 'petróleo', 'carrero', 'salir', 'acabar', 'premio', 'coronado', 'adelantar', 'pista', 'sebastiar', 'vettel', 'líder', 'mundial', 'querido', 'sacar', 'pecho', 'coche', 'tocado', 'problema', 'dirección', 'claro', 'desventajar', 'perder', 'recta', 'imposible', 'adelantar él', 'conseguir', 'pillar él', 'aber', 'pensar', 'curva', 'poder', 'intentar', 'salir', 'contento', 'séptir', 'sumar', 'punto', 'carrera', 'señalado']\n"
          ]
        }
      ],
      "source": [
        "raw = \"\"\"Fernando Alonso ha vuelto a sacar petróleo de la carrera, saliendo 13º y acabando 7º un\n",
        "         gran premio que ha coronado adelantando en pista a Sebastian Vettel, líder del Mundial.\n",
        "         Aunque no ha querido sacar pecho por ello: \"Su coche estaba tocado, tenía problemas de dirección,\n",
        "         estaban en clara desventaja e iba perdiendo cada vez más, vi que en la recta iba a ser imposible\n",
        "         adelantarle incluso con el DRS no conseguía pillarle así que como se abría mucho pensé que en la\n",
        "         primera curva que pudiera lo intentaba por dentro y a la primera salió bien y creo que hay que\n",
        "         estar contentos, séptimos otra vez, sumando puntos en las tres carreras\", ha señalado.\"\"\"\n",
        "print(normalize(raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjS7gDdmwuGN"
      },
      "source": [
        "#### En este ejemplo podemos ver como reducimos las palabras (tokens) del texto original, quedandonos con lo importante y normalizado\n",
        "#### Pasamos de 128 tokens del texto original a 44 tokens tras la normalización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceQHiNXNwuGO",
        "outputId": "0ddb6978-e0e7-4c23-876e-63b7f9161c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de tokens del texto original: 128\n",
            "Número de tokens distintos del texto original: 91\n",
            "Número de tokens tras la normalización: 43\n",
            "Número de tokens distintos tras la normalización: 41\n"
          ]
        }
      ],
      "source": [
        "print('Número de tokens del texto original: ' + str(len(get_tokens(raw))))\n",
        "print('Número de tokens distintos del texto original: ' + str(len(set(get_tokens(raw)))))\n",
        "print('Número de tokens tras la normalización: ' + str(len(normalize(raw))))\n",
        "print('Número de tokens distintos tras la normalización: ' + str(len(set(normalize(raw)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve6_LrJ9wuGO"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "# Bonus Track - Tratamiento de Strings\n",
        "\n",
        "\n",
        "## Codificación de Caracteres (Unicode)\n",
        "\n",
        "\n",
        "* Uno de los quebraderos de cabeza que se tiene a la hora de trabajar con python (sobre todo con python 2.X) es el tema de la ***codificación de los textos (Strings)***.\n",
        "\n",
        "\n",
        "* En un principio los ordenadores se diseñaron para utilizar el alfabeto ingles (que entre otras cosas no tiene ni acentos ni letras como la \"ñ\" para el Español) y por ese motivo se definió la codificación ***ASCII*** (***A***merican ***S***tandard ***C***ode for ***I***nformation ***I***nterchange) definido con 128 caracteres (7 bits para representar los 2<sup>7</sup> = 128 caracteres).\n",
        "\n",
        "\n",
        "<img src=\"./imgs/019_ASCII.png\" style=\"width: 500px;\"/>\n",
        "\n",
        "\n",
        "* Dado que en el resto de lenguas en el mundo hay muchos más caracteres, se definió una nueva codificación de caracteres denominada como ***UNICODE*** que representa alrededor de 110.000 caracteres.\n",
        "\n",
        "\n",
        "* Por tanto para poder trabajar con Strings (codificados de diferente manera) se debería hacer lo siguiente:\n",
        "\n",
        "    1. ¿Cual es la codificación de mi fichero original?\n",
        "    2. **Decode**: Paso el string de mi fichero a Unicode (cambio de codificación)\n",
        "    3. Realizo las operaciones que sean necesarias sobre los strings codificados en **Unicode**\n",
        "    4. **Encode**: Escribo de **Unicode** a otra **codificación** el string con el que he trabajado\n",
        "\n",
        "<img src=\"./imgs/008_Unicode_Decode_Encode.png\" style=\"width: 500px;\"/>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "\n",
        "## Operaciones con Strings\n",
        "\n",
        "\n",
        "* Muchas veces tenemos que realizar operaciones de transforación sobre palabras o textos. A continuación se muestran algunas de las funciones más útiles para trabajar con strings:\n",
        "\n",
        "|Nombre Función|Funcionalidad|\n",
        "|---|---|\n",
        "|[s.find(t)](#M1)|index of first instance of string t inside s (-1 if not found)|\n",
        "|[s.rfind(t)](#M2)|index of last instance of string t inside s (-1 if not found)|\n",
        "|[s.index(t)](#M3)|like s.find(t) except it raises ValueError if not found|\n",
        "|[s.rindex(t)](#M4)|like s.rfind(t) except it raises ValueError if not found|\n",
        "|[s.join(text)](#M5)|combine the words of the text into a string using s as the glue|\n",
        "|[s.split(t)](#M6)|split s into a list wherever a t is found (whitespace by default)|\n",
        "|[s.splitlines()](#M7)|split s into a list of strings, one per line|\n",
        "|[s.lower()](#M8)|a lowercased version of the string s|\n",
        "|[s.upper()](#M9)|an uppercased version of the string s|\n",
        "|[s.title()](#M10)|a titlecased version of the string s|\n",
        "|[s.strip()](#M11)|a copy of s without leading or trailing whitespace|\n",
        "|[s.replace(t, u)](#M12)|replace instances of t with u inside s|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwVjsJsnwuGO"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M1\">s.find(t)</a>\n",
        "\n",
        "\n",
        "* Encuentra la posición (indice) del string que se pasa como parámetro empezando a contar desde la izquierda.\n",
        "\n",
        "\n",
        "* Si no encuentra el string, devuelve valor -1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiKsHQLbwuGO",
        "outputId": "a3ad8182-5d15-4a18-c5d4-b15e7783f8ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = 'Ricardo Moya'\n",
        "s.find('Moya')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOFpa-b_wuGO",
        "outputId": "23e75cfb-4c50-4108-e406-c7af59194f65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.find('a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja1NuAFFwuGO",
        "outputId": "b856cc3f-569b-43e5-974a-932d81627d3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.find('e')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW_d86WgwuGP"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M2\">s.rfind(t)</a>\n",
        "\n",
        "\n",
        "* Hace lo mismo que \"s.find(t)\" pero empezando a contar desde la derecha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xhiuq2z3wuGP",
        "outputId": "6576caeb-b73a-4e85-e95a-a4ca6122f759"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.rfind('a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHEcjddlwuGP",
        "outputId": "8ffd618b-b1b6-4bba-8906-f56ad7012ca7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.rfind('Moya')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZbnvBHmwuGP"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M3\">s.index(t)</a>\n",
        "\n",
        "\n",
        "* Hace lo mismo que \"s.find(t)\", con la única diferencia que devuelve un error (en vez de un -1) si no encuentra el string que se pasa como parámetro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xM1_14nwuGP",
        "outputId": "c401718f-e63d-47c3-e002-c6845502cd07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.index('Moya')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaLUEtfpwuGP",
        "outputId": "4f7a0a90-cc91-4b45-8bad-d214d08cc6d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.index('a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHhkBBqLwuGP",
        "outputId": "68b0f10e-23f9-46fe-9ba1-1fe5908e28a7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "substring not found",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19980/3499166528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'e'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Devuelve un error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m: substring not found"
          ]
        }
      ],
      "source": [
        "s.index('e') # Devuelve un error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t13ou6SwuGP"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M4\">s.rindex(t)\n",
        "\n",
        "\n",
        "* Hace lo mismo que \"s.index(t)\" pero empezando a contar desde la derecha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHndUaIfwuGR",
        "outputId": "48325508-92cf-47a9-9313-5f15e921482b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.rindex('a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ3Kt4dpwuGR",
        "outputId": "72c8a258-a135-4d0c-d517-6b5c8de9799f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.rfind('Moya')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MympgiXnwuGR"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M5\">separador.join(text)</a>\n",
        "\n",
        "\n",
        "* Une cada letra del string que se le pasa como parámetro con el separador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE6SX-r4wuGR",
        "outputId": "f49f9cc9-0d5a-4762-a64e-d72b7d4f1d3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'R-i-c-a-r-d-o- -M-o-y-a'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'-'.join(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXI__2ChwuGR"
      },
      "source": [
        "* Esta es una función muy utilizada para formar una cadena de texto con separador (por ejemplo un espacio en blanco) a partir de una lista o tupla:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggxQT63QwuGR",
        "outputId": "db54b913-911b-45ec-d504-87b0faf70416"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Un radar multa a Mariano Rajoy por caminar demasiado rapido'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lista = [\"Un\", \"radar\", \"multa\", \"a\", \"Mariano\", \"Rajoy\", \"por\", \"caminar\", \"demasiado\", \"rapido\"]\n",
        "' '.join(lista)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieN15oupwuGS"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M6\">s.split(t)</a>\n",
        "\n",
        "\n",
        "* Divide el String \"***s***\" en una lista siempre que encuentre un separador \"***t***\".\n",
        "\n",
        "\n",
        "* Por defecto el separador es el espacio en blanco."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP_bTORZwuGS",
        "outputId": "ff8d3b61-e318-45f0-f659-b5f7419a4f19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Un',\n",
              " 'radar',\n",
              " 'multa',\n",
              " 'a',\n",
              " 'Mariano',\n",
              " 'Rajoy',\n",
              " 'por',\n",
              " 'caminar',\n",
              " 'demasiado',\n",
              " 'rapido']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texto = \"Un radar multa a Mariano Rajoy por caminar demasiado rapido\"\n",
        "texto.split(' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFInaAhGwuGS"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M7\">s.splitlines()</a>\n",
        "\n",
        "\n",
        "* Divide un String \"***s***\" en una lista siempre que encuentre un salto de linea (\\n)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dq-zAedwuGS",
        "outputId": "d1164426-d1d1-4bdf-fdfa-be63f2da6f5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' linea 1', 'linea 2', 'linea 3']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texto = \"\"\" linea 1\\nlinea 2\n",
        "linea 3\n",
        "\"\"\"\n",
        "\n",
        "texto.splitlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt1KpfXLwuGS"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M8\">s.lower()</a>\n",
        "\n",
        "\n",
        "* Transforma un String \"***s***\" a minúsculas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D44cWNlowuGS",
        "outputId": "7f4f1176-2806-4999-9e59-7d85acc01256"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'minusculas'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = \"MiNuSCuLaS\"\n",
        "s.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGco45TWwuGS"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M9\">s.upper()</a>\n",
        "\n",
        "\n",
        "* Transforma un String \"***s***\" a mayúsculas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGlthXqZwuGW",
        "outputId": "f16b52ac-b8b0-44e0-d6c3-669a6370af54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'MAYUSCULAS'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = \"mAyUscUlAs\"\n",
        "s.upper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kQVAVpjwuGW"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M10\">s.title()</a>\n",
        "\n",
        "\n",
        "* Transforma el String \"***s***\" en formato título; es decir, pone la primera letra de cada palabra de String en mayúsculas y el resto en minúsculas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_VUrxsIwuGW",
        "outputId": "e5e7a49e-0f82-47ad-8545-29e67ed56877"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ricardo Moya'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = \"rIcArdO mOyA\"\n",
        "s.title()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTKc0RqfwuGW"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M11\">s.strip()</a>\n",
        "\n",
        "\n",
        "* Elimina los espacios en blanco y caracteres espaciales que hay tanto a la decrecha como a la izquierda del String \"***s***\".\n",
        "\n",
        "\n",
        "* Existen también las variantes de:\n",
        "    - s.rstrip(): Elimina los espacios en blanco y caracteres espaciales que hay a la derecha del string.\n",
        "    - s.lstrip(): Elimina los espacios en blanco y caracteres espaciales que hay a la izquierda del string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh9SdMrJwuGW",
        "outputId": "103d864c-f7ca-4a9a-f3b6-521021a433ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ricardo Moya'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = \"   \\tRicardo Moya  \\t  \"\n",
        "s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xtm9e7ILwuGX",
        "outputId": "7b339ceb-1fd4-4cbd-9270-303e2285e9f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'   \\tRicardo Moya'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.rstrip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afj8tjiMwuGX",
        "outputId": "ae1ce921-009f-477c-8b41-0f446f0c7817"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ricardo Moya  \\t  '"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.lstrip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flUuK4jswuGX"
      },
      "source": [
        "<hr>\n",
        "\n",
        "\n",
        "### <a name=\"M12\">s.replace(t, u)</a>\n",
        "\n",
        "\n",
        "* Dado un String \"***s***\" sustituye cada aparición \"***t***\" por \"***u***\", pasandose \"***t***\" y \"***u***\" como parámetro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr0enS0CwuGX",
        "outputId": "d01f70be-da3c-4589-bcb9-06182914653d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Un radar multa a un tio por caminar demasiado rapido'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = \"Un radar multa a Mariano Rajoy por caminar demasiado rapido\"\n",
        "s.replace(\"Mariano Rajoy\", \"un tio\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}