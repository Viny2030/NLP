{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viny2030/NLP/blob/main/chapter_3_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext Cython"
      ],
      "metadata": {
        "id": "TlZrVuO-YNJ1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiTNGJJUYGzS",
        "outputId": "89fc73ee-63e6-46a0-ad91-04b156ac3538"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (3.0.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6DUUokjbVIh"
      },
      "source": [
        "**Exercise 1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UbD2l7tAbVIi",
        "outputId": "36e99300-657a-42f5-ae0c-67457a29603e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'colourless'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "s = 'colorless'\n",
        "s = s[:4] + 'u' + s[4:]\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRyHjEVtbVIk"
      },
      "source": [
        "**Exercise 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "meMisp_LbVIk",
        "outputId": "c0ea9a2f-2780-4189-f743-e9979a6e62ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dish'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "'dishes'[:-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DDBLieSFbVIl",
        "outputId": "5a76c31f-4ddd-4109-c868-9810b3bd3fb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'run'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "'running'[:-4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CyPONt3ybVIl",
        "outputId": "80edbc0d-561c-4aba-d533-ba9138b18e9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "'nationality'[:-5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8I0IQ4ChbVIm",
        "outputId": "5715bad8-0dd2-47e2-b315-7fa48fbd2b31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'do'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "'undo'[2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hhi2yWNzbVIm",
        "outputId": "b49f2ea0-d262-4e5b-bcf5-b8db6ca6f648"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'heat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "'preheat'[3:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "0O6kgZi9bVIm"
      },
      "source": [
        "**Exercise 3)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4FKy7sJEbVIm"
      },
      "outputs": [],
      "source": [
        "##'in'[-5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18lUCzW4bVIn"
      },
      "source": [
        "**Exercise 4)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HDR3IYatbVIn",
        "outputId": "16464c2d-3cec-4c13-9245-b205a1aa7d1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pto'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "monty = 'Monty Python'\n",
        "monty[6:11:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PoFYQCK0bVIn",
        "outputId": "348faff1-8048-4659-bcd6-7cca4b0cd47e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'otP'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "monty[10:5:-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TaQKwPNtbVIo",
        "outputId": "369478b6-c59d-4195-eea2-7eae953db849"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "monty[1:10:-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hZapNex5bVIo",
        "outputId": "c0aacbc2-dde7-4114-add3-77518b89ed89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'onty '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "monty[1:6:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol6kBedHbVIo"
      },
      "source": [
        "**Exercise 5)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5EC76qiLbVIo",
        "outputId": "5c724b4d-3755-41d3-ef90-39b980bad48e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nohtyP ytnoM'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "monty[::-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWj1bcZ3bVIo"
      },
      "source": [
        "**Exercise 6)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "48kaADTMbVIp"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "import nltk, re, pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DteMVMBEbVIp",
        "outputId": "51d85e5a-6834-45f9-e103-aa3d81391173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Monty} {Python}\n"
          ]
        }
      ],
      "source": [
        "# a - one or more letters\n",
        "nltk.re_show(r'[a-zA-Z]+', monty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FaHMe2LbVIp",
        "outputId": "e5958b13-6f03-4cdd-b935-8efa8b958194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Monty} {Python}\n",
            "{A} very {Intersting}3 example\n"
          ]
        }
      ],
      "source": [
        "# b - one capital letter and zero or more lowercase letters\n",
        "nltk.re_show(r'[A-Z][a-z]*', monty)\n",
        "nltk.re_show(r'[A-Z][a-z]*', 'A very Intersting3 example')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtuAXaBJbVIp",
        "outputId": "55b30938-a3e2-4374-e2f9-b8e55f4edc6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "two {pout}ing party {pet}s - {pt}\n"
          ]
        }
      ],
      "source": [
        "# c - a word starting with p, followed by 0 up to 2 vowels and ending with p\n",
        "nltk.re_show(r'p[aeiou]{,2}t', 'two pouting party pets - pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHBvSemebVIp",
        "outputId": "a08d460c-c0b9-4b11-edea-e0f2157026b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This should match {23} as well as {1.093} and {999.9}\n"
          ]
        }
      ],
      "source": [
        "# d - integer or decimal number\n",
        "nltk.re_show(r'\\d+(\\.\\d+)?', 'This should match 23 as well as 1.093 and 999.9')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCyfWw2PbVIq",
        "outputId": "72126533-fd7b-4361-e6ba-1f29c449ef76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}T{his}{} {}s{}h{}o{}u{}l{}d{} {mat}{}c{}h{} {pet as}{} {wel}{}l{ as}{} {cut an}{}d{} {lol}{}\n"
          ]
        }
      ],
      "source": [
        "# e - zero or more sequences of not-a-vowel - vowel - not-a-vowel\n",
        "nltk.re_show(r'([^aeiou][aeiou][^aeiou])*', 'This should match pet as well as cut and lol')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YspsUtc2bVIq",
        "outputId": "a652bffc-61bb-4090-d7dd-c202577a3884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{should} {match} {me} {but} {not}\n"
          ]
        }
      ],
      "source": [
        "# f - one or more alphanumeric characters or one or more charcters that are neither alpahnumeric nor whitespace\n",
        "nltk.re_show(r'\\w+|[^\\w\\s]+', 'should match me but not \\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpS91fGzbVIq"
      },
      "source": [
        "**Exercise 7)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWbALmgDbVIs",
        "outputId": "e635092b-2d96-408b-82a2-8e3501c09b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the something\n",
            "{the}\n",
            "{an}\n",
            "anything\n"
          ]
        }
      ],
      "source": [
        "a = r'^(the|a|an)$'\n",
        "nltk.re_show(a, 'the something')\n",
        "nltk.re_show(a, 'the')\n",
        "nltk.re_show(a, 'an')\n",
        "nltk.re_show(a, 'anything')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBfHsY72bVIs",
        "outputId": "237df3a4-42a3-4061-a500-3eb19065e4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "something+2\n",
            "{2*3+8}\n",
            "{200+5000}\n",
            "{2*3+8}-5/6\n"
          ]
        }
      ],
      "source": [
        "b = r'\\d+([\\+\\*]\\d+)+'\n",
        "nltk.re_show(b, 'something+2')\n",
        "nltk.re_show(b, '2*3+8')\n",
        "nltk.re_show(b, '200+5000')\n",
        "nltk.re_show(b, '2*3+8-5/6')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-464xpZnbVIs"
      },
      "source": [
        "**Exercise 8)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "\n",
        "def getContentFromURL(url):\n",
        "    raw = urllib.request.urlopen(url).read()\n",
        "    soup = BeautifulSoup(raw)\n",
        "    return soup.get_text()\n",
        "\n",
        "getContentFromURL('http://www.nltk.org/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "o9L1nhT6fgSZ",
        "outputId": "d19c12e3-7b16-4879-d24c-61722a8d8781"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\nNLTK :: Natural Language Toolkit\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNLTK\\n\\n\\n\\nDocumentation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNLTK Documentation\\n\\nAPI Reference\\nExample Usage\\nModule Index\\nWiki\\nFAQ\\nOpen Issues\\nNLTK on GitHub\\n\\nInstallation\\n\\nInstalling NLTK\\nInstalling NLTK Data\\n\\nMore\\n\\nRelease Notes\\nContributing to NLTK\\nNLTK Team\\n\\n\\n\\n\\n\\n\\nNatural Language Toolkit¶\\nNLTK is a leading platform for building Python programs to work with human language data.\\nIt provides easy-to-use interfaces to over 50 corpora and lexical\\nresources such as WordNet,\\nalong with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,\\nwrappers for industrial-strength NLP libraries,\\nand an active discussion forum.\\nThanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,\\nNLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.\\nNLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\\nNLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,”\\nand “an amazing library to play with natural language.”\\nNatural Language Processing with Python provides a practical\\nintroduction to programming for language processing.\\nWritten by the creators of NLTK, it guides the reader through the fundamentals\\nof writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,\\nand more.\\nThe online version of the book has been been updated for Python 3 and NLTK 3.\\n(The original Python 2 version is still available at https://www.nltk.org/book_1ed.)\\n\\nSome simple things you can do with NLTK¶\\nTokenize and tag some text:\\n>>> import nltk\\n>>> sentence = \"\"\"At eight o\\'clock on Thursday morning\\n... Arthur didn\\'t feel very good.\"\"\"\\n>>> tokens = nltk.word_tokenize(sentence)\\n>>> tokens\\n[\\'At\\', \\'eight\\', \"o\\'clock\", \\'on\\', \\'Thursday\\', \\'morning\\',\\n\\'Arthur\\', \\'did\\', \"n\\'t\", \\'feel\\', \\'very\\', \\'good\\', \\'.\\']\\n>>> tagged = nltk.pos_tag(tokens)\\n>>> tagged[0:6]\\n[(\\'At\\', \\'IN\\'), (\\'eight\\', \\'CD\\'), (\"o\\'clock\", \\'JJ\\'), (\\'on\\', \\'IN\\'),\\n(\\'Thursday\\', \\'NNP\\'), (\\'morning\\', \\'NN\\')]\\n\\n\\nIdentify named entities:\\n>>> entities = nltk.chunk.ne_chunk(tagged)\\n>>> entities\\nTree(\\'S\\', [(\\'At\\', \\'IN\\'), (\\'eight\\', \\'CD\\'), (\"o\\'clock\", \\'JJ\\'),\\n           (\\'on\\', \\'IN\\'), (\\'Thursday\\', \\'NNP\\'), (\\'morning\\', \\'NN\\'),\\n       Tree(\\'PERSON\\', [(\\'Arthur\\', \\'NNP\\')]),\\n           (\\'did\\', \\'VBD\\'), (\"n\\'t\", \\'RB\\'), (\\'feel\\', \\'VB\\'),\\n           (\\'very\\', \\'RB\\'), (\\'good\\', \\'JJ\\'), (\\'.\\', \\'.\\')])\\n\\n\\nDisplay a parse tree:\\n>>> from nltk.corpus import treebank\\n>>> t = treebank.parsed_sents(\\'wsj_0001.mrg\\')[0]\\n>>> t.draw()\\n\\n\\n\\nNB. If you publish work that uses NLTK, please cite the NLTK book as\\nfollows:\\n\\nBird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python.  O’Reilly Media Inc.\\n\\n\\n\\nNext Steps¶\\n\\nSign up for release announcements\\nJoin in the discussion\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n source\\n\\n\\n3.9.1\\n\\n\\n                    Aug 19, 2024\\n                \\n\\n\\n                © 2024, NLTK Project\\n            \\n\\n            created with Sphinx and NLTK Theme\\n\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMY08iVWbVIt"
      },
      "source": [
        "**Exercise 9)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "ozBCZ9hrJI1J"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load(fileName):\n",
        "    \"\"\"\n",
        "    Loads the content of a text file.\n",
        "\n",
        "    Args:\n",
        "        fileName (str): The name of the file without the extension.\n",
        "\n",
        "    Returns:\n",
        "        str: The content of the file.\n",
        "    \"\"\"\n",
        "    # Construct the file path with .txt extension\n",
        "    filePath = os.path.abspath(fileName + '.txt')\n",
        "\n",
        "    # Print the expected file path for debugging\n",
        "    print(f\"Looking for file at: {filePath}\")\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(filePath):\n",
        "        raise FileNotFoundError(f\"File '{fileName}.txt' not found at {filePath}. \"\n",
        "                                f\"Please make sure the file exists in the specified location.\")\n",
        "    # Check if the user has read permissions\n",
        "    if not os.access(filePath, os.R_OK):\n",
        "        raise PermissionError(f\"Permission denied to access file '{fileName}.txt'\")\n",
        "    # Open the file and read its contents\n",
        "    with open(filePath, 'r') as f:\n",
        "        return f.read()"
      ],
      "metadata": {
        "id": "jfRsqjPkJT-a"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load(fileName):\n",
        "    \"\"\"\n",
        "    Loads the content of a text file.\n",
        "\n",
        "    Args:\n",
        "        fileName (str): The name of the file without the extension.\n",
        "\n",
        "    Returns:\n",
        "        str: The content of the file.\n",
        "    \"\"\"\n",
        "    # Get the current working directory\n",
        "    current_dir = os.getcwd()\n",
        "\n",
        "    # Construct the file path with .txt extension relative to the current directory\n",
        "    filePath = os.path.join(current_dir, fileName + '.txt')\n",
        "\n",
        "    # Print the expected file path for debugging\n",
        "    print(f\"Looking for file at: {filePath}\")\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(filePath):\n",
        "        raise FileNotFoundError(f\"File '{fileName}.txt' not found at {filePath}. \"\n",
        "                                f\"Please make sure the file exists in the specified location.\")\n",
        "    # Check if the user has read permissions\n",
        "    if not os.access(filePath, os.R_OK):\n",
        "        raise PermissionError(f\"Permission denied to access file '{fileName}.txt'\")\n",
        "    # Open the file and read its contents\n",
        "    with open(filePath, 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "corpusText = load('corpus') # Assuming 'corpus.txt' is in the same directory as the script"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "MpTGmECVJslp",
        "outputId": "14f426a6-e57d-4ec5-807b-7fe28826f49b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for file at: /content/corpus.txt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "File 'corpus.txt' not found at /content/corpus.txt. Please make sure the file exists in the specified location.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-0d7d4eb17aa3>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mcorpusText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpus'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Assuming 'corpus.txt' is in the same directory as the script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-0d7d4eb17aa3>\u001b[0m in \u001b[0;36mload\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Check if the file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         raise FileNotFoundError(f\"File '{fileName}.txt' not found at {filePath}. \"\n\u001b[0m\u001b[1;32m     25\u001b[0m                                 f\"Please make sure the file exists in the specified location.\")\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Check if the user has read permissions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File 'corpus.txt' not found at /content/corpus.txt. Please make sure the file exists in the specified location."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PzRZMqCVJsX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load(fileName):\n",
        "    \"\"\"\n",
        "    Loads the content of a text file.\n",
        "\n",
        "    Args:\n",
        "        fileName (str): The name of the file without the extension.\n",
        "\n",
        "    Returns:\n",
        "        str: The content of the file.\n",
        "    \"\"\"\n",
        "    # Construct the file path with .txt extension, ensuring it's relative to the script's location\n",
        "    filePath = os.path.join(os.path.dirname(__file__), fileName + '.txt')\n",
        "\n",
        "    # Print the expected file path for debugging\n",
        "    print(f\"Looking for file at: {filePath}\")\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(filePath):\n",
        "        raise FileNotFoundError(f\"File '{fileName}.txt' not found at {filePath}. \"\n",
        "                                f\"Please make sure the file exists in the specified location.\")\n",
        "    # Check if the user has read permissions\n",
        "    if not os.access(filePath, os.R_OK):\n",
        "        raise PermissionError(f\"Permission denied to access file '{fileName}.txt'\")\n",
        "    # Open the file and read its contents\n",
        "    with open(filePath, 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "corpusText = load('corpus') # Assuming 'corpus.txt' is in the same directory as the script"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "tdwdSowtJi8l",
        "outputId": "98620836-b501-4aae-db60-a4312a05afa7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '__file__' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-c5fbfda2c2d4>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mcorpusText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpus'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Assuming 'corpus.txt' is in the same directory as the script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-c5fbfda2c2d4>\u001b[0m in \u001b[0;36mload\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Construct the file path with .txt extension, ensuring it's relative to the script's location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Print the expected file path for debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "-2AALRsPbVIt",
        "outputId": "e2647feb-7c5a-4b29-c544-fc06cb731e7a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'corpus.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-2defeda6fef3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcorpusText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-2defeda6fef3>\u001b[0m in \u001b[0;36mload\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorpusText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'corpus.txt'"
          ]
        }
      ],
      "source": [
        "def load(fileName):\n",
        "    f = open(fileName + '.txt')\n",
        "    return f.read()\n",
        "corpusText = load('corpus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "VasOG9tJbVIu",
        "outputId": "5bb16b05-cba9-46c5-d9de-9fb1f2c72068"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'corpusText' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-1ba3bc375121>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0;31m?\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0m_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;31m# one or more punctuation symbols, brackets etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m '''\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'corpusText' is not defined"
          ]
        }
      ],
      "source": [
        "# a\n",
        "pattern = r'''(?x)\n",
        "    [\\.,;\"'?\\(\\):\\-_`\\[\\]\\{\\}]+ # one or more punctuation symbols, brackets etc.\n",
        "'''\n",
        "print (nltk.regexp_tokenize(corpusText, pattern))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "gwXIFZ0fbVIu",
        "outputId": "92b5ed11-b9d5-42be-842b-54548f44ec36"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "Missing parentheses in call to 'print'. Did you mean print(...)? (<ipython-input-59-286a6fc41db4>, line 10)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-59-286a6fc41db4>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    print nltk.regexp_tokenize(testString, pattern)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(...)?\n"
          ]
        }
      ],
      "source": [
        "# b\n",
        "pattern = r'''(?x)\n",
        "    (?:\\d+\\.)?\\d+\\s?\\$                  # Monetary amount like 2.40$\n",
        "    | \\$\\s?(?:\\d+\\.)?\\d+                # Monetary amount like $2.40\n",
        "    | \\d{4}\\-\\d{2}\\-\\d{2}               # Date like 2016-22-01\n",
        "    | \\d{1,2}\\s[A-Z][a-z]{2,8}\\s\\d{4}   # Date like 2 March 1998\n",
        "    | [A-Z][a-z]+(?:\\s[A-Z][a-z]+)?     # Proper Names - TODO: don't match beginning of sentence\n",
        "'''\n",
        "testString = 'should match 3.50$ or 8 $ or 9$ or $2.40 or 2016-11-01 or 2 March 1998 or 19 January 2001 or Sam or United Nations'\n",
        "print nltk.regexp_tokenize(testString, pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQZJjWcebVIv"
      },
      "outputs": [],
      "source": [
        "print nltk.regexp_tokenize(corpusText, pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFHdkWvHbVIv"
      },
      "source": [
        "**Exercise 10)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS68QkUPbVIv",
        "outputId": "2942c491-035d-4d82-9b84-5080a3e5e20a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 3), ('dog', 3), ('gave', 4), ('John', 4), ('the', 3), ('newspaper', 9)]\n"
          ]
        }
      ],
      "source": [
        "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
        "print ([(w, len(w)) for w in sent])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNS-QmmWbVIv"
      },
      "source": [
        "**Exercise 11)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itH4WFJibVIv",
        "outputId": "34f02ddf-6f3d-4272-fbd1-0a505ec5c2d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres ', 'ris', 'es ', 'igres comen ', 'rigo en un ', 'rigal.']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "raw = 'Tres tristes tigres comen trigo en un trigal.'\n",
        "raw.split('t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL2qH3WHbVI2"
      },
      "source": [
        "**Exercise 12)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1fv6D5FbVI3",
        "outputId": "be7d2c93-8e38-49f9-fd4a-c5cece038574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T\n",
            "r\n",
            "e\n",
            "s\n",
            " \n",
            "t\n",
            "r\n",
            "i\n",
            "s\n",
            "t\n"
          ]
        }
      ],
      "source": [
        "for char in raw[:10]:\n",
        "    print (char)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "QJEOiRx0bVI3"
      },
      "source": [
        "**Exercise 13)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYxthPMUbVI3",
        "outputId": "e23438a8-4820-4040-883e-b2adbb9ce3e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres', 'tristes', 'tigres', 'comen', 'trigo', 'en', 'un', 'trigal.']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "raw.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSmP3HJhbVI3",
        "outputId": "20003d97-7fc8-4146-a7ce-67d30c4c4363"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres', 'tristes', 'tigres', 'comen', 'trigo', 'en', 'un', 'trigal.']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "raw.split(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TibOaYa0bVI3",
        "outputId": "72740574-8acc-4c5c-eb92-17a6176d7865"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres', 'tristes', 'tigres', 'comen', 'trigo', 'en', 'un', 'trigal.']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "sent = 'Tres\\ttristes\\ttigres\\tcomen\\ttrigo\\ten\\tun\\ttrigal.'\n",
        "sent.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhdmPOv9bVI3",
        "outputId": "5c8949cf-132d-457b-bb41-4dc0299462a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres\\ttristes\\ttigres\\tcomen\\ttrigo\\ten\\tun\\ttrigal.']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "sent.split(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0pT3We_bVI3",
        "outputId": "de30679a-8f30-4a7f-da60-651f2870c96b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres', 'tristes', 'tigres', 'comen', 'trigo', 'en', 'un', 'trigal.']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "sent = 'Tres   tristes   tigres   comen   trigo   en   un   trigal.'\n",
        "sent.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtZAzHR4bVI4",
        "outputId": "fe1da497-daa5-4b7d-bdaa-8e2d6809ab87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres',\n",
              " '',\n",
              " '',\n",
              " 'tristes',\n",
              " '',\n",
              " '',\n",
              " 'tigres',\n",
              " '',\n",
              " '',\n",
              " 'comen',\n",
              " '',\n",
              " '',\n",
              " 'trigo',\n",
              " '',\n",
              " '',\n",
              " 'en',\n",
              " '',\n",
              " '',\n",
              " 'un',\n",
              " '',\n",
              " '',\n",
              " 'trigal.']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "sent.split(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxuGsun3bVI4",
        "outputId": "32bc6008-ff1b-4a02-d1bc-5d24ad225749"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres', 'tristes', 'tigres', 'comen', 'trigo', 'en', 'un', 'trigal.']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "sent = 'Tres \\ttristes\\t\\t\\ttigres\\t\\t comen\\t \\t trigo en un trigal.'\n",
        "sent.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsC1ygHybVI4",
        "outputId": "940b8fb8-e6f1-469a-8258-39ac1d53a866"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres',\n",
              " '\\ttristes\\t\\t\\ttigres\\t\\t',\n",
              " 'comen\\t',\n",
              " '\\t',\n",
              " 'trigo',\n",
              " 'en',\n",
              " 'un',\n",
              " 'trigal.']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "sent.split(' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSzw8EhVbVI4"
      },
      "source": [
        "**Exercise 14)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4USvvb6dbVI4",
        "outputId": "55d28cfb-f25b-4448-9e4c-fb8c413e2aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tres', 'tristes', 'tigres', 'comen', 'trigo', 'en', 'un', 'trigal.']\n",
            "['Tres', 'comen', 'en', 'tigres', 'trigal.', 'trigo', 'tristes', 'un']\n"
          ]
        }
      ],
      "source": [
        "words = raw.split()\n",
        "print (words)\n",
        "words.sort()\n",
        "print( words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L49CUPjbVI4",
        "outputId": "75083808-0efe-4ff2-9aaa-d1095c69b699"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres', 'comen', 'en', 'tigres', 'trigal.', 'trigo', 'tristes', 'un']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "words = raw.split()\n",
        "sorted(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3UL4on8bVI4",
        "outputId": "1606da49-b391-461d-f4f7-6f81ada23851"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tres', 'tristes', 'tigres', 'comen', 'trigo', 'en', 'un', 'trigal.']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "1CTVLuVkbVI5"
      },
      "outputs": [],
      "source": [
        "# .sort() changes original list, sorted() returns new list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gURksFeGbVI5"
      },
      "source": [
        "**Exercise 15)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dAwCCLtTbVI5",
        "outputId": "4f3711d7-315a-4e97-d1bf-f292f24c9e96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3333333'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "'3' * 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUtZyTgKbVI5",
        "outputId": "7ffc2635-1428-4ec1-db35-218ac99d22ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "3 * 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9cu1gZrbVI5",
        "outputId": "fa26a102-05d5-4961-802e-6ea8d5b0e4d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "int('3') * 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ltug-fcGbVI5",
        "outputId": "b157350f-4805-4e6e-e616-72afa48790dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3333333'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "str(3) * 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-ndLUygbVI5"
      },
      "source": [
        "**Exercise 16)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the variable montyTest\n",
        "montyTest = \"Some value\""
      ],
      "metadata": {
        "id": "LHJKA-z8gynK"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZJcHNUTGbVI6",
        "outputId": "92b95f66-dff1-41d8-d84b-29f1f85e28fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Some value'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "montyTest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pip-install-test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGGsbX1nhLNV",
        "outputId": "bc18960c-7649-4e8b-b9d2-319ae5dce155"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pip-install-test\n",
            "  Downloading pip_install_test-0.5-py3-none-any.whl.metadata (979 bytes)\n",
            "Downloading pip_install_test-0.5-py3-none-any.whl (1.7 kB)\n",
            "Installing collected packages: pip-install-test\n",
            "Successfully installed pip-install-test-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(montyTest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goDak9JmZoGN",
        "outputId": "3452bb05-a5d2-44d1-beba-892460a4b04e"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import test\n",
        "\n",
        "# Attempt to print available attributes of the module\n",
        "print(dir(test))\n",
        "\n",
        "# Based on the output above, adjust the line below to the actual variable name\n",
        "# or function in the module. For example, if you see \"my_variable\" in the list\n",
        "# above, use the following line:\n",
        "try:\n",
        "    test_value = getattr(test, 'test_variable')\n",
        "    print(test_value)\n",
        "except AttributeError:\n",
        "    print(\"Module 'test' does not have an attribute 'test_variable'.\")\n",
        "    print(\"Available attributes:\", dir(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YIiRy7FZ-oA",
        "outputId": "1bf2332c-a2bd-4421-8065-6806b907b36b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n",
            "Module 'test' does not have an attribute 'test_variable'.\n",
            "Available attributes: ['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SyL58aUbVI6"
      },
      "source": [
        "**Exercise 17)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8FPV-Y8bVI6",
        "outputId": "75f5ffcf-78f8-4fcf-9cbe-c8e4eceb2034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "some  superexcitinglylong  examplewords "
          ]
        }
      ],
      "source": [
        "words = ['some', 'superexcitingly', 'long', 'example', 'words']\n",
        "for w in words:\n",
        "    print('%-6s' % w, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic4_FdoPbVI6",
        "outputId": "dda68308-2ab8-4fb8-9383-b3b5eb3d35a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "some  superexcitinglylong  examplewords "
          ]
        }
      ],
      "source": [
        "for w in words:\n",
        "    print('%-6s' % w, end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfXrgcczbVI6",
        "outputId": "b0644bed-466c-4909-faca-565b93caa1a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  some\n",
            "superexcitingly\n",
            "  long\n",
            "example\n",
            " words\n"
          ]
        }
      ],
      "source": [
        "for w in words:\n",
        "    print('%6s' % w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwGVJdvFbVI6"
      },
      "source": [
        "**Exercise 18)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "yWFFYJ4Sh_4F"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "\n",
        "def load(fileName):\n",
        "    \"\"\"\n",
        "    Loads a text file, handling potential FileNotFoundError.\n",
        "\n",
        "    Args:\n",
        "        fileName: The name of the file to load (without extension).\n",
        "\n",
        "    Returns:\n",
        "        The content of the file as a string, or None if the file is not found.\n",
        "    \"\"\"\n",
        "    filePath = os.path.join(os.getcwd(), fileName + '.txt')  # Construct full path\n",
        "    try:\n",
        "        with open(filePath, 'r') as f:\n",
        "            return f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{filePath}' not found.\")\n",
        "        return None\n",
        "\n",
        "# Example usage:\n",
        "myCorpus = load('corpus')\n",
        "if myCorpus:  # Check if file was loaded successfully\n",
        "    tokens = nltk.wordpunct_tokenize(myCorpus)\n",
        "else:\n",
        "    print(\"Corpus loading failed. Exiting.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO4BCk2baLL8",
        "outputId": "df8c93be-f3d3-44f4-fc34-01715f21fad6"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File '/content/corpus.txt' not found.\n",
            "Corpus loading failed. Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "\n",
        "def load(fileName):\n",
        "    \"\"\"\n",
        "    Loads a text file, handling potential FileNotFoundError.\n",
        "\n",
        "    Args:\n",
        "        fileName: The name of the file to load (without extension).\n",
        "\n",
        "    Returns:\n",
        "        The content of the file as a string, or None if the file is not found.\n",
        "    \"\"\"\n",
        "    filePath = os.path.join(os.getcwd(), fileName + '.txt')  # Construct full path\n",
        "    try:\n",
        "        with open(filePath, 'r') as f:\n",
        "            return f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{filePath}' not found.\")\n",
        "        return None\n",
        "\n",
        "# Example usage:\n",
        "myCorpus = load('corpus')\n",
        "if myCorpus:  # Check if file was loaded successfully\n",
        "    tokens = nltk.wordpunct_tokenize(myCorpus)\n",
        "    # Define whWords inside the if block where tokens is defined\n",
        "    whWords = [w for w in tokens if w.startswith('wh') or w.startswith('Wh')]\n",
        "    print (whWords[:50])\n",
        "else:\n",
        "    print(\"Corpus loading failed. Exiting.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gn-nXFyaXnC",
        "outputId": "7e98028e-4480-4f3f-f557-c34e42a88d53"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File '/content/corpus.txt' not found.\n",
            "Corpus loading failed. Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "eaVC0wRFbVI7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "6fe51e22-7770-4ef4-f0fe-ab2ccf5725e1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'whWords' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-72276866b224>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'whWords' is not defined"
          ]
        }
      ],
      "source": [
        "print (sorted(set(whWords)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m4tRON3bVI7"
      },
      "source": [
        "**Exercise 19)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "X6r2WRKbbVI7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "2ac83b26-d95b-43d4-c37e-8a701df4f496"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'freqs.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-bf5ca15b9575>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'freqs.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'freqs.txt'"
          ]
        }
      ],
      "source": [
        "freqs = open('freqs.txt').readlines()\n",
        "freqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "LeUn6jWKbVI7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "56d85426-9ee0-49dc-d3db-35568d68099a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'freqs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-5cdcc323a790>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msplitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'freqs' is not defined"
          ]
        }
      ],
      "source": [
        "splitted = [[line.split()[0], int(line.split()[1])] for line in freqs]\n",
        "splitted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uubMuGu-bVI7"
      },
      "source": [
        "**Exercise 20)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# extracts the topic of the article of the day of given Wikipedia Homepage\n",
        "def find_topic(url, trigger):\n",
        "    # Use urllib.request.urlopen instead of urllib.urlopen\n",
        "    text = urllib.request.urlopen(url).read().decode('utf-8') # Decode the response to a string\n",
        "    index = text.rfind(trigger)\n",
        "    text = text[index:]\n",
        "    # Check if any matches are found before accessing the list\n",
        "    matches = re.findall(r'\\<b\\>.+?\\<\\/b\\>', text)\n",
        "    if matches:\n",
        "        title_with_markup = matches[0]\n",
        "        soup = BeautifulSoup(title_with_markup, 'html.parser') # Specify the parser\n",
        "        return soup.get_text()\n",
        "    else:\n",
        "        # Handle the case where no matches are found\n",
        "        print(\"No <b> tag found after the trigger.\")  # You can customize the handling here\n",
        "        return None  # Or return an appropriate value\n",
        "\n",
        "# German Wikipedia:\n",
        "print (find_topic('https://de.wikipedia.org/wiki/Wikipedia:Hauptseite', '<span class=\"mw-headline\" id=\"Artikel_des_Tages\">Artikel des Tages</span>'))\n",
        "\n",
        "# English Wikipedia:\n",
        "print (find_topic('https://en.wikipedia.org/wiki/Main_Page', '<span class=\"mw-headline\" id=\"From_today.27s_featured_article\">From today\\'s featured article</span>'))\n",
        "\n",
        "# Danish Wikipedia:\n",
        "print (find_topic('https://da.wikipedia.org/wiki/Forside', '<div style=\"padding-left: 38px; color:#333;\">Ugens artikel</div>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5DL34iTbGIZ",
        "outputId": "79b05e35-12cb-494d-dc47-9cc1041bcfc4"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No <b> tag found after the trigger.\n",
            "None\n",
            "No <b> tag found after the trigger.\n",
            "None\n",
            "D-A-D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEwMRq7SbVI8"
      },
      "source": [
        "**Exercise 21)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qWgfM-3amQB",
        "outputId": "3caa276c-491c-4990-f747-95e4529cb829"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "UDA6aJR9bVI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e292fd9-7b6c-43c5-cc7e-d4d7f4d06172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sidebar', 'events', 'changes', 'tools', 'editors', 'sidebar', 'changes', 'pages', 'shortened', 'projects', 'sidebar', 'articles', 'released', 'follows', 'teenager', 'comrades', 'aliens', 'called', 'stars', 'reviewers', 'endorsing', 'reviews', 'has', 'has', 'launched', 'multimedia', 'games', 'comics', 'email', 'articles', 'implicating', 'has', 'views', 'impressions', 'lyrics', 'criticized', 'communities', 'debuted', 'politicians', 'theories', 'issued', 'sacrifices', 'published', 'dropped', 'attempts', 'served', 'wins', 'kills', 'ruins', 'dubbed', 'timeline', 'timeline', 'deaths', 'du', 'performed', 'murdered', 'materials', 'specimens', 'described', 'opened', 'services', 'announced', 'anniversaries', 'email', 'crispus', 'centimetres', 'inches', 'kilograms', 'pounds', 'wingspan', 'centimetres', 'inches', 'largest', 'largest', 'birds', 'has', 'spanning', 'overwintering', 'areas', 'lakes', 'rivers', 'deltas', 'estuaries', 'feeds', 'pelicans', 'vocalisations', 'including', 'barks', 'hisses', 'grunts', 'photographed', 'pictures', 'areas', 'editors', 'resources', 'tasks', 'announcements', 'discussions', 'including', 'policies', 'issues', 'broader', 'questions', 'using', 'editing', 'questions', 'using', 'editing', 'questions', 'topics', 'portals', 'projects', 'editors', 'hosted', 'hosts', 'projects', 'software', 'coordination', 'textbooks', 'manuals', 'quotations', 'tools', 'languages', 'largest', 'articles', 'articles', 'bokm', 'articles', 'nynorsk', 'languages', 'bokm', 'nynorsk', 'srpski', 'edited', 'terms', 'using', 'trademark']\n"
          ]
        }
      ],
      "source": [
        "def unknown(url):\n",
        "    content = getContentFromURL(url)\n",
        "    lowercased = re.findall(r'[\\s\\(\\[\\{]([a-z]+)', content)\n",
        "    words = nltk.corpus.words.words()\n",
        "    return [w for w in lowercased if w not in words]\n",
        "print (unknown('https://en.wikipedia.org/wiki/Main_Page'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "collapsed": true,
        "id": "EGg0GvEBbVI9"
      },
      "outputs": [],
      "source": [
        "# derived forms, abbreviations, foreign words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t9waPctbVI9"
      },
      "source": [
        "**Exercise 22)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "lVXVMAM_bVI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b299d3-0004-4e14-9100-71ccc75bfd86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prepares', 'things', 'says', 'pledges', 'hours', 'hours', 'voted', 'hours', 'experts', 'hours', 'doomed', 'hours', 'delivered', 'hours', 'countries', 'matters', 'hours', 'stories', 'rates', 'hints', 'fewer', 'falls', 'comments', 'rates', 'minutes', 'mortgages', 'loans', 'cheaper', 'hours', 'died', 'drugs', 'patients', 'charged', 'hours', 'engulfed', 'falls', 'hours', 'prices', 'minutes', 'minutes', 'minutes', 'children', 'families', 'hours', 'hours', 'says', 'hours', 'nationclose', 'stories', 'headlines', 'stories', 'stories', 'rates', 'hints', 'fewer', 'falls', 'comments', 'rates', 'minutes', 'escorted', 'hours', 'mortgages', 'loans', 'cheaper', 'hours', 'patients', 'charged', 'hours', 'neighbouring', 'hours', 'engulfed', 'falls', 'hours', 'prices', 'minutes', 'minutes', 'minutes', 'children', 'families', 'hours', 'hours', 'says', 'hours', 'nationclose', 'stories', 'headlines', 'stories', 'stories', 'rates', 'hints', 'fewer', 'falls', 'comments', 'rates', 'minutes', 'mortgages', 'loans', 'cheaper', 'hours', 'patients', 'charged', 'hours', 'engulfed', 'falls', 'hours', 'prices', 'minutes', 'minutes', 'minutes', 'children', 'families', 'hours', 'hours', 'says', 'hours', 'teenager', 'faces', 'years', 'failed', 'hours', 'nationclose', 'stories', 'headlines', 'stories', 'stories', 'rates', 'hints', 'fewer', 'falls', 'comments', 'rates', 'minutes', 'mortgages', 'loans', 'cheaper', 'hours', 'patients', 'charged', 'hours', 'engulfed', 'falls', 'hours', 'prices', 'minutes', 'minutes', 'minutes', 'children', 'families', 'hours', 'hours', 'says', 'hours', 'teenager', 'faces', 'years', 'failed', 'hours', 'nationclose', 'stories', 'headlines', 'stories', 'stories', 'rates', 'hints', 'fewer', 'falls', 'comments', 'rates', 'minutes', 'mortgages', 'loans', 'cheaper', 'hours', 'patients', 'charged', 'hours', 'engulfed', 'falls', 'hours', 'prices', 'minutes', 'minutes', 'minutes', 'children', 'families', 'hours', 'hours', 'says', 'hours', 'teenager', 'faces', 'years', 'failed', 'hours', 'nationclose', 'stories', 'headlines', 'stories', 'races', 'hours', 'leaders', 'hours', 'minutes', 'voters', 'voters', 'hours', 'results', 'happens', 'happens', 'voters', 'voters', 'gives', 'gives', 'impressions', 'impressions', 'congratulates', 'congratulates', 'means', 'means', 'witnessed', 'greatest', 'witnessed', 'greatest', 'inbox', 'cornflakes', 'detectives', 'teenager', 'hours', 'prices', 'hours', 'forgets', 'walks', 'forgets', 'walks', 'hours', 'bringing', 'charges', 'hours', 'died', 'hours', 'spews', 'spews', 'hours', 'unveils', 'hours', 'forgets', 'walks', 'spews', 'cleaners', 'seats', 'voters', 'burns', 'things', 'says', 'flocked', 'escorted', 'rates', 'hints', 'fewer', 'falls', 'charged', 'engulfed', 'falls', 'homes', 'countries', 'matters', 'doomed', 'app', 'stories', 'reporting', 'topics', 'interests', 'app', 'minutes', 'minutes', 'sitcom', 'suitcases', 'sacks', 'coffins', 'called', 'plants', 'calls', 'games', 'minutes', 'minutes', 'hours', 'hours', 'hours', 'hours', 'hours', 'escorted', 'hours', 'minutes', 'dies', 'minutes', 'killed', 'hours', 'alerts', 'sites']\n"
          ]
        }
      ],
      "source": [
        "print (unknown('http://news.bbc.co.uk/'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "QQHh4eCHbVI9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "a376d2a9-4c88-4f70-813b-35706d563967"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'urllib' has no attribute 'urlopen'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-d6329eb29436>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlowercased\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://www.bbc.com/news'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-116-d6329eb29436>\u001b[0m in \u001b[0;36munknown\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\<script(?:.|\\n)*?\\<\\/script\\>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\<style(?:.|\\n)*?\\<\\/style\\>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'urllib' has no attribute 'urlopen'"
          ]
        }
      ],
      "source": [
        "def unknown(url):\n",
        "    text = urllib.urlopen(url).read()\n",
        "    text = re.sub(r'\\<script(?:.|\\n)*?\\<\\/script\\>', '', text)\n",
        "    text = re.sub(r'\\<style(?:.|\\n)*?\\<\\/style\\>', '', text)\n",
        "    soup = BeautifulSoup(text)\n",
        "    content = soup.get_text()\n",
        "    lowercased = re.findall(r'[\\s\\(\\[\\{]([a-z]+)', content)\n",
        "    words = nltk.corpus.words.words()\n",
        "    return set([w for w in lowercased if w not in words])\n",
        "\n",
        "print (unknown('http://www.bbc.com/news'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIMsKtAkbVI9"
      },
      "source": [
        "**Exercise 23)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "37ElpAEsbVI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e10f02-4c36-45e0-c7d0-0f9565f676bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'don', 't', 'hate', 'regular', 'expressions']"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "sample_text = \"I don't hate regular expressions.\"\n",
        "nltk.regexp_tokenize(sample_text, r'n\\'t|\\w+')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "qOsKQFerbVI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe36536-abbf-4404-fd76-969d4af2aa36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'do', \"n't\", 'hate', 'regular', 'expressions']\n",
            "['It', 'does', \"n't\", 'split', 'donald']\n"
          ]
        }
      ],
      "source": [
        "# doesn't work because of greediness of operators -> don matches \\w+\n",
        "print (nltk.regexp_tokenize(sample_text, r'\\w+(?=n\\'t)|n\\'t|\\w+'))\n",
        "print (nltk.regexp_tokenize('It doesn\\'t split donald.', r'\\w+(?=n\\'t)|n\\'t|\\w+')) # ?= lookahead assertion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV4Sp1ClbVI-"
      },
      "source": [
        "**Exercise 24)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "73_wesfXbVI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769ad75b-79d8-4dbf-e165-22b8e4dfc133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h3||0 w0r|d!\n",
            "1t 15 g3tt1ng |85w33t!\n"
          ]
        }
      ],
      "source": [
        "def encode(text):\n",
        "    text = text.lower();\n",
        "    trans = [('ate', '8'), ('e', '3'), ('i', '1'), ('o', '0'), ('l', '|'), ('s', '5'), ('\\.', '5w33t!')]\n",
        "    for (key, value) in trans:\n",
        "        text = re.sub(key, value, text)\n",
        "    return text\n",
        "\n",
        "print (encode('Hello World!'))\n",
        "print (encode('It is getting late.'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "0mBZCqdVbVI-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "647c2c6d-c540-4867-d808-f128adbcd29b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'$h0u|d tr3at $3a d1ff3r3nt fr0m a555w33t!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "def encode_enhanced(text):\n",
        "    text = text.lower();\n",
        "    trans = [('ate', '8'), ('e', '3'), ('i', '1'), ('o', '0'), ('l', '|'), ('^s|(?<=\\s)s', '$'), ('s', '5'), ('\\.', '5w33t!')]\n",
        "    #?<= lookbehind assertion\n",
        "    for (key, value) in trans:\n",
        "        text = re.sub(key, value, text)\n",
        "    return text\n",
        "encode_enhanced('Should treat sea different from ass.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRsyeKtgbVI-"
      },
      "source": [
        "**Exercise 25)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "qAiNmroibVI_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "338eb564-36e2-487e-f7e0-e2ac53df9f64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ingstray'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "# a\n",
        "def piginizeWord(word):\n",
        "    cons = re.findall(r'^[^aeiouAEIOU]*', word)\n",
        "    return word[len(cons[0]):] + cons[0] + 'ay'\n",
        "\n",
        "piginizeWord('string')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "IbDwj-4gbVI_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "94b86e0d-d1a1-446e-c137-9030a923a2ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'omeSay uietqay ingstray erehay atthay ouldshay ebay onvertedcay otay igPay atinLay atay onceay.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "# b\n",
        "def piginizeText(text):\n",
        "    def helper(matchObj):\n",
        "        return piginizeWord(matchObj.group(0))\n",
        "    return re.sub(r'[A-Za-z]+', helper, text)\n",
        "piginizeText('Some quiet string here that should be converted to Pig Latin at once.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "1Qf2rVQBbVI_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a976f7f9-186a-4d17-d44b-3580e568667a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ymay ietquay ellowyay ylishstay ingstray atthay ouldshay ebay onvertedcay otay Igpay Atinlay atay onceay.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "# c\n",
        "def piginizeWordImproved(word):\n",
        "    cons = re.findall(r'^[^aeiouAEIOU]+(?=y)|^[^aeiouqAEIOUQ]*(?:qu)?(?:Qu)?[^aeiouqAEIOUQ]*', word)[0]\n",
        "    remainder = word[len(cons):]\n",
        "    if (word.istitle()):\n",
        "        return remainder.title() + cons.lower() + 'ay'\n",
        "    return remainder + cons + 'ay'\n",
        "\n",
        "def piginizeText(text):\n",
        "    def helper(matchObj):\n",
        "        return piginizeWordImproved(matchObj.group(0))\n",
        "    return re.sub(r'[A-Za-z]+', helper, text)\n",
        "piginizeText('My quiet yellow stylish string that should be converted to Pig Latin at once.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srS_yqmobVI_"
      },
      "source": [
        "**Exercise 26)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "XL8o-efCbVI_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "514fcca0-78a3-4f82-dc8e-652aeb081825"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'urllib' has no attribute 'urlopen'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-9b578232f8b5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://tr.wikipedia.org/wiki/%C4%B0stanbul'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\<script(?:.|\\n)*?\\<\\/script\\>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\<style(?:.|\\n)*?\\<\\/style\\>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'urllib' has no attribute 'urlopen'"
          ]
        }
      ],
      "source": [
        "text = urllib.urlopen('https://tr.wikipedia.org/wiki/%C4%B0stanbul').read()\n",
        "text = re.sub(r'\\<script(?:.|\\n)*?\\<\\/script\\>', '', text)\n",
        "text = re.sub(r'\\<style(?:.|\\n)*?\\<\\/style\\>', '', text)\n",
        "soup = BeautifulSoup(text)\n",
        "content = soup.get_text()\n",
        "tokens = nltk.wordpunct_tokenize(content)\n",
        "text = nltk.Text(tokens)\n",
        "words = [w.lower() for w in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "MOPBHyQNbVI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05574fb8-97cf-4a7f-b6f7-03ef31fa6b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['oe', 'ueeii', 'o', 'eae', 'o']\n"
          ]
        }
      ],
      "source": [
        "vowel_sequences = []\n",
        "for word in words:\n",
        "    vowels = ''.join(re.findall(r'[aeiou]', word))\n",
        "    if (len(vowels) > 0):\n",
        "        vowel_sequences.append(vowels)\n",
        "print (vowel_sequences[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "EFf_zUXubVJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c90d08-9c53-4f25-c641-a5e1e94ab385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('o', 'e'), ('u', 'e'), ('e', 'e'), ('e', 'i'), ('i', 'i'), ('e', 'a'), ('a', 'e')]\n"
          ]
        }
      ],
      "source": [
        "bigrams = []\n",
        "for vowel_seq in vowel_sequences:\n",
        "    count = 0\n",
        "    while (count + 1 < len(vowel_seq)):\n",
        "        bigrams.append((vowel_seq[count], vowel_seq[count + 1]))\n",
        "        count += 1\n",
        "print (bigrams[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "Y0lFjq9kbVJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f373e07e-4121-44d6-a5f8-21d2c19e359e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['o', 'u', 'e', 'i', 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "vowels = ['a', 'e', 'i', 'o', 'u']\n",
        "cfd = nltk.ConditionalFreqDist(bigrams)\n",
        "cfd.conditions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "o8d6RznXbVJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ef2ec3-33cd-4864-b8a5-2313aed2536c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  a e i o u \n",
            "a 0 1 0 0 0 \n",
            "e 1 1 1 0 0 \n",
            "i 0 0 1 0 0 \n",
            "o 0 1 0 0 0 \n",
            "u 0 1 0 0 0 \n"
          ]
        }
      ],
      "source": [
        "cfd.tabulate(conditions=vowels,samples=vowels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQaIxFdbVJA"
      },
      "source": [
        "**Exercise 27)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "Th1eBNjKbVJA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "94ca25e5-8f0d-4ef4-a67f-98a08deeaa86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eeahhahheheaheeh ae he hhh hahahaahhh eaaaeeah hehaaha eah e a eha heh aaheaeehhhhaehhhahhhah hh eaeehaahahhe ee h h hhaaaahae hh h h aeeh heahahhaaeheeah hhaaahh hehhaha aahh hehaeh hh hhhe hhhehhhehh ehhhehheh ahhhahheaehha ahaaa h eeehhhhhh hahehha hah aeehh a ahhha h heh ahhaae h eeh ea hhhhh ah eeahehhehh e a ahhhe hhe eehh eh heah heehaehaehheeahh aahheehe e eehhheehheah eahe hhaeh heeaahhheeahh heea ha eehah ehhhahh he h haehaeh ah a ehaheaehaheaahehea hehahheae aahhhh eh'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "import random\n",
        "def laugh():\n",
        "    raw = ''.join(random.choice('aehh ') for x in range(500))\n",
        "    return ' '.join(raw.split())\n",
        "laugh()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImyPx-RVbVJA"
      },
      "source": [
        "**Exercise 28)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "collapsed": true,
        "id": "r_J6e7zFbVJB"
      },
      "outputs": [],
      "source": [
        "# three words -> woulld be compatible with splitting on whitespace\n",
        "# one compound word -> would make sense semantically, may be relevant for natural language understanding applications\n",
        "# nine words -> would make sense phonetically, relevant for speech processing applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsyL0gMibVJB"
      },
      "source": [
        "**Exercise 29)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-zKk8TlcMhE",
        "outputId": "7f367d6e-75a5-4545-fb70-dc9fc421f365"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "0aGKnvn5bVJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b493000-596f-4dca-f704-f558bfa64da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.254756197101155\n",
            "11.926007043317348\n",
            "12.08430349501021\n",
            "4.34922419804213\n"
          ]
        }
      ],
      "source": [
        "def ari(category):\n",
        "    words = nltk.corpus.brown.words(categories=category)\n",
        "    sents = nltk.corpus.brown.sents(categories=category)\n",
        "    av_wordlength = sum(len(w) for w in words) / len(words)\n",
        "    av_sentlength = sum(len(s) for s in sents) / len(sents)\n",
        "    return (4.71 * av_wordlength) + (0.5 * av_sentlength) - 21.43\n",
        "print (ari('lore'))\n",
        "print (ari('learned'))\n",
        "print (ari('government'))\n",
        "print (ari('romance'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVlRMOU4bVJB"
      },
      "source": [
        "**Exercise 30)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "gG0SJ_YQbVJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab2625c-ba47-4a0c-cfa4-3616e32f6990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['new', 'rule', 'allow', 'sikh', 'polic', 'offic', 'to', 'wear', 'turban', 'instead', 'of', 'tradit', 'polic', 'hat', 'have', 'been', 'introduc', 'in', 'new', 'york', ',', 'offici', 'say', '.', 'the', 'new', 'york', 'polic', 'depart', 'said', 'the', 'turban', 'must', 'be', 'navi', 'blue', 'and', 'have', 'the', 'nypd', 'insignia', 'attach', '.', 'under', 'the', 'new', 'rule', ',', 'religi', 'member', 'of', 'the', 'forc', 'are', 'also', 'permit', 'to', 'grow', 'beard', 'up', 'to', 'half', '-', 'an', '-', 'inch', 'long', '.', 'sikh', 'offic', 'have', 'until', 'now', 'worn', 'turban', 'under', 'their', 'cap', '.', 'beard', 'have', 'not', 'been', 'permit', '.']\n",
            "\n",
            "\n",
            "\n",
            "['new', 'rul', 'allow', 'sikh', 'pol', 'off', 'to', 'wear', 'turb', 'instead', 'of', 'tradit', 'pol', 'hat', 'hav', 'been', 'introduc', 'in', 'new', 'york', ',', 'off', 'say', '.', 'the', 'new', 'york', 'pol', 'depart', 'said', 'the', 'turb', 'must', 'be', 'navy', 'blu', 'and', 'hav', 'the', 'nypd', 'insign', 'attach', '.', 'und', 'the', 'new', 'rul', ',', 'religy', 'memb', 'of', 'the', 'forc', 'ar', 'also', 'permit', 'to', 'grow', 'beard', 'up', 'to', 'half', '-', 'an', '-', 'inch', 'long', '.', 'sikh', 'off', 'hav', 'until', 'now', 'worn', 'turb', 'und', 'their', 'cap', '.', 'beard', 'hav', 'not', 'been', 'permit', '.']\n"
          ]
        }
      ],
      "source": [
        "porter = nltk.PorterStemmer()\n",
        "lancaster = nltk.LancasterStemmer()\n",
        "text = 'New rules allowing Sikh police officers to wear turbans instead of traditional police hats have been introduced in New York, officials say. The New York Police Department said the turbans must be navy blue and have the NYPD insignia attached. Under the new rules, religious members of the force are also permitted to grow beards up to half-an-inch long. Sikh officers have until now worn turbans under their caps. Beards have not been permitted.'\n",
        "tokens = nltk.wordpunct_tokenize(text)\n",
        "print ([porter.stem(t) for t in tokens])\n",
        "print ('\\n\\n')\n",
        "print ( [lancaster.stem(t) for t in tokens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "collapsed": true,
        "id": "snkumFhkbVJB"
      },
      "outputs": [],
      "source": [
        "# Porter preserves upper case, uses unicode, seems to tend to longer stems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaUofLJ2bVJB"
      },
      "source": [
        "**Exercise 31)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "9W-rFDq0bVJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd877ed-6227-4d0c-9990-915e60c5a922"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 3, 2, 4, 3, 4, 1, 4, 2, 4, 4, 4, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "saying = ['After', 'all', 'is', 'said', 'and', 'done', ',', 'more', 'is', 'said', 'than', 'done', '.']\n",
        "lengths = []\n",
        "for w in saying:\n",
        "    lengths.append(len(w))\n",
        "lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcgDk-3kbVJC"
      },
      "source": [
        "**Exercise 32)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "CPidGJHEbVJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ee3160-5f18-48b7-ce4e-051ed138c76b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['newly', 'formed', 'bland', 'ideas', 'are', 'inexpressible', 'in', 'an', 'infuriating', 'way']\n"
          ]
        }
      ],
      "source": [
        "silly = 'newly formed bland ideas are inexpressible in an infuriating way'\n",
        "# a\n",
        "bland = silly.split()\n",
        "print (bland)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "5O68LjJybVJC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c00f7897-e6b6-447f-fe64-01eb17c180e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eoldrnnnna'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "# b\n",
        "''.join(w[1] for w in bland)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "W7jfaZygbVJC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "12054080-1248-489c-aac0-9362137fbd7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'newly formed bland ideas are inexpressible in an infuriating way'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "# c\n",
        "' '.join(bland)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "EWBBcO09bVJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e817ed-4c0d-48ec-9684-e706f8752233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "an\n",
            "are\n",
            "bland\n",
            "formed\n",
            "ideas\n",
            "in\n",
            "inexpressible\n",
            "infuriating\n",
            "newly\n",
            "way\n"
          ]
        }
      ],
      "source": [
        "# d\n",
        "for w in sorted(bland):\n",
        "    print (w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4u9W-oAbVJD"
      },
      "source": [
        "**Exercise 33)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "RnodOxQkbVJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26b2073-1d0c-4470-ce86-2d8c3c3ebe08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "# a\n",
        "'inexpressible'.index('re')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "GcIIWgo1bVJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0d4a2d-6960-4402-fa76-f612b7386b28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "# b\n",
        "words = ['this', 'is', 'a', 'dull', 'list', 'of', 'words']\n",
        "words.index('dull')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "IC381ri0bVJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d974d6-bbe9-4acf-f567-3f3df6bde277"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['newly', 'formed', 'bland', 'ideas', 'are', 'inexpressible']"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "# c\n",
        "bland[:bland.index('in')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKplmo3hbVJD"
      },
      "source": [
        "**Exercise 34)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "ZuB1GozgbVJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09778c6c-174d-4d22-a2d8-23c652e06b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Canada\n",
            "Australia\n",
            "China\n"
          ]
        }
      ],
      "source": [
        "def convertNationality(adjective):\n",
        "    if (adjective.endswith('dian') or adjective.endswith('ese')):\n",
        "        return adjective[:-3] + 'a'\n",
        "    elif (adjective.endswith('ian')):\n",
        "        return adjective[:-1]\n",
        "\n",
        "print (convertNationality('Canadian'))\n",
        "print (convertNationality('Australian'))\n",
        "print (convertNationality('Chinese'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISdJeZm2bVJD"
      },
      "source": [
        "**Exercise 35)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('webtext')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cp89YY9dBGS",
        "outputId": "32caf326-033e-42e1-f201-a1f12ce53422"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/webtext.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "I5nd9mNebVJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d30aa2-f0b3-4328-d862-73f5967b579a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "0\n",
            "['as best you can']\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "pronouns = ['I', 'you', 'he', 'she', 'it', 'we', 'they']\n",
        "corpus = ' '.join(nltk.corpus.webtext.words())\n",
        "sample1 = re.findall(r'[aA]s best as (?:I|you|he|she|it|we|they) can', corpus)\n",
        "print (sample1[:10])\n",
        "print ( len(sample1))\n",
        "sample2 = re.findall(r'[aA]s best (?:I|you|he|she|it|we|they) can', corpus)\n",
        "print (sample2[:10])\n",
        "print (len(sample2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQPLZriAbVJE"
      },
      "source": [
        "**Exercise 36)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('genesis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7PxEGCidLZs",
        "outputId": "f14e9195-07b6-4d60-9e5e-bc83af47a4fd"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "okRU9g38bVJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9b569f-ae3e-49fd-85d2-ef8c2ecd2795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh hai . In teh beginnin Ceiling Cat maded teh skiez An da Urfs , but he did not eated dem . Da Urfs no had shapez An haded dark face , An Ceiling Cat rode invisible bike over teh waterz . An Ceiling Cat sayed light Day An dark no Day . It were FURST !!! 1 An Ceiling Cat sayed , i can has teh firmmint wich iz funny bibel naim 4 ceiling , so wuz teh twoth day . An Ceiling Cat called no waterz urth and waters oshun . Iz good . An so teh threeth day jazzhands . An so teh furth day w00t . An so teh ... fith day . Ceiling Cat taek a wile 2 cawnt . An Ceiling Cat doed moar living stuff , mooes , An creepies , An otehr animuls , An did not eated tehm . An Ceiling Cat sayed , letz us do peeps like uz , becuz we ish teh qte , An let min p0wnz0r becuz tehy has can openers . So Ceiling Cat createded teh peeps taht waz like him , can has can openers he maed tehm , min An womin wuz maeded , but he did not eated tehm . An Ceiling Cat sed them O hai maek bebehs kthx , An p0wn teh waterz , no waterz An teh firmmint , An evry stufs . For evry createded stufs tehre are the fuudz , to the burdies , teh creepiez , An teh mooes , so tehre . It happen . Iz good . An Ceiling Cat sayed , Beholdt , teh good enouf for releaze as version 0 . 8a . kthxbai . An teh skyz an teh Urfs wur finishd , an al teh stufz in dem , an Ceiling Cat was liek al tired an stuf . Ceiling Cat blesd teh 7f day , an sed itz teh h0liez0rz ; cuz dats when he restd fum all his werk wich Ceiling Cat creatd an maed . Yay holy Caturday ! Iz how teh skyz an Urfs wur maed , wen Ceiling Cat pwnt . Urfs no can has plantz n treez n catnipz yet , cuz Ceiling Cat no can maek rainz , but iz ok for kittehs DUNT LYKEZ wetfurz . An ther wuznt ne man to mek farmz n stuf ; cuz teh clowds wur al happie an dint feel liek cryin , wich wuz ok to cuz umbrellaz wuznt inventd yut . An Ceiling Cat madez kitteh owt ov teh flore dust , an breathd ntew his nawstrils teh bref ov life , wich wuz sorta liek doin cpr on a mudpie , but it wuz al gud . An Ceiling Cat madez evry tre dat iz prity , an gud fur fud ; teh tre ov lief wuz in teh gardun to , an teh tre ov teh nawlej ov gud an evul . man askd Ceiling Cat to makez a kooki tree ,\n"
          ]
        }
      ],
      "source": [
        "print (' '.join(nltk.corpus.genesis.words('lolcat.txt')[:500]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "fTd7NTgjbVJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5241f66f-8b2c-43bd-ebf9-dcf85bfd41df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ai\n",
            "hai\n",
            "riet\n",
            "kiet\n",
            "liek\n",
            "ovah\n",
            "lowd\n",
            "kitteh\n",
            "free\n",
            "nofin\n",
            "littel\n"
          ]
        }
      ],
      "source": [
        "def lolcat(word):\n",
        "    word = re.sub(r'ight', 'iet', word)\n",
        "    word = re.sub(r'^I$', 'ai', word)\n",
        "    word = re.sub(r'(?<=[^aeiouAEIOU])i$', 'ai', word)\n",
        "    word = re.sub(r'le$', 'el', word)\n",
        "    def helper(matchObj):\n",
        "        return 'e' + matchObj.group(1)\n",
        "    word = re.sub(r'([^aeiouAEIOU])e$', helper, word)\n",
        "    word = re.sub(r'(?<=[^aeiouAEIOU])er$', 'ah', word)\n",
        "    word = re.sub(r'ou', 'ow', word)\n",
        "    word = re.sub(r'Ou', 'Ow', word)\n",
        "    word = re.sub(r'(?<=[^aeiouAEIOU])y$', 'eh', word)\n",
        "    word = re.sub(r'th', 'f', word)\n",
        "    word = re.sub(r'Th', 'F', word)\n",
        "    word = re.sub(r'ing$', 'in', word)\n",
        "    return word\n",
        "print (lolcat('I'))\n",
        "print (lolcat('hi'))\n",
        "print (lolcat('right'))\n",
        "print (lolcat('kite'))\n",
        "print (lolcat('like'))\n",
        "print (lolcat('over'))\n",
        "print (lolcat('loud'))\n",
        "print (lolcat('kitty'))\n",
        "print (lolcat('three'))\n",
        "print (lolcat('nothing'))\n",
        "print (lolcat('little'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd-D5utrbVJE"
      },
      "source": [
        "**Exercise 37)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "fwEJWXZ_bVJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fd59d2-7bd6-4b63-eed2-50d5a0c15eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function sub in module re:\n",
            "\n",
            "sub(pattern, repl, string, count=0, flags=0)\n",
            "    Return the string obtained by replacing the leftmost\n",
            "    non-overlapping occurrences of the pattern in string by the\n",
            "    replacement repl.  repl can be either a string or a callable;\n",
            "    if a string, backslash escapes in it are processed.  If it is\n",
            "    a callable, it's passed the Match object and must return\n",
            "    a replacement string to be used.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(re.sub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "YTSO9LXNbVJE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c30849af-1fae-421d-c088-d300ba0e882e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A span which should be cleaned'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "def clean(html):\n",
        "    # remove html tags:\n",
        "    text = re.sub(r'\\<.*?\\>', '', html)\n",
        "    # normalize whitespace:\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "clean('<span class=\"some class\">A span    which  should<br> be cleaned</span>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwL-s3owbVJF"
      },
      "source": [
        "**Exercise 38)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "5X9GzWMcbVJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06babb5f-b2ea-492c-a58f-9e9e0f7a1b69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['long-\\nterm', 'encyclo-\\npedia']"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "# a\n",
        "text = 'some text with long-\\nterm and encyclo-\\npedia'\n",
        "words = re.findall(r'\\w+\\-\\n\\w+', text)\n",
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "gJKzc0t9bVJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c086df33-9b5e-482a-dd4a-75ff0ec4173d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "long-term\n",
            "encyclo-pedia\n"
          ]
        }
      ],
      "source": [
        "# b\n",
        "for w in words:\n",
        "    print (re.sub('\\n', '', w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "d2isDIO2bVJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0455fe-859b-4d67-dfbb-77c26ff6210e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "long-term\n",
            "encyclopedia\n"
          ]
        }
      ],
      "source": [
        "# c\n",
        "for w in words:\n",
        "    word = re.sub('\\n', '', w)\n",
        "    parts = word.lower().split('-')\n",
        "    if (parts[0] not in nltk.corpus.words.words() and parts[1] not in nltk.corpus.words.words()):\n",
        "        print (re.sub('\\-', '', word))\n",
        "    else:\n",
        "        print (word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQfCcQ-HbVJF"
      },
      "source": [
        "**Exercise 39)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "Db7zxouabVJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbead47-682f-4e00-972f-f62c18f6269b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R163\n",
            "R163\n",
            "R150\n",
            "A261\n",
            "A261\n",
            "T522\n",
            "P236\n"
          ]
        }
      ],
      "source": [
        "def soundex(name):\n",
        "    first = name[0]\n",
        "    # remove w & h\n",
        "    encoded = first.lower() + re.sub('[wh]', '', name[1:].lower())\n",
        "    # replace consonants with numbers\n",
        "    encoded = re.sub(r'[bfpv]', '1', encoded)\n",
        "    encoded = re.sub(r'[cgjkqsxz]', '2', encoded)\n",
        "    encoded = re.sub(r'[dt]', '3', encoded)\n",
        "    encoded = re.sub(r'l', '4', encoded)\n",
        "    encoded = re.sub(r'[mn]', '5', encoded)\n",
        "    encoded = re.sub(r'r', '6', encoded)\n",
        "    # merge adjacent same digits into one\n",
        "    count = 1\n",
        "    while count < 7:\n",
        "        encoded = re.sub(str(count) + '{2,}', str(count), encoded)\n",
        "        count += 1\n",
        "    # remove vowels\n",
        "    encoded = encoded[0].upper() + re.sub('[aeiouy]', '', encoded[1:])\n",
        "    # if first character is digit, replace it with the saved letter\n",
        "    if (encoded[0].isdigit()):\n",
        "        encoded = first.upper() + encoded[1:]\n",
        "    # encoded must contain 3 digits -> fill it up with zeros if too short\n",
        "    if (len(encoded) < 4):\n",
        "        encoded += '000'\n",
        "    return encoded[:4]\n",
        "\n",
        "print (soundex('Robert')) #R163\n",
        "print (soundex('Rupert')) #R163\n",
        "print (soundex('Rubin')) #R150\n",
        "print (soundex('Ashcraft')) #A261\n",
        "print (soundex('Ashcroft')) #A261\n",
        "print (soundex('Tymczak')) #T522\n",
        "print (soundex('Pfister')) #P236"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ects6BpibVJG"
      },
      "source": [
        "**Exercise 40)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('abc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW_Ho1B3eVYl",
        "outputId": "e8f5d02a-75fa-4f91-857c-2afdeda2a2cd"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/abc.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx7AHpsRea0U",
        "outputId": "eb46e0d4-6f76-45ff-951a-d9bf62561aac"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "E7Ed7lIBbVJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94cc1d4-8311-4a45-8b2c-88a0eb00847a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68.56946783662772\n",
            "68.81462876815377\n"
          ]
        }
      ],
      "source": [
        "def ari(raw):\n",
        "    sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    sents = sent_tokenizer.tokenize(raw)\n",
        "    words = nltk.word_tokenize(raw)\n",
        "    av_wordlength = sum(len(w) for w in words) / len(words)\n",
        "    av_sentlength = sum(len(s) for s in sents) / len(sents)\n",
        "    return (4.71 * av_wordlength) + (0.5 * av_sentlength) - 21.43\n",
        "print (ari(nltk.corpus.abc.raw(\"rural.txt\")))\n",
        "print (ari(nltk.corpus.abc.raw(\"science.txt\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaJrB3GFbVJG"
      },
      "source": [
        "**Exercise 41)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "3FX76YWEbVJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84816c97-0c4e-481e-970b-820cb35b3353"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ],
      "source": [
        "words = ['attribution', 'confabulation', 'elocution', 'sequoia', 'tenacious', 'unidirectional']\n",
        "# more elegant with regular expression instead of nested list comprehension:\n",
        "vsequences = set([''.join(re.findall(r'[aeiou]', word)) for word in words])\n",
        "sorted(vsequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "WjyuL7WtbVJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6001f8-cfc9-4430-83d0-f3043e9640ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ],
      "source": [
        "# nested list comprehension:\n",
        "vsequences = set([''.join([char for char in word if char in 'aeiou']) for word in words])\n",
        "sorted(vsequences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFFPX6UybVJG"
      },
      "source": [
        "**Exercise 42)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL7CkueGeq6J",
        "outputId": "0d3fded2-00fc-468e-94f0-3af7cc52f9fb"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "PfMt7U-6bVJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39ba5ed-3019-4b7c-af3b-777b713e5612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r king ! DENNIS : Listen , strange women lying in ponds distributing swords is no\n",
            " beat a very brave retreat . ROBIN : All lies ! MINSTREL : [ singing ] Bravest of\n",
            "       Nay . Nay . Come . Come . You may lie here . Oh , but you are wounded !   \n",
            "doctors immediately ! No , no , please ! Lie down . [ clap clap ] PIGLET : Well  \n",
            "ere is much danger , for beyond the cave lies the Gorge of Eternal Peril , which \n",
            "   you . Oh ... TIM : To the north there lies a cave -- the cave of Caerbannog --\n",
            "h it and lived ! Bones of full fifty men lie strewn about its lair . So , brave k\n",
            "not stop our fight ' til each one of you lies dead , and the Holy Grail returns t\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "class IndexedText(object):\n",
        "    def __init__(self, stemmer, text):\n",
        "        self._text = text\n",
        "        self._stemmer = stemmer\n",
        "        self._index = nltk.Index((self._stem(word), i)\n",
        "            for (i, word) in enumerate(text))\n",
        "\n",
        "    def concordance(self, word, width=40):\n",
        "        key = self._stem(word)\n",
        "        wc = int(width/4) # words of context\n",
        "        for i in self._index[key]:\n",
        "            lcontext = ' '.join(self._text[i-wc:i])\n",
        "            rcontext = ' '.join(self._text[i:i+wc])\n",
        "            offset = '(WordNet Offset: ' + str(wn.synsets(self._text[i])[0].offset()) + ')'\n",
        "            ldisplay = '%*s' % (width, lcontext[-width:])\n",
        "            rdisplay = '%-*s' % (width, rcontext[:width])\n",
        "            print (ldisplay, rdisplay)\n",
        "\n",
        "    def _stem(self, word):\n",
        "        return self._stemmer.stem(word).lower()\n",
        "\n",
        "porter = nltk.PorterStemmer()\n",
        "grail = nltk.corpus.webtext.words('grail.txt')\n",
        "text = IndexedText(porter, grail)\n",
        "text.concordance('lie')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOSf3mfMbVJH"
      },
      "source": [
        "**Exercise 43)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('udhr')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgTMcxzQe82J",
        "outputId": "09f045b2-09cd-442d-d658-2d93107b9ead"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/udhr.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "sMfr72uKbVJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c8d3b8-728e-4361-e1b2-17584f7c77ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function spearman_correlation in module nltk.metrics.spearman:\n",
            "\n",
            "spearman_correlation(ranks1, ranks2)\n",
            "    Returns the Spearman correlation coefficient for two rankings, which\n",
            "    should be dicts or sequences of (key, rank). The coefficient ranges from\n",
            "    -1.0 (ranks are opposite) to 1.0 (ranks are identical), and is only\n",
            "    calculated for keys in both rankings (for meaningful results, remove keys\n",
            "    present in only one list before ranking).\n",
            "\n",
            "English\n",
            "German_Deutsch\n"
          ]
        }
      ],
      "source": [
        "def guessLanguage(text):\n",
        "    tokens = nltk.wordpunct_tokenize(text)\n",
        "    text = nltk.Text(tokens)\n",
        "    fdist_text = nltk.FreqDist(text)\n",
        "    best_guess = ('', 0)\n",
        "    best_intersection = []\n",
        "    for lang in nltk.corpus.udhr.fileids():\n",
        "        if (lang.endswith('-Latin1')):\n",
        "            fdist_lang = nltk.FreqDist(nltk.corpus.udhr.words(lang))\n",
        "            intersection = list(set(fdist_text.keys()) & set(fdist_lang.keys()))\n",
        "            dict_text = []\n",
        "            dict_lang = []\n",
        "            for word in intersection:\n",
        "                dict_text.append((word, fdist_text[word]))\n",
        "                dict_lang.append((word, fdist_lang[word]))\n",
        "            spearman = nltk.spearman_correlation(dict_text, dict_lang)\n",
        "            if ((best_guess[1] == 0 and spearman != 0.0) or (spearman != 0.0 and spearman > best_guess[1])):\n",
        "                best_guess = (lang[:-7], spearman)\n",
        "    return best_guess[0];\n",
        "\n",
        "help(nltk.spearman_correlation)\n",
        "print (guessLanguage('This is clearly an example of English text which should not be hard to recognize.'))\n",
        "print (guessLanguage(u'Carapax (von gr. charax „Befestigungsanlage“, „Palisade“ und pagios „fest“; Plural: Carapaces) ist eine Bezeichnung für eine bei verschiedenen Tiergruppen (Taxa) unabhängig voneinander entstandene harte Bedeckung der Körperoberseite. Bei Schildkröten heißt der Carapax gemeinsprachlich Rückenschild oder Rückenpanzer, bei Krustentieren (Krebstieren in der Küche) ist er ein Teil der „Schale“. Viele Krebstiere (Crustacea) besitzen eine Hautfalte, die vom Kopfhinterrand (Segment der 2. Maxille) ausgeht; diese kann auch primär (z. B. Cephalocarida) oder sekundär (z. B. Asseln und Flohkrebse) fehlen, gehört also nicht zum Grundbauplan der Krebstiere. Vielfach ist die chitinöse Kopffalte durch eingelagerten Kalk panzerartig versteift, vor allem bei vielen Zehnfußkrebsen. Bedeckt diese Struktur als Rückenschild einige oder ggf. alle Rumpfsegmente, wird sie Carapax genannt. Der Carapax schließt also an den Kopf an, setzt sich über dessen Hinterrand hinaus fort und erstreckt sich mehr oder weniger weit über den Rumpf des Krebses. Je nach Ausbildung kann er auch den Kopf selbst umhüllen (z. B. bei den Muschelkrebsen) und mehr oder weniger weit auch seitlich herabgezogen sein.  – Zum Artikel …'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "YcoTn6tvbVJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0bc2a7-e99a-4f21-b74e-48e91073e6fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Danish_Dansk\n"
          ]
        }
      ],
      "source": [
        "print (guessLanguage(u'Dødsstraf eller livsstraf er henrettelse som straf for en forbrydelse. I de jurisdiktioner, der praktiserer dødsstraf, er den som regel forbeholdt et lille antal alvorlige forbrydelser, ofte overlagt mord og landsforræderi. I Kina praktiseres tillige dødsstraf for økonomisk kriminalitet og narkokriminalitet, og i Iran for homoseksualitet, ligesom der i visse områder kontrolleret af islamiske oprørsbevægelser gennemføres henrettelser baseret på en streng fortolkning af sharia. Mange lande har dødsstraf i den militære straffelov eller for forbrydelser begået i krigstid. I Danmark blev dødsstraf første gang afskaffet i den borgerlige straffelov den 15. april 1930. Loven trådte i kraft 15. april 1933. Dødsstraf blev på dette tidspunkt beholdt i den militære straffelov. I forbindelse med retsopgøret efter 2. verdenskrig genindførtes dødsstraffen (som kaldtes livsstraf) i 1945 for forbrydelser begået under besættelsen. Loven var en særlov og kendes som Landsforræderloven eller retteligen Straffelovstillægget og havde tilbagevirkende kraft for handlinger begået efter 9. april 1940. 46 personer blev på den baggrund henrettet af frivillige politifolk. Den 20. juli 1950 kl. 01:00 blev Ib Birkedal Hansen henrettet som den sidste i Danmark. (Læs mere..)'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHiyqxKMbVJH"
      },
      "source": [
        "**Exercise 44)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW7h1lb7fMs-",
        "outputId": "775379df-3023-4353-c3c5-47c27c76778a"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S4m20i5fTGR",
        "outputId": "0420035e-eb58-4d2e-a686-b893008088fa"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "revxFwZBbVJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2a1252-17d1-4a13-96d3-573237faabfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Jane', 'Fairfax', 'therefore', 'that', 'he', 'would', 'have', 'preferred', 'the', 'society', 'of', 'William', 'Larkins', '.', 'No', '!--', 'she', 'was', 'more', 'and', 'more', 'convinced', 'that', 'Mrs', '.', 'Weston', 'was', 'quite', 'mistaken', 'in', 'that', 'surmise', '.', 'There', 'was', 'a', 'great', 'deal', 'of', 'friendly', 'and', 'of', 'compassionate', 'attachment', 'on', 'his', 'side', '--', 'but', 'no', 'love', '.', 'Alas', '!', 'there', 'was', 'soon', 'no', 'leisure', 'for', 'quarrelling', 'with', 'Mr', '.', 'Knightley', '.', 'Two', 'days', 'of', 'joyful', 'security', 'were', 'immediately', 'followed', 'by', 'the', 'over', '-', 'throw', 'of', 'every', 'thing', '.', 'A', 'letter', 'arrived', 'from', 'Mr', '.', 'Churchill', 'to', 'urge', 'his', 'nephew', \"'\", 's', 'instant', 'return', '.', 'Mrs']\n",
            "Average Similarity:  0.11560158515725369\n"
          ]
        }
      ],
      "source": [
        "def novel_sense(word, text):\n",
        "    content_words = []\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    count = 0\n",
        "    for w in text:\n",
        "        if (w.isalpha() and w not in stopwords):\n",
        "            content_words.append((w, count))\n",
        "        count += 1\n",
        "    count = 0\n",
        "    oddest = False\n",
        "    for w in content_words:\n",
        "        if (w[0] == word):\n",
        "            count_comparisons = 0\n",
        "            overall_sim = 0\n",
        "            for synset in wn.synsets(w[0]):\n",
        "                # compare to words in context on left side:\n",
        "                for index in range(1, min(21, count+1)):\n",
        "                    context_word = content_words[count - index][0]\n",
        "                    for context_synset in wn.synsets(context_word):\n",
        "                        path_sim = synset.path_similarity(context_synset)\n",
        "                        if (path_sim != None):\n",
        "                            overall_sim += path_sim\n",
        "                            count_comparisons += 1\n",
        "                # compare to words in context on right side:\n",
        "                for index in range(1, min(21, len(content_words)-count-1)):\n",
        "                        context_word = content_words[count + index][0]\n",
        "                        for context_synset in wn.synsets(context_word):\n",
        "                            path_sim = synset.path_similarity(context_synset)\n",
        "                            if (path_sim != None):\n",
        "                                overall_sim += path_sim\n",
        "                                count_comparisons += 1\n",
        "            av_sim = overall_sim / count_comparisons\n",
        "            if (oddest == False or oddest[1] > av_sim):\n",
        "                oddest = (w[1], av_sim) # w[1] = original index of the word in the text\n",
        "        count += 1\n",
        "    if (oddest != False):\n",
        "        print (text[max(0, oddest[0] - 50):min(oddest[0] + 50, len(text))])\n",
        "        print ('Average Similarity: ', str(oddest[1]))\n",
        "\n",
        "novel_sense('love', nltk.corpus.gutenberg.words('austen-emma.txt'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}