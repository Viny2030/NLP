{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viny2030/NLP/blob/main/nltk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2lhxNXHuk8ST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.nltk.org/book/\n"
      ],
      "metadata": {
        "id": "F2fAYuCKCcdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La biblioteca nltk (kit de herramientas de lenguaje natural) es una biblioteca maravillosa que podemos\n",
        "Uso para trabajar con idiomas. NLTK se ha utilizado en muchas áreas, incluida\n",
        "Procesamiento del lenguaje, lingüística computacional, inteligencia artificial, información\n",
        "recuperación y aprendizaje automático.\n",
        "Uno necesita importar y descargar la biblioteca y sus datos antes de que se pueda usar."
      ],
      "metadata": {
        "id": "ggNPnYaHk-_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXMRqwRHlD86",
        "outputId": "62d394aa-141a-4770-cc64-98dcd7e0ffb0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iwg6YNjUk2Cg",
        "outputId": "d36c77d1-a956-4b08-89e8-f202cf0fdf9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_eng Averaged Perceptron Tagger (JSON)\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] averaged_perceptron_tagger_rus Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] bcp47............... BCP-47 Language Tags\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "Hit Enter to continue: Brown Corpus\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "Hit Enter to continue: Brown Corpus\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_ne_chunker_tab ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger_tab Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "Hit Enter to continue: quit\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] punkt............... Punkt Tokenizer Models\n",
            "Hit Enter to continue: puntkt\n",
            "  [ ] punkt_tab........... Punkt Tokenizer Models\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] stopwords........... Stopwords Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "Hit Enter to continue: swadesh\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] tagsets_json........ Help on Tagsets (JSON)\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet2021......... Open English Wordnet 2021\n",
            "  [ ] wordnet2022......... Open English Wordnet 2022\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3b02390c7677>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"d\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"u\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_interactive_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_simple_interactive_download\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Identifier> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"l\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m                     self._ds.list(\n\u001b[0m\u001b[1;32m   1185\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                         \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(self, download_dir, show_packages, show_collections, header, more_prompt, skip_installed)\u001b[0m\n\u001b[1;32m    567\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# for more_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmore_prompt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m                     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hit Enter to continue: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"q\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La biblioteca nltk contiene una variedad de textos, como la lista de todo el idioma inglés\n",
        "Palabras, o una selección de libros del Proyecto Gutenberg.\n",
        "Ahora podemos importar todas las palabras en inglés (disponibles en este paquete)."
      ],
      "metadata": {
        "id": "_XoL2N6BldT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HRQPCu8lzIa",
        "outputId": "7daf15c9-08d3-4b54-a484-af8a89ef09e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import words\n",
        "word_list = words.words()"
      ],
      "metadata": {
        "id": "gxla1K2el1ey"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import words\n",
        "word_list = words.words()"
      ],
      "metadata": {
        "id": "EolKJk-FlrvK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLd65Xxul3qq",
        "outputId": "506c14d2-6a0f-4c46-e305-5c0cc2ce1799"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'a',\n",
              " 'aa',\n",
              " 'aal',\n",
              " 'aalii',\n",
              " 'aam',\n",
              " 'Aani',\n",
              " 'aardvark',\n",
              " 'aardwolf',\n",
              " 'Aaron',\n",
              " 'Aaronic',\n",
              " 'Aaronical',\n",
              " 'Aaronite',\n",
              " 'Aaronitic',\n",
              " 'Aaru',\n",
              " 'Ab',\n",
              " 'aba',\n",
              " 'Ababdeh',\n",
              " 'Ababua',\n",
              " 'abac',\n",
              " 'abaca',\n",
              " 'abacate',\n",
              " 'abacay',\n",
              " 'abacinate',\n",
              " 'abacination',\n",
              " 'abaciscus',\n",
              " 'abacist',\n",
              " 'aback',\n",
              " 'abactinal',\n",
              " 'abactinally',\n",
              " 'abaction',\n",
              " 'abactor',\n",
              " 'abaculus',\n",
              " 'abacus',\n",
              " 'Abadite',\n",
              " 'abaff',\n",
              " 'abaft',\n",
              " 'abaisance',\n",
              " 'abaiser',\n",
              " 'abaissed',\n",
              " 'abalienate',\n",
              " 'abalienation',\n",
              " 'abalone',\n",
              " 'Abama',\n",
              " 'abampere',\n",
              " 'abandon',\n",
              " 'abandonable',\n",
              " 'abandoned',\n",
              " 'abandonedly',\n",
              " 'abandonee',\n",
              " 'abandoner',\n",
              " 'abandonment',\n",
              " 'Abanic',\n",
              " 'Abantes',\n",
              " 'abaptiston',\n",
              " 'Abarambo',\n",
              " 'Abaris',\n",
              " 'abarthrosis',\n",
              " 'abarticular',\n",
              " 'abarticulation',\n",
              " 'abas',\n",
              " 'abase',\n",
              " 'abased',\n",
              " 'abasedly',\n",
              " 'abasedness',\n",
              " 'abasement',\n",
              " 'abaser',\n",
              " 'Abasgi',\n",
              " 'abash',\n",
              " 'abashed',\n",
              " 'abashedly',\n",
              " 'abashedness',\n",
              " 'abashless',\n",
              " 'abashlessly',\n",
              " 'abashment',\n",
              " 'abasia',\n",
              " 'abasic',\n",
              " 'abask',\n",
              " 'Abassin',\n",
              " 'abastardize',\n",
              " 'abatable',\n",
              " 'abate',\n",
              " 'abatement',\n",
              " 'abater',\n",
              " 'abatis',\n",
              " 'abatised',\n",
              " 'abaton',\n",
              " 'abator',\n",
              " 'abattoir',\n",
              " 'Abatua',\n",
              " 'abature',\n",
              " 'abave',\n",
              " 'abaxial',\n",
              " 'abaxile',\n",
              " 'abaze',\n",
              " 'abb',\n",
              " 'Abba',\n",
              " 'abbacomes',\n",
              " 'abbacy',\n",
              " 'Abbadide',\n",
              " 'abbas',\n",
              " 'abbasi',\n",
              " 'abbassi',\n",
              " 'Abbasside',\n",
              " 'abbatial',\n",
              " 'abbatical',\n",
              " 'abbess',\n",
              " 'abbey',\n",
              " 'abbeystede',\n",
              " 'Abbie',\n",
              " 'abbot',\n",
              " 'abbotcy',\n",
              " 'abbotnullius',\n",
              " 'abbotship',\n",
              " 'abbreviate',\n",
              " 'abbreviately',\n",
              " 'abbreviation',\n",
              " 'abbreviator',\n",
              " 'abbreviatory',\n",
              " 'abbreviature',\n",
              " 'Abby',\n",
              " 'abcoulomb',\n",
              " 'abdal',\n",
              " 'abdat',\n",
              " 'Abderian',\n",
              " 'Abderite',\n",
              " 'abdest',\n",
              " 'abdicable',\n",
              " 'abdicant',\n",
              " 'abdicate',\n",
              " 'abdication',\n",
              " 'abdicative',\n",
              " 'abdicator',\n",
              " 'Abdiel',\n",
              " 'abditive',\n",
              " 'abditory',\n",
              " 'abdomen',\n",
              " 'abdominal',\n",
              " 'Abdominales',\n",
              " 'abdominalian',\n",
              " 'abdominally',\n",
              " 'abdominoanterior',\n",
              " 'abdominocardiac',\n",
              " 'abdominocentesis',\n",
              " 'abdominocystic',\n",
              " 'abdominogenital',\n",
              " 'abdominohysterectomy',\n",
              " 'abdominohysterotomy',\n",
              " 'abdominoposterior',\n",
              " 'abdominoscope',\n",
              " 'abdominoscopy',\n",
              " 'abdominothoracic',\n",
              " 'abdominous',\n",
              " 'abdominovaginal',\n",
              " 'abdominovesical',\n",
              " 'abduce',\n",
              " 'abducens',\n",
              " 'abducent',\n",
              " 'abduct',\n",
              " 'abduction',\n",
              " 'abductor',\n",
              " 'Abe',\n",
              " 'abeam',\n",
              " 'abear',\n",
              " 'abearance',\n",
              " 'abecedarian',\n",
              " 'abecedarium',\n",
              " 'abecedary',\n",
              " 'abed',\n",
              " 'abeigh',\n",
              " 'Abel',\n",
              " 'abele',\n",
              " 'Abelia',\n",
              " 'Abelian',\n",
              " 'Abelicea',\n",
              " 'Abelite',\n",
              " 'abelite',\n",
              " 'Abelmoschus',\n",
              " 'abelmosk',\n",
              " 'Abelonian',\n",
              " 'abeltree',\n",
              " 'Abencerrages',\n",
              " 'abenteric',\n",
              " 'abepithymia',\n",
              " 'Aberdeen',\n",
              " 'aberdevine',\n",
              " 'Aberdonian',\n",
              " 'Aberia',\n",
              " 'aberrance',\n",
              " 'aberrancy',\n",
              " 'aberrant',\n",
              " 'aberrate',\n",
              " 'aberration',\n",
              " 'aberrational',\n",
              " 'aberrator',\n",
              " 'aberrometer',\n",
              " 'aberroscope',\n",
              " 'aberuncator',\n",
              " 'abet',\n",
              " 'abetment',\n",
              " 'abettal',\n",
              " 'abettor',\n",
              " 'abevacuation',\n",
              " 'abey',\n",
              " 'abeyance',\n",
              " 'abeyancy',\n",
              " 'abeyant',\n",
              " 'abfarad',\n",
              " 'abhenry',\n",
              " 'abhiseka',\n",
              " 'abhominable',\n",
              " 'abhor',\n",
              " 'abhorrence',\n",
              " 'abhorrency',\n",
              " 'abhorrent',\n",
              " 'abhorrently',\n",
              " 'abhorrer',\n",
              " 'abhorrible',\n",
              " 'abhorring',\n",
              " 'Abhorson',\n",
              " 'abidal',\n",
              " 'abidance',\n",
              " 'abide',\n",
              " 'abider',\n",
              " 'abidi',\n",
              " 'abiding',\n",
              " 'abidingly',\n",
              " 'abidingness',\n",
              " 'Abie',\n",
              " 'Abies',\n",
              " 'abietate',\n",
              " 'abietene',\n",
              " 'abietic',\n",
              " 'abietin',\n",
              " 'Abietineae',\n",
              " 'abietineous',\n",
              " 'abietinic',\n",
              " 'Abiezer',\n",
              " 'Abigail',\n",
              " 'abigail',\n",
              " 'abigailship',\n",
              " 'abigeat',\n",
              " 'abigeus',\n",
              " 'abilao',\n",
              " 'ability',\n",
              " 'abilla',\n",
              " 'abilo',\n",
              " 'abintestate',\n",
              " 'abiogenesis',\n",
              " 'abiogenesist',\n",
              " 'abiogenetic',\n",
              " 'abiogenetical',\n",
              " 'abiogenetically',\n",
              " 'abiogenist',\n",
              " 'abiogenous',\n",
              " 'abiogeny',\n",
              " 'abiological',\n",
              " 'abiologically',\n",
              " 'abiology',\n",
              " 'abiosis',\n",
              " 'abiotic',\n",
              " 'abiotrophic',\n",
              " 'abiotrophy',\n",
              " 'Abipon',\n",
              " 'abir',\n",
              " 'abirritant',\n",
              " 'abirritate',\n",
              " 'abirritation',\n",
              " 'abirritative',\n",
              " 'abiston',\n",
              " 'Abitibi',\n",
              " 'abiuret',\n",
              " 'abject',\n",
              " 'abjectedness',\n",
              " 'abjection',\n",
              " 'abjective',\n",
              " 'abjectly',\n",
              " 'abjectness',\n",
              " 'abjoint',\n",
              " 'abjudge',\n",
              " 'abjudicate',\n",
              " 'abjudication',\n",
              " 'abjunction',\n",
              " 'abjunctive',\n",
              " 'abjuration',\n",
              " 'abjuratory',\n",
              " 'abjure',\n",
              " 'abjurement',\n",
              " 'abjurer',\n",
              " 'abkar',\n",
              " 'abkari',\n",
              " 'Abkhas',\n",
              " 'Abkhasian',\n",
              " 'ablach',\n",
              " 'ablactate',\n",
              " 'ablactation',\n",
              " 'ablare',\n",
              " 'ablastemic',\n",
              " 'ablastous',\n",
              " 'ablate',\n",
              " 'ablation',\n",
              " 'ablatitious',\n",
              " 'ablatival',\n",
              " 'ablative',\n",
              " 'ablator',\n",
              " 'ablaut',\n",
              " 'ablaze',\n",
              " 'able',\n",
              " 'ableeze',\n",
              " 'ablegate',\n",
              " 'ableness',\n",
              " 'ablepharia',\n",
              " 'ablepharon',\n",
              " 'ablepharous',\n",
              " 'Ablepharus',\n",
              " 'ablepsia',\n",
              " 'ableptical',\n",
              " 'ableptically',\n",
              " 'abler',\n",
              " 'ablest',\n",
              " 'ablewhackets',\n",
              " 'ablins',\n",
              " 'abloom',\n",
              " 'ablow',\n",
              " 'ablude',\n",
              " 'abluent',\n",
              " 'ablush',\n",
              " 'ablution',\n",
              " 'ablutionary',\n",
              " 'abluvion',\n",
              " 'ably',\n",
              " 'abmho',\n",
              " 'Abnaki',\n",
              " 'abnegate',\n",
              " 'abnegation',\n",
              " 'abnegative',\n",
              " 'abnegator',\n",
              " 'Abner',\n",
              " 'abnerval',\n",
              " 'abnet',\n",
              " 'abneural',\n",
              " 'abnormal',\n",
              " 'abnormalism',\n",
              " 'abnormalist',\n",
              " 'abnormality',\n",
              " 'abnormalize',\n",
              " 'abnormally',\n",
              " 'abnormalness',\n",
              " 'abnormity',\n",
              " 'abnormous',\n",
              " 'abnumerable',\n",
              " 'Abo',\n",
              " 'aboard',\n",
              " 'Abobra',\n",
              " 'abode',\n",
              " 'abodement',\n",
              " 'abody',\n",
              " 'abohm',\n",
              " 'aboil',\n",
              " 'abolish',\n",
              " 'abolisher',\n",
              " 'abolishment',\n",
              " 'abolition',\n",
              " 'abolitionary',\n",
              " 'abolitionism',\n",
              " 'abolitionist',\n",
              " 'abolitionize',\n",
              " 'abolla',\n",
              " 'aboma',\n",
              " 'abomasum',\n",
              " 'abomasus',\n",
              " 'abominable',\n",
              " 'abominableness',\n",
              " 'abominably',\n",
              " 'abominate',\n",
              " 'abomination',\n",
              " 'abominator',\n",
              " 'abomine',\n",
              " 'Abongo',\n",
              " 'aboon',\n",
              " 'aborad',\n",
              " 'aboral',\n",
              " 'aborally',\n",
              " 'abord',\n",
              " 'aboriginal',\n",
              " 'aboriginality',\n",
              " 'aboriginally',\n",
              " 'aboriginary',\n",
              " 'aborigine',\n",
              " 'abort',\n",
              " 'aborted',\n",
              " 'aborticide',\n",
              " 'abortient',\n",
              " 'abortifacient',\n",
              " 'abortin',\n",
              " 'abortion',\n",
              " 'abortional',\n",
              " 'abortionist',\n",
              " 'abortive',\n",
              " 'abortively',\n",
              " 'abortiveness',\n",
              " 'abortus',\n",
              " 'abouchement',\n",
              " 'abound',\n",
              " 'abounder',\n",
              " 'abounding',\n",
              " 'aboundingly',\n",
              " 'about',\n",
              " 'abouts',\n",
              " 'above',\n",
              " 'aboveboard',\n",
              " 'abovedeck',\n",
              " 'aboveground',\n",
              " 'aboveproof',\n",
              " 'abovestairs',\n",
              " 'abox',\n",
              " 'abracadabra',\n",
              " 'abrachia',\n",
              " 'abradant',\n",
              " 'abrade',\n",
              " 'abrader',\n",
              " 'Abraham',\n",
              " 'Abrahamic',\n",
              " 'Abrahamidae',\n",
              " 'Abrahamite',\n",
              " 'Abrahamitic',\n",
              " 'abraid',\n",
              " 'Abram',\n",
              " 'Abramis',\n",
              " 'abranchial',\n",
              " 'abranchialism',\n",
              " 'abranchian',\n",
              " 'Abranchiata',\n",
              " 'abranchiate',\n",
              " 'abranchious',\n",
              " 'abrasax',\n",
              " 'abrase',\n",
              " 'abrash',\n",
              " 'abrasiometer',\n",
              " 'abrasion',\n",
              " 'abrasive',\n",
              " 'abrastol',\n",
              " 'abraum',\n",
              " 'abraxas',\n",
              " 'abreact',\n",
              " 'abreaction',\n",
              " 'abreast',\n",
              " 'abrenounce',\n",
              " 'abret',\n",
              " 'abrico',\n",
              " 'abridge',\n",
              " 'abridgeable',\n",
              " 'abridged',\n",
              " 'abridgedly',\n",
              " 'abridger',\n",
              " 'abridgment',\n",
              " 'abrim',\n",
              " 'abrin',\n",
              " 'abristle',\n",
              " 'abroach',\n",
              " 'abroad',\n",
              " 'Abrocoma',\n",
              " 'abrocome',\n",
              " 'abrogable',\n",
              " 'abrogate',\n",
              " 'abrogation',\n",
              " 'abrogative',\n",
              " 'abrogator',\n",
              " 'Abroma',\n",
              " 'Abronia',\n",
              " 'abrook',\n",
              " 'abrotanum',\n",
              " 'abrotine',\n",
              " 'abrupt',\n",
              " 'abruptedly',\n",
              " 'abruption',\n",
              " 'abruptly',\n",
              " 'abruptness',\n",
              " 'Abrus',\n",
              " 'Absalom',\n",
              " 'absampere',\n",
              " 'Absaroka',\n",
              " 'absarokite',\n",
              " 'abscess',\n",
              " 'abscessed',\n",
              " 'abscession',\n",
              " 'abscessroot',\n",
              " 'abscind',\n",
              " 'abscise',\n",
              " 'abscision',\n",
              " 'absciss',\n",
              " 'abscissa',\n",
              " 'abscissae',\n",
              " 'abscisse',\n",
              " 'abscission',\n",
              " 'absconce',\n",
              " 'abscond',\n",
              " 'absconded',\n",
              " 'abscondedly',\n",
              " 'abscondence',\n",
              " 'absconder',\n",
              " 'absconsa',\n",
              " 'abscoulomb',\n",
              " 'absence',\n",
              " 'absent',\n",
              " 'absentation',\n",
              " 'absentee',\n",
              " 'absenteeism',\n",
              " 'absenteeship',\n",
              " 'absenter',\n",
              " 'absently',\n",
              " 'absentment',\n",
              " 'absentmindedly',\n",
              " 'absentness',\n",
              " 'absfarad',\n",
              " 'abshenry',\n",
              " 'Absi',\n",
              " 'absinthe',\n",
              " 'absinthial',\n",
              " 'absinthian',\n",
              " 'absinthiate',\n",
              " 'absinthic',\n",
              " 'absinthin',\n",
              " 'absinthine',\n",
              " 'absinthism',\n",
              " 'absinthismic',\n",
              " 'absinthium',\n",
              " 'absinthol',\n",
              " 'absit',\n",
              " 'absmho',\n",
              " 'absohm',\n",
              " 'absolute',\n",
              " 'absolutely',\n",
              " 'absoluteness',\n",
              " 'absolution',\n",
              " 'absolutism',\n",
              " 'absolutist',\n",
              " 'absolutistic',\n",
              " 'absolutistically',\n",
              " 'absolutive',\n",
              " 'absolutization',\n",
              " 'absolutize',\n",
              " 'absolutory',\n",
              " 'absolvable',\n",
              " 'absolvatory',\n",
              " 'absolve',\n",
              " 'absolvent',\n",
              " 'absolver',\n",
              " 'absolvitor',\n",
              " 'absolvitory',\n",
              " 'absonant',\n",
              " 'absonous',\n",
              " 'absorb',\n",
              " 'absorbability',\n",
              " 'absorbable',\n",
              " 'absorbed',\n",
              " 'absorbedly',\n",
              " 'absorbedness',\n",
              " 'absorbefacient',\n",
              " 'absorbency',\n",
              " 'absorbent',\n",
              " 'absorber',\n",
              " 'absorbing',\n",
              " 'absorbingly',\n",
              " 'absorbition',\n",
              " 'absorpt',\n",
              " 'absorptance',\n",
              " 'absorptiometer',\n",
              " 'absorptiometric',\n",
              " 'absorption',\n",
              " 'absorptive',\n",
              " 'absorptively',\n",
              " 'absorptiveness',\n",
              " 'absorptivity',\n",
              " 'absquatulate',\n",
              " 'abstain',\n",
              " 'abstainer',\n",
              " 'abstainment',\n",
              " 'abstemious',\n",
              " 'abstemiously',\n",
              " 'abstemiousness',\n",
              " 'abstention',\n",
              " 'abstentionist',\n",
              " 'abstentious',\n",
              " 'absterge',\n",
              " 'abstergent',\n",
              " 'abstersion',\n",
              " 'abstersive',\n",
              " 'abstersiveness',\n",
              " 'abstinence',\n",
              " 'abstinency',\n",
              " 'abstinent',\n",
              " 'abstinential',\n",
              " 'abstinently',\n",
              " 'abstract',\n",
              " 'abstracted',\n",
              " 'abstractedly',\n",
              " 'abstractedness',\n",
              " 'abstracter',\n",
              " 'abstraction',\n",
              " 'abstractional',\n",
              " 'abstractionism',\n",
              " 'abstractionist',\n",
              " 'abstractitious',\n",
              " 'abstractive',\n",
              " 'abstractively',\n",
              " 'abstractiveness',\n",
              " 'abstractly',\n",
              " 'abstractness',\n",
              " 'abstractor',\n",
              " 'abstrahent',\n",
              " 'abstricted',\n",
              " 'abstriction',\n",
              " 'abstruse',\n",
              " 'abstrusely',\n",
              " 'abstruseness',\n",
              " 'abstrusion',\n",
              " 'abstrusity',\n",
              " 'absume',\n",
              " 'absumption',\n",
              " 'absurd',\n",
              " 'absurdity',\n",
              " 'absurdly',\n",
              " 'absurdness',\n",
              " 'absvolt',\n",
              " 'Absyrtus',\n",
              " 'abterminal',\n",
              " 'abthain',\n",
              " 'abthainrie',\n",
              " 'abthainry',\n",
              " 'abthanage',\n",
              " 'Abu',\n",
              " 'abu',\n",
              " 'abucco',\n",
              " 'abulia',\n",
              " 'abulic',\n",
              " 'abulomania',\n",
              " 'abuna',\n",
              " 'abundance',\n",
              " 'abundancy',\n",
              " 'abundant',\n",
              " 'Abundantia',\n",
              " 'abundantly',\n",
              " 'abura',\n",
              " 'aburabozu',\n",
              " 'aburban',\n",
              " 'aburst',\n",
              " 'aburton',\n",
              " 'abusable',\n",
              " 'abuse',\n",
              " 'abusedly',\n",
              " 'abusee',\n",
              " 'abuseful',\n",
              " 'abusefully',\n",
              " 'abusefulness',\n",
              " 'abuser',\n",
              " 'abusion',\n",
              " 'abusious',\n",
              " 'abusive',\n",
              " 'abusively',\n",
              " 'abusiveness',\n",
              " 'abut',\n",
              " 'Abuta',\n",
              " 'Abutilon',\n",
              " 'abutment',\n",
              " 'abuttal',\n",
              " 'abutter',\n",
              " 'abutting',\n",
              " 'abuzz',\n",
              " 'abvolt',\n",
              " 'abwab',\n",
              " 'aby',\n",
              " 'abysm',\n",
              " 'abysmal',\n",
              " 'abysmally',\n",
              " 'abyss',\n",
              " 'abyssal',\n",
              " 'Abyssinian',\n",
              " 'abyssobenthonic',\n",
              " 'abyssolith',\n",
              " 'abyssopelagic',\n",
              " 'acacatechin',\n",
              " 'acacatechol',\n",
              " 'acacetin',\n",
              " 'Acacia',\n",
              " 'Acacian',\n",
              " 'acaciin',\n",
              " 'acacin',\n",
              " 'academe',\n",
              " 'academial',\n",
              " 'academian',\n",
              " 'Academic',\n",
              " 'academic',\n",
              " 'academical',\n",
              " 'academically',\n",
              " 'academicals',\n",
              " 'academician',\n",
              " 'academicism',\n",
              " 'academism',\n",
              " 'academist',\n",
              " 'academite',\n",
              " 'academization',\n",
              " 'academize',\n",
              " 'Academus',\n",
              " 'academy',\n",
              " 'Acadia',\n",
              " 'acadialite',\n",
              " 'Acadian',\n",
              " 'Acadie',\n",
              " 'Acaena',\n",
              " 'acajou',\n",
              " 'acaleph',\n",
              " 'Acalepha',\n",
              " 'Acalephae',\n",
              " 'acalephan',\n",
              " 'acalephoid',\n",
              " 'acalycal',\n",
              " 'acalycine',\n",
              " 'acalycinous',\n",
              " 'acalyculate',\n",
              " 'Acalypha',\n",
              " 'Acalypterae',\n",
              " 'Acalyptrata',\n",
              " 'Acalyptratae',\n",
              " 'acalyptrate',\n",
              " 'Acamar',\n",
              " 'acampsia',\n",
              " 'acana',\n",
              " 'acanaceous',\n",
              " 'acanonical',\n",
              " 'acanth',\n",
              " 'acantha',\n",
              " 'Acanthaceae',\n",
              " 'acanthaceous',\n",
              " 'acanthad',\n",
              " 'Acantharia',\n",
              " 'Acanthia',\n",
              " 'acanthial',\n",
              " 'acanthin',\n",
              " 'acanthine',\n",
              " 'acanthion',\n",
              " 'acanthite',\n",
              " 'acanthocarpous',\n",
              " 'Acanthocephala',\n",
              " 'acanthocephalan',\n",
              " 'Acanthocephali',\n",
              " 'acanthocephalous',\n",
              " 'Acanthocereus',\n",
              " 'acanthocladous',\n",
              " 'Acanthodea',\n",
              " 'acanthodean',\n",
              " 'Acanthodei',\n",
              " 'Acanthodes',\n",
              " 'acanthodian',\n",
              " 'Acanthodidae',\n",
              " 'Acanthodii',\n",
              " 'Acanthodini',\n",
              " 'acanthoid',\n",
              " 'Acantholimon',\n",
              " 'acanthological',\n",
              " 'acanthology',\n",
              " 'acantholysis',\n",
              " 'acanthoma',\n",
              " 'Acanthomeridae',\n",
              " 'acanthon',\n",
              " 'Acanthopanax',\n",
              " 'Acanthophis',\n",
              " 'acanthophorous',\n",
              " 'acanthopod',\n",
              " 'acanthopodous',\n",
              " 'acanthopomatous',\n",
              " 'acanthopore',\n",
              " 'acanthopteran',\n",
              " 'Acanthopteri',\n",
              " 'acanthopterous',\n",
              " 'acanthopterygian',\n",
              " 'Acanthopterygii',\n",
              " 'acanthosis',\n",
              " 'acanthous',\n",
              " 'Acanthuridae',\n",
              " 'Acanthurus',\n",
              " 'acanthus',\n",
              " 'acapnia',\n",
              " 'acapnial',\n",
              " 'acapsular',\n",
              " 'acapu',\n",
              " 'acapulco',\n",
              " 'acara',\n",
              " 'Acarapis',\n",
              " 'acardia',\n",
              " 'acardiac',\n",
              " 'acari',\n",
              " 'acarian',\n",
              " 'acariasis',\n",
              " 'acaricidal',\n",
              " 'acaricide',\n",
              " 'acarid',\n",
              " 'Acarida',\n",
              " 'Acaridea',\n",
              " 'acaridean',\n",
              " 'acaridomatium',\n",
              " 'acariform',\n",
              " 'Acarina',\n",
              " 'acarine',\n",
              " 'acarinosis',\n",
              " 'acarocecidium',\n",
              " 'acarodermatitis',\n",
              " 'acaroid',\n",
              " 'acarol',\n",
              " 'acarologist',\n",
              " 'acarology',\n",
              " 'acarophilous',\n",
              " 'acarophobia',\n",
              " 'acarotoxic',\n",
              " 'acarpelous',\n",
              " 'acarpous',\n",
              " 'Acarus',\n",
              " 'Acastus',\n",
              " 'acatalectic',\n",
              " 'acatalepsia',\n",
              " 'acatalepsy',\n",
              " 'acataleptic',\n",
              " 'acatallactic',\n",
              " 'acatamathesia',\n",
              " 'acataphasia',\n",
              " 'acataposis',\n",
              " 'acatastasia',\n",
              " 'acatastatic',\n",
              " 'acate',\n",
              " 'acategorical',\n",
              " 'acatery',\n",
              " 'acatharsia',\n",
              " 'acatharsy',\n",
              " 'acatholic',\n",
              " 'acaudal',\n",
              " 'acaudate',\n",
              " 'acaulescent',\n",
              " 'acauline',\n",
              " 'acaulose',\n",
              " 'acaulous',\n",
              " 'acca',\n",
              " 'accede',\n",
              " 'accedence',\n",
              " 'acceder',\n",
              " 'accelerable',\n",
              " 'accelerando',\n",
              " 'accelerant',\n",
              " 'accelerate',\n",
              " 'accelerated',\n",
              " 'acceleratedly',\n",
              " 'acceleration',\n",
              " 'accelerative',\n",
              " 'accelerator',\n",
              " 'acceleratory',\n",
              " 'accelerograph',\n",
              " 'accelerometer',\n",
              " 'accend',\n",
              " 'accendibility',\n",
              " 'accendible',\n",
              " 'accension',\n",
              " 'accensor',\n",
              " 'accent',\n",
              " 'accentless',\n",
              " 'accentor',\n",
              " 'accentuable',\n",
              " 'accentual',\n",
              " 'accentuality',\n",
              " 'accentually',\n",
              " 'accentuate',\n",
              " 'accentuation',\n",
              " 'accentuator',\n",
              " 'accentus',\n",
              " 'accept',\n",
              " 'acceptability',\n",
              " 'acceptable',\n",
              " 'acceptableness',\n",
              " 'acceptably',\n",
              " 'acceptance',\n",
              " 'acceptancy',\n",
              " 'acceptant',\n",
              " 'acceptation',\n",
              " 'accepted',\n",
              " 'acceptedly',\n",
              " 'accepter',\n",
              " 'acceptilate',\n",
              " 'acceptilation',\n",
              " 'acception',\n",
              " 'acceptive',\n",
              " 'acceptor',\n",
              " 'acceptress',\n",
              " 'accerse',\n",
              " 'accersition',\n",
              " 'accersitor',\n",
              " 'access',\n",
              " 'accessarily',\n",
              " 'accessariness',\n",
              " 'accessary',\n",
              " 'accessaryship',\n",
              " 'accessibility',\n",
              " 'accessible',\n",
              " 'accessibly',\n",
              " 'accession',\n",
              " 'accessional',\n",
              " 'accessioner',\n",
              " 'accessive',\n",
              " 'accessively',\n",
              " 'accessless',\n",
              " 'accessorial',\n",
              " 'accessorily',\n",
              " 'accessoriness',\n",
              " 'accessorius',\n",
              " 'accessory',\n",
              " 'accidence',\n",
              " 'accidency',\n",
              " 'accident',\n",
              " 'accidental',\n",
              " 'accidentalism',\n",
              " 'accidentalist',\n",
              " 'accidentality',\n",
              " 'accidentally',\n",
              " 'accidentalness',\n",
              " 'accidented',\n",
              " 'accidential',\n",
              " 'accidentiality',\n",
              " 'accidently',\n",
              " 'accidia',\n",
              " 'accidie',\n",
              " 'accinge',\n",
              " 'accipient',\n",
              " 'Accipiter',\n",
              " 'accipitral',\n",
              " 'accipitrary',\n",
              " 'Accipitres',\n",
              " 'accipitrine',\n",
              " 'accismus',\n",
              " 'accite',\n",
              " 'acclaim',\n",
              " 'acclaimable',\n",
              " 'acclaimer',\n",
              " 'acclamation',\n",
              " 'acclamator',\n",
              " 'acclamatory',\n",
              " 'acclimatable',\n",
              " 'acclimatation',\n",
              " 'acclimate',\n",
              " 'acclimatement',\n",
              " 'acclimation',\n",
              " 'acclimatizable',\n",
              " 'acclimatization',\n",
              " 'acclimatize',\n",
              " 'acclimatizer',\n",
              " 'acclimature',\n",
              " 'acclinal',\n",
              " 'acclinate',\n",
              " 'acclivitous',\n",
              " 'acclivity',\n",
              " 'acclivous',\n",
              " 'accloy',\n",
              " 'accoast',\n",
              " 'accoil',\n",
              " 'accolade',\n",
              " 'accoladed',\n",
              " 'accolated',\n",
              " 'accolent',\n",
              " 'accolle',\n",
              " 'accombination',\n",
              " 'accommodable',\n",
              " 'accommodableness',\n",
              " 'accommodate',\n",
              " 'accommodately',\n",
              " 'accommodateness',\n",
              " 'accommodating',\n",
              " 'accommodatingly',\n",
              " 'accommodation',\n",
              " 'accommodational',\n",
              " 'accommodative',\n",
              " 'accommodativeness',\n",
              " 'accommodator',\n",
              " 'accompanier',\n",
              " 'accompaniment',\n",
              " 'accompanimental',\n",
              " 'accompanist',\n",
              " 'accompany',\n",
              " 'accompanyist',\n",
              " 'accompletive',\n",
              " 'accomplice',\n",
              " 'accompliceship',\n",
              " 'accomplicity',\n",
              " 'accomplish',\n",
              " 'accomplishable',\n",
              " 'accomplished',\n",
              " 'accomplisher',\n",
              " 'accomplishment',\n",
              " 'accomplisht',\n",
              " 'accompt',\n",
              " 'accord',\n",
              " 'accordable',\n",
              " 'accordance',\n",
              " 'accordancy',\n",
              " 'accordant',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(word_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eg3eIyul81j",
        "outputId": "d2b30316-d00d-45d6-8e03-6f5901d08ebc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrwKk91Bl_v7",
        "outputId": "30f71daf-b449-4a8f-e341-3b8479e7e1cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236736"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'fortunate' in word_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqgS0OVLmC89",
        "outputId": "c9a85b8b-530a-4250-fd14-4c99f8faacc9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list[ : : 20001]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrXrQrDqmRde",
        "outputId": "68dcd60e-3b9c-458d-dd8e-82ecf1304f45"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'beefhead',\n",
              " 'commerceless',\n",
              " 'Einsteinian',\n",
              " 'grievingly',\n",
              " 'jheel',\n",
              " 'mountaintop',\n",
              " 'pasilaly',\n",
              " 'pun',\n",
              " 'sheikly',\n",
              " 'tenorite',\n",
              " 'unomnipotent']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Here is the list of books available from Project Gutenberg.**"
      ],
      "metadata": {
        "id": "I-XbirxjmUzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaPF6IrDPbwn",
        "outputId": "655c9bcd-4e33-4691-f496-87da6d613b3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "try:\n",
        "    gutenberg.fileids()\n",
        "except LookupError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "sEZJ09f0mhJo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D9mEc0Ymeex",
        "outputId": "4fa0f94d-fc6c-4d21-a141-77e8d68f05e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "###gutenberg.fileids()"
      ],
      "metadata": {
        "id": "g1WlfnfbmYWH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gutenberg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8F31q38mpiJ",
        "outputId": "8c2e8e1e-5275-462c-f04e-f859083b61ea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PlaintextCorpusReader in '/root/nltk_data/corpora/gutenberg'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now import Hamlet into the program using the function sents, which divides\n",
        "the text up into its sentences, where each sentence is a list of words."
      ],
      "metadata": {
        "id": "LgtNlJuInwO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora importamos Hamlet al programa utilizando la función SENT, que divide el texto en sus oraciones, donde cada oración es una lista de palabras."
      ],
      "metadata": {
        "id": "kQbdijA_CmUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import PlaintextCorpusReader"
      ],
      "metadata": {
        "id": "CVJb1UjXQit_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_root = 'path/to/your/corpus'"
      ],
      "metadata": {
        "id": "VXKfEZX3CyzW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import PlaintextCorpusReader\n",
        "import os\n",
        "\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "# Construct the path to your corpus relative to the current directory\n",
        "# Replace 'your_corpus_folder' with the actual name of your folder\n",
        "corpus_root = os.path.join(current_directory, 'your_corpus_folder')\n",
        "\n",
        "# Create a PlaintextCorpusReader instance\n",
        "gutenberg = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
        "\n",
        "# Now you can use the updated gutenberg object\n",
        "print(gutenberg.fileids()) # Example usage to get the file IDs in the corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "01NEn4G_C3yf",
        "outputId": "4f43bec0-6905-4336-ae3a-35a82ebbd6d4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No such file or directory: '/content/your_corpus_folder'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-62e15f6f425b>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Create a PlaintextCorpusReader instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgutenberg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaintextCorpusReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.*\\.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Now you can use the updated gutenberg object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/plaintext.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fileids, word_tokenizer, sent_tokenizer, para_block_reader, encoding)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mcorpus\u001b[0m \u001b[0minto\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mCorpusReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_word_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sent_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fileids, encoding, tagset)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPathPointer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CorpusReader: expected a string or a PathPointer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, _path)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file or directory: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No such file or directory: '/content/your_corpus_folder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW-5zkFyn3-k",
        "outputId": "e93338c5-f864-4ec1-8e8e-e7a691982a70"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Hamlet_sentences = gutenberg.sents('/content/drive/MyDrive/UNED/notebooks/Hamlet.txt')"
      ],
      "metadata": {
        "id": "zPW0miSAnysb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vITWKFwrDz4L",
        "outputId": "3398181b-b789-4e2c-f63b-5f6b0976925d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Hamlet_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLzpJ1cwER00",
        "outputId": "4bf56c95-e828-440d-94c9-1d4f3a61ce1f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Folger', 'Shakespeare', 'Library'], ['http', '://', 'www', '.', 'folgerdigitaltexts', '.', 'org'], ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4F9davdELx8",
        "outputId": "5f13f84f-38a5-4137-adc7-0c5797084d3f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Hamlet_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua2jWko_n-m1",
        "outputId": "4cc35ec4-67a2-4841-fe2b-dceefa537bb2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3175"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('genesis')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX3OqqpKoecA",
        "outputId": "6132955f-db06-49c8-dddf-ef999b32d4c4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inscriptis\n",
        "import inscriptis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGWGrhZvKi9l",
        "outputId": "fbf93a08-7903-4fc3-9fa6-ee49bd00c5f6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting inscriptis\n",
            "  Downloading inscriptis-2.5.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: lxml>=4.9.3 in /usr/local/lib/python3.10/dist-packages (from inscriptis) (5.3.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from inscriptis) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->inscriptis) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->inscriptis) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->inscriptis) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->inscriptis) (2024.8.30)\n",
            "Downloading inscriptis-2.5.0-py3-none-any.whl (45 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: inscriptis\n",
            "Successfully installed inscriptis-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42XVLkLxKsYG",
        "outputId": "00d8c900-d314-45a5-e57d-89bc5c454f82"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.8.30)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator"
      ],
      "metadata": {
        "id": "yBWwE04cKuru"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import bs4\n",
        "import urllib.request\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "from inscriptis import get_text\n",
        "from googletrans import Translator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1qM8m8ZKPZ1",
        "outputId": "805881a5-e741-49cc-c69b-83aa1bd470af"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ".#scrapea articulo de wikipedia, lo limpia\n",
        "enlace = input('https://es.wikipedia.org/wiki/NLTK\\n')\n",
        "minLetters = int(input('Digite el minimo de palabras que desea tener el reumen\\n'))\n",
        "html = urllib.request.urlopen(enlace).read().decode('utf-8')\n",
        "text = get_text(html)\n",
        "article_text = text\n",
        "article_text = article_text.replace(\"[ edit ]\", \"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEP6Oh3vLUUU",
        "outputId": "6fe9bbe1-8eb9-4f6b-b717-1c70039dabe3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://es.wikipedia.org/wiki/NLTK\n",
            "https://es.wikipedia.org/wiki/NLTK\n",
            "Digite el minimo de palabras que desea tener el reumen\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "MupiG3asMCmx",
        "outputId": "d365f453-14c3-4c26-9b0a-4f4aa62fa11d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ir al contenido\\n      Menú principal\\n                Menú principal\\n              mover a la barra lateral ocultar\\n                Navegación\\n                  * Portada\\n                  * Portal de la comunidad\\n                  * Actualidad\\n                  * Cambios recientes\\n                  * Páginas nuevas\\n                  * Página aleatoria\\n                  * Ayuda\\n                  * Notificar un error\\n      Buscar\\n          Buscar\\n        Apariencia\\n            * Donaciones\\n            * Crear una cuenta\\n            * Acceder\\n      Herramientas personales\\n              * Donaciones\\n              * Crear una cuenta\\n              * Acceder\\n            Páginas para editores desconectados más información\\n              * Contribuciones\\n              * Discusión\\n\\n              Contenidos\\n\\n              mover a la barra lateral ocultar\\n                * Inicio\\n                * 1 Referencias\\n                * 2 Enlaces externos\\n        Cambiar a la tabla de contenidos\\n\\n      NLTK\\n\\n        15 idiomas\\n              * العربية\\n              * Català\\n              * Deutsch\\n              * English\\n              * Euskara\\n              * Français\\n              * Hrvatski\\n              * Italiano\\n              * Polski\\n              * Русский\\n              * ไทย\\n              * Українська\\n              * Tiếng Việt\\n              * 中文\\n              * 粵語\\n              Editar enlaces\\n                  * Artículo\\n                  * Discusión\\n              español\\n                  * Leer\\n                  * Editar\\n                  * Ver historial\\n              Herramientas\\n                        Herramientas\\n                      mover a la barra lateral ocultar\\n                        Acciones\\n                          * Leer\\n                          * Editar\\n                          * Ver historial\\n                        General\\n                          * Lo que enlaza aquí\\n                          * Cambios en enlazadas\\n                          * Subir archivo\\n                          * Páginas especiales\\n                          * Enlace permanente\\n                          * Información de la página\\n                          * Citar esta página\\n                          * Obtener URL acortado\\n                          * Descargar código QR\\n                        Imprimir/exportar\\n                          * Crear un libro\\n                          * Descargar como PDF\\n                          * Versión para imprimir\\n                        En otros proyectos\\n                          * Elemento de Wikidata\\n                  Apariencia\\n                mover a la barra lateral ocultar\\n            De Wikipedia, la enciclopedia libre\\n              Natural Language Toolkit    \\n                                          \\n              Información general         \\n              Tipo de programa              Procesamiento del lenguaje natural   \\n              Autor                         Steven Bird, Edward Loper, Ewan Klein\\n              Desarrollador                 NLTK - Developers and contributors   \\n              Licencia                      Apache 2.0                           \\n              Información técnica         \\n              Programado en                 Python                               \\n              Versiones                   \\n              Última versión estable        3.4.5 ( 20 de agosto de 2019 [ 2 ] \\u200b)\\n              Enlaces                     \\n                Sitio web oficial         \\n                Repositorio de código     \\n                Seguimiento de errores    \\n                [editar datos en Wikidata]\\n              \\n\\n              Parse árbol generado con NLTK\\n\\n              El kit de herramientas de lenguaje natural, o más comúnmente NLTK, es un conjunto de bibliotecas y programas para el procesamiento del lenguaje natural (PLN) simbólico y estadísticos para el lenguaje de programación Python. NLTK incluye demostraciones gráficas y datos de muestra. Se acompaña de un libro que explica los conceptos subyacentes a las tareas de procesamiento del lenguaje compatibles el toolkit, [ 3 ] \\u200b además de programas de ejemplo. [ 4 ] \\u200b NLTK está destinado a apoyar la investigación y la enseñanza en procesamiento de lenguaje natural (PLN) o áreas muy relacionadas, que incluyen la lingüística empírica, las ciencias cognitivas, la inteligencia artificial, la recuperación de información, y el aprendizaje de la máquina. [ 5 ] \\u200b NLTK se ha utilizado con éxito como herramienta de enseñanza, como una herramienta de estudio individual, y como plataforma para los sistemas de investigación de prototipos y construcción.\\n\\n                Referencias\\n\\n                [ editar ]\\n                 1. ↑ project site on SourceForge ; registered:2001-07-09\\n                 2. ↑ «NLTK ChangeLog» . nltk.org . Consultado el 31 de enero de 2020 .\\n                 3. ↑ Bird, Steven; Ewan Klein; Edward Loper (2009). Natural Language Processing with Python . O'Reilly Media Inc. ISBN 0-596-51649-5 .\\n                 4. ↑ Perkins, Jacob (2010). Python Text Processing with NLTK 2.0 Cookbook . Packt Publishing. ISBN 1849513600 .\\n                 5. ↑ Bird, Steven; Edward Loper; Jason Baldridge (2008). Multidisciplinary instruction with the Natural Language Toolkit . Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics, ACL. Archivado desde el original el 2 de septiembre de 2011. |autor1= y |last= redundantes ( ayuda )\\n\\n                Enlaces externos\\n\\n                [ editar ]\\n                * \\n                * Sitio web oficial\\n                * NLTK libro en línea Archivado el 1 de marzo de 2018 en Wayback Machine.\\n                * NLTK desarrollo en GitHub\\n                * Documentación de la API Archivado el 2 de marzo de 2018 en Wayback Machine.\\n\\n              NLTK Presentation at Baypiggies User Group en YouTube.. Presentado en el campus de Google el 12 de junio de 2007.\\n\\n                                                * Proyectos Wikimedia                              \\n                                                * Datos: Q1635410                                  \\n                                                * Informática                                      \\n                                                * Arch Linux: python-nltk                          \\n                    Control de autoridades      * Debian: python3-nltk                             \\n                                                * Free Software Directory: Natural_Language_Toolkit\\n                                                * Gentoo: dev-python/nltk                          \\n                                                * Open Hub : nltk                                  \\n                                                * PyPI : nltk                                      \\n                    \\n                      * Datos: Q1635410\\n                Obtenido de «https://es.wikipedia.org/w/index.php?title=NLTK&oldid=155946697»\\n                Categorías:\\n                  * Análisis de datos\\n                  * Bibliotecas de Python\\n                  * Software libre programado en Python\\n                  * Procesamiento de lenguaje natural\\n                  * Visión por computadora\\n                Categoría oculta:\\n                  * Wikipedia:Páginas con referencias con parámetros redundantes\\n          * Esta página se editó por última vez el 11 dic 2023 a las 06:11.\\n          * El texto está disponible bajo la Licencia Creative Commons Atribución-CompartirIgual 4.0; pueden aplicarse cláusulas adicionales. Al usar este sitio aceptas nuestros términos de uso y nuestra política de privacidad.\\n            Wikipedia® es una marca registrada de la Fundación Wikimedia, una organización sin ánimo de lucro.\\n          * Política de privacidad\\n          * Acerca de Wikipedia\\n          * Limitación de responsabilidad\\n          * Código de conducta\\n          * Desarrolladores\\n          * Estadísticas\\n          * Declaración de cookies\\n          * Versión para móviles\\n          * \\n          * \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize,sent_tokenize\n",
        "# Elimina caracteres especiales y espacios\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)\n"
      ],
      "metadata": {
        "id": "mhuJNYcZLjun"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
        "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)\n",
        "#EN ESTA PARTE HACE LA TOKENIZACION\n",
        "sentence_list = nltk.sent_tokenize(article_text)"
      ],
      "metadata": {
        "id": "LTW4qfgXMApr"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SEPARA CADA PALABRA Y LA FRECUENCIA DE CADA UNA\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(formatted_article_text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1"
      ],
      "metadata": {
        "id": "g8mSMooVMIbL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "maximum_frequency = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequency)"
      ],
      "metadata": {
        "id": "62ll2VpYMN8r"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SELECCIONA LAS FRASES QUE MÁS SE REPITEN\n",
        "sentence_scores = {}\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < minLetters:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "metadata": {
        "id": "PrQEDeJZMZp0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evhqT3QIMoFv",
        "outputId": "56cadeb0-0b02-4e6f-d013-58d40ff2cfa3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.8.30)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator"
      ],
      "metadata": {
        "id": "Ag1Zz7c3MqXz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()"
      ],
      "metadata": {
        "id": "3Wu1A4z0MsgI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIqDvpfKNDki",
        "outputId": "71d93ff0-7d7f-4cb5-ba42-29e9c9be9216"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.8.30)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import googletrans"
      ],
      "metadata": {
        "id": "3nVZQkk8NFi8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(translator))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwZTgOqANHUD",
        "outputId": "6fbbe051-75ec-4ea2-cc38-f27f7bf89db8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'googletrans.client.Translator'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(service_urls=['translate.google.cn'])"
      ],
      "metadata": {
        "id": "8DsTh_GeMuyQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REALIZA EL RESUMEN CON LAS MEJORES FRASES\n",
        "opc= input('¿Desea traducir el resumen? y/n \\n')\n",
        "import heapq\n",
        "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
        "summary = ' '.join(summary_sentences)\n",
        "if(opc=='n'):\n",
        "   print(summary)\n",
        "else:\n",
        "    translator = Translator()\n",
        "    translate = translator.translate(summary, src=\"en\", dest=\"es\")\n",
        "    print(\"***************************TRADUCCIÓN*******************************\")\n",
        "    print(translate.text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyKDNvjcMg0n",
        "outputId": "5369f53c-5c48-419b-f9db-ee849e273c38"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Desea traducir el resumen? y/n \n",
            "n\n",
            "Archivado desde el original el 2 de septiembre de 2011. Consultado el 31 de enero de 2020 . NLTK incluye demostraciones gráficas y datos de muestra. Python Text Processing with NLTK 2.0 Cookbook . Natural Language Processing with Python . Multidisciplinary instruction with the Natural Language Toolkit . ↑ «NLTK ChangeLog» .\n"
          ]
        }
      ]
    }
  ]
}