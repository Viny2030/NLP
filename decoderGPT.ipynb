{"cells":[{"cell_type":"markdown","metadata":{"id":"cNQNGDUEJZrG"},"source":["# Generación de texto usando GPT-2: Formas de decodificar la salida del texto generado"]},{"cell_type":"markdown","metadata":{"id":"c0Luw2ORJZrI"},"source":["En este cuaderno se utilizá el modelo GPT-2 para generar texto. Se exploran diferentes formas de decodificar la salida del modelo para generar texto. Se verán los problemas que tienen cada una de las opciones, intentando en todos los casos generar texto que sea lo más natural y coherente posible.\n","\n","Este cuaderno se ha desarrollado apoyándose en las explicaciones de [este post](https://huggingface.co/blog/how-to-generate) del blog de HuggingFace."]},{"cell_type":"markdown","metadata":{"id":"nGpv6CesJZrJ"},"source":["## Instalación e importación de librerías y definición de parámetros"]},{"cell_type":"markdown","metadata":{"id":"0HTyASoIJZrJ"},"source":["Se instalan usando el comando `pip install` las librerías necesarias para el desarrollo del proyecto."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gyJeITYrJZrJ","executionInfo":{"status":"ok","timestamp":1705490472118,"user_tz":-60,"elapsed":30808,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"026b2a99-0ad1-4208-fc53-09ea9e212f13"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.27.2\n","  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.2) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.2) (0.20.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.2) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.2) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.2) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.2) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.2)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.2) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.2) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.2) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.2) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.2) (2023.11.17)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.15.0\n","    Uninstalling tokenizers-0.15.0:\n","      Successfully uninstalled tokenizers-0.15.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.35.2\n","    Uninstalling transformers-4.35.2:\n","      Successfully uninstalled transformers-4.35.2\n","Successfully installed tokenizers-0.13.3 transformers-4.27.2\n","Looking in indexes: https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install transformers==4.27.2\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"]},{"cell_type":"markdown","metadata":{"id":"QTouZIkgJZrK"},"source":["Se importan las librerías necesarias para este cuaderno."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-bN7wLPCJZrK","executionInfo":{"status":"ok","timestamp":1705490477179,"user_tz":-60,"elapsed":5065,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}}},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch"]},{"cell_type":"markdown","metadata":{"id":"Wd2Xk9CoJZrL"},"source":["Una vez importadas, se definen una serie de parámetros que se utilizarán a lo largo del cuaderno.\n","\n","- **model_name**: Nombre del modelo que será reentrenado.\n","- **max_length**: Longitud máxima de las secuencias de texto generadas."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"1mPRA_eBJZrL","executionInfo":{"status":"ok","timestamp":1705490477519,"user_tz":-60,"elapsed":343,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}}},"outputs":[],"source":["model_name = \"gpt2\"\n","max_length = 200"]},{"cell_type":"markdown","metadata":{"id":"Suji_ryJJZrM"},"source":["## Importación del modelo"]},{"cell_type":"markdown","metadata":{"id":"l3SVE8lFJZrM"},"source":["Usando las clases Auto (más información sobre que es una clase Auto [aquí](https://huggingface.co/transformers/model_doc/auto.html)), se puede importar un modelo preentrenado de HuggingFace.\n","\n","Se importa [GPT2](https://huggingface.co/transformers/model_doc/gpt2.html) y se define el tokenizer que se utilizará para procesar los datos. En este caso, se usa AutoModelForCasualLM, que es una clase que permite importar un modelo preentrenado para tareas de lenguaje natural. Más información sobre esta clase [aquí](https://huggingface.co/transformers/model_doc/auto.html#automodelforcausallm)."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286,"referenced_widgets":["f823da9f5efc454882b5405e52d79992","e805c7eb1a184b93bfe2281f1a0bb39e","f71d5d8bfb51435e910b502504d50981","22e9ed0bf7954dae9731b4ef938b3f28","8f28f93c63b64463abf7b6d98c8fb39e","e6d91eb5f5964c5c87500dba26280364","f8206ae08c4a47219a5d7a8d8c65f06c","235de92e5e994b4082fb473fa30f8740","52b210b3983c4e0fa2b62d13dc072e20","a63271b3f2484ac190ac520661954f3b","460f7e26f4424cbc9aeb537b1a3ff35d","ec57b836a0c5438f84b559a037b1e989","c19628b4198d44889edb4af0e6f5b334","580cac2617f04cde9954b8f754646a5c","53e04aa6c3ed42bf814182ce38cd2019","bef34984e3524d40bd764249efdedf3b","a34413d63f5f487387d2bc557ec7f4c0","d0b1135dae714bdbb03ad66d44432ca2","550656ed4bf94b49909cd128b7d603fa","d0a4e74c7afd468487153c7c7e375bd5","23d07e0400444edd9a64ae61cce9e169","5392766b662742aca59742c5dc8710d6","579cacdb257c404db60fae8689959c21","d238c2656f1c4b4ca3694dcfa8e93c12","405c7e928fa24e1caf33bee018773ca1","54885898c2464347abf761c711c371af","94fe428f56904b67b9053d96b46e85cb","73554e0f655d47e6b67831f5ab4f8803","ef507f744f1c4fdba6ea73ae1df12d0c","f13c57ec3f2748a3a2a48aa1c08d7384","a84d3d7b032f4eb1a77d02f88e15cd80","1b552649ee2543dcae050db9d9bfed59","c676850e489e4e8da63498f5d40d6685","519c9d2d96744dd49af454a17b80d45d","319f2fc174874958a0e1747e25c83b4f","b75603bfd74b46678b1c109afbe857f7","54d3c1dfb9d1456eba1ab18acd22d016","69702990646d4e508f1d38f58f8ac773","3bc2f83af6754e19aff075619b535c14","60fffdf4171b474db6c3681ac99bcb1a","3418dbbec57648759400988ba9eab39c","1cd9aa0afa264226861ab928381d5bee","f82958d7c10043c5af4a63fab8fe4ee0","418f0bec3e034c998357527b7bfe4936","879b239aa6ef46f1836a59c331510b97","23e4d5018a874d4fbe63403f531437af","0e87ff394f934eca90b5f0fec3dd9583","2811af0856234946972765c516503f3d","de08c5959f8941c7bb404e3ce6e12510","4294e27bb7654a14ba1df57cd75f57f2","4a170a1e4848484e8fcb6583d5119890","d3a8cf3b08aa4e43bae57438bef119de","bb0ed0b82d9542b1bfb8655e4d69215c","8708c9a1f8f0419d9da2d1b370a4019b","38fc59524ab04f97aa216eecf9955ccb"]},"id":"cGA1B5tnJZrM","executionInfo":{"status":"ok","timestamp":1705490490078,"user_tz":-60,"elapsed":12561,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"9b19a12a-58f3-4919-e16a-cbc851ade333"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f823da9f5efc454882b5405e52d79992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec57b836a0c5438f84b559a037b1e989"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"579cacdb257c404db60fae8689959c21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519c9d2d96744dd49af454a17b80d45d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"879b239aa6ef46f1836a59c331510b97"}},"metadata":{}}],"source":["from transformers import GPT2Tokenizer, AutoModelForCausalLM\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)"]},{"cell_type":"markdown","metadata":{"id":"e9DL0tdaJZrM"},"source":["Dado que el modelo GPT-2 no tiene configurado el token de padding (el cual se utiliza para rellenar las secuencias de texto), se define el token de padding con el del token de fin de secuencia (EOS), cuyo valor es 50256."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"dbtpQLz2JZrM","executionInfo":{"status":"ok","timestamp":1705490490078,"user_tz":-60,"elapsed":3,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}}},"outputs":[],"source":["tokenizer.pad_token = tokenizer.eos_token\n","model.config.pad_token_id = tokenizer.pad_token_id"]},{"cell_type":"markdown","metadata":{"id":"qgxJVWbKJZrM"},"source":["## Métodos de decodificación"]},{"cell_type":"markdown","metadata":{"id":"xDnVBa-nJZrM"},"source":["Dado un modelo de generación, existen difernetes formas de decodificar la salida producida por el modelo. El resultado que arroje el modelo dependerá de como de buena sea esa decodificación.\n","\n","En esta sección se explicarán diferentes formas para realizar este proceso, estando todas ellas implementadas en la librería ```transformers```.\n","\n","En este caso, como ya se ha comentado, se utilizará el modelo ```GPT2```, pero estas formas de decodificación son aplicables a otros conocidos modelos de generación como ```BART``` o ```T5```."]},{"cell_type":"markdown","metadata":{"id":"eJ1DgSqWJZrM"},"source":["Para poder comparar los resultados que produzcan los difernetes métodos de generación, se utilizará el mismo texto de entrada al modelo, el cual se define a continuación."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"igSPcWmTJZrN","executionInfo":{"status":"ok","timestamp":1705490490078,"user_tz":-60,"elapsed":2,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}}},"outputs":[],"source":["inputText = \"The University of Alicante is a\""]},{"cell_type":"markdown","metadata":{"id":"ZqUWHmPvJZrN"},"source":["### Greedy Search"]},{"cell_type":"markdown","metadata":{"id":"5nIkhKSBJZrN"},"source":["En el método de búsqueda greedy (avaricioso), se selecciona la palabra con mayor probabilidad en cada paso. Este método es el más rápido, pero no siempre produce los mejores resultados.\n","\n","Se muestra a continuación un ejemplo:\n","\n","![Greedy Search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/greedy_search.png)\n","\n","El texto producido es el que está marcado en rojo (<span style=\"color:red\">*The nice woman*</span>).\n","\n","Como se puede ver, dada la palabra <span style=\"color:red\">*The*</span> se producen tres posibles caminos, <span style=\"color:red\">*dog*</span>, <span style=\"color:red\">*nice*</span> y <span style=\"color:red\">*car*</span>, con probabilidades 0.4, 0.5 y 0.1 respectivamente. Como 0.5 es la mayor de las probabilidades, se elige la palabra <span style=\"color:red\">*nice*</span> y se continúa con el proceso. Del mismo modo se elige la palabra <span style=\"color:red\">*woman*</span> frente a otras dos posiblidades.\n","\n","En total, el camino elegido tiene una probabilidad de $0.5 \\times 0.4 = 0.2$."]},{"cell_type":"markdown","metadata":{"id":"SNuewnQ3JZrN"},"source":["Visto un ejemplo, se procede ahora a generar texto usando este método."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"4HAnWNq4JZrN","executionInfo":{"status":"ok","timestamp":1705490504937,"user_tz":-60,"elapsed":14861,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"b716ffbd-df53-4f59-fa26-5e74028066ce"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["\"The University of Alicante is a leading research university in the Netherlands. We are a member of the European Union's Scientific Council and the European Commission. We are also a member of the European Commission's Scientific Council.\\n\\nWe are a member of the European Commission's Scientific Council and the European Commission. We are also a member of the European Commission's Scientific Council. We are a member of the European Commission's Scientific Council. We are a member of the European Commission's Scientific Council. We are a member of the European Commission's Scientific Council. We are a member of the European Commission's Scientific Council. We are a member of the European Commission's Scientific Council. We are a member of the European Commission's Scientific Council. We are a member of the European Commission's Scientific Council. We are a member of the European Commission's Scientific Council. We are a member of the European Commission's Scientific Council. We are a member of the European Commission's Scientific Council. We are a member of the\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}],"source":["input_ids = tokenizer.encode(inputText, return_tensors=\"pt\")\n","output = model.generate(input_ids, max_length=max_length)\n","tokenizer.decode(output[0], skip_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"Sq6RbEokJZrN"},"source":["Como se puede observar en la salida, el modelo comienza a producir texto con cierto sentido, pero a medida que se va generando texto, este va perdiendo sentido y empieza a repetirse, cosa que no nos interesa."]},{"cell_type":"markdown","metadata":{"id":"r6-uFMqrJZrN"},"source":["### Beam Search"]},{"cell_type":"markdown","metadata":{"id":"TQv_5aGOJZrN"},"source":["Beam search (búsqueda de haz) es un método de búsqueda que se basa en la búsqueda greedy, pero en lugar de elegir la palabra con mayor probabilidad, se eligen las *k* palabras con mayor probabilidad. De estas *k* palabras, se elige la que tenga mayor probabilidad de producir una secuencia de palabras con sentido.\n","\n","Para ello, en se definen el número de beams (```num_beams```), el cual indica el número de palabras que se seleccionarán en cada paso.\n","\n","Se muestra a continuación un ejemplo:\n","\n","![Beam search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/beam_search.png)\n","\n","El texto mostrado en la imagen es el mismo que el mostrado en el caso anterior. Ahora, si definimos que ```num_beams = 2``` podemos ver como, tras la palabra <span style=\"color:red\">*The*</span>, se consideran dos caminos, los correspondientes a las palabras <span style=\"color:red\">*nice*</span> y <span style=\"color:red\">*dog*</span>, las cuales son las dos con mayor probabilidad.\n","\n","En este caso, considerar el camino de las palabras <span style=\"color:red\">*dog*</span> y <span style=\"color:red\">*has*</span> tendría una probabilidad de $0.4 \\times 0.9 = 0.34$, frente a la probabilidad de $0.2 del camino de las palabras <span style=\"color:red\">*nice*</span> y <span style=\"color:red\">*woman*</span>. Por tanto, se elige el primer camino al ser el que mayor probabilidad global tiene."]},{"cell_type":"markdown","metadata":{"id":"d8hauImgJZrN"},"source":["Visto el ejemplo teórico, se procede ahora a generar texto usando este método, definiendo el número de beams a 5 y estableciendo el parámetro ```early_stopping``` a ```True```, lo cual indica que el modelo dejará de generar texto cuando todos los beams hayan generado el token de final de secuencia (```<EOS>``` token)."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"KzEjMNsRJZrN","executionInfo":{"status":"ok","timestamp":1705490528363,"user_tz":-60,"elapsed":23429,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"636a4911-a8c5-4774-9b9d-0ee42c29d180"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The University of Alicante is a member of the European Union, the European Commission, the European Parliament, the European Commission, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament, the European Parliament'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["input_ids = tokenizer(inputText, return_tensors=\"pt\").input_ids\n","output = model.generate(input_ids, max_length=max_length, num_beams=5, early_stopping=True)\n","tokenizer.decode(output[0], skip_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"n2UdCqOWJZrN"},"source":["Podemos ver como en este caso el modelo se sigue repitiendo. Para intentar paliar esta sitación, se pueden utilizar métodos de penalización de repeticiones, como la penalización de n-gramas.\n","\n","Esa penalización, la cual se puede establecer mediante el parámetro ```no_repeat_ngram_size```, indica el tamaño del n-grama que no se puede repetir, asignando un valor de probabilidad de 0 a las palabras que formen parte de un n-grama repetido.\n","\n","Se prueba a continuación a generar texto usando este método, definiendo el parámetro ```no_repeat_ngram_size``` a 5."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"hVpTgI5JJZrN","executionInfo":{"status":"ok","timestamp":1705490551288,"user_tz":-60,"elapsed":22927,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"98232610-fe37-4730-c48f-5d1c7c35e1a4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The University of Alicante is a member of the European Union, the European Commission, the European Parliament, the European Council, the European Parliament of the United Kingdom, and the European Parliament. It is a member state of the European Economic Area (EEA) of the European Union.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}],"source":["input_ids = tokenizer(inputText, return_tensors=\"pt\").input_ids\n","output = model.generate(input_ids, max_length=max_length, num_beams=5, early_stopping=True, no_repeat_ngram_size=5)\n","tokenizer.decode(output[0], skip_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"UIMEo8vyJZrO"},"source":["Podemos ver como ahora mejora la respuesta que ofrece el modelo, no repitiéndose tanto como en el caso anterior.\n","\n","Otro parámetro que se puede configurar es el ```num_return_sequences```, el cual indica el número de secuencias que se devolverán como salida. En el caso anterior, se devolvía una única secuencia, pero se puede devolver más de una.\n","\n","Cabe destacar que siempre ```num_return_sequences``` deberá de ser menor o igual que ```num_beams```.\n","\n","Se prueba a continuación retornando 3 secuencias."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJsvSg46JZrO","executionInfo":{"status":"ok","timestamp":1705490574285,"user_tz":-60,"elapsed":22999,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"16cc4dc4-4718-4580-f3c9-e23626bcf828"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence 1: The University of Alicante is a member of the European Union, the European Commission, the European Parliament, the European Council, the European Parliament of the United Kingdom, and the European Parliament. It is a member state of the European Economic Area (EEA) of the European Union.\n","****************************************************************************************************\n","Sequence 2: The University of Alicante is a member of the European Union, the European Commission, the European Parliament, the European Council, the European Parliament of the United Kingdom, and the European Parliament. It is a member state of the European Economic Area (EEA), the European Economic Area of the European Union (EEA) and the EEA. It is also a member of the International Monetary Fund (IMF), the European Central Bank (ECB), the European Investment Bank (EIB) and the European Investment Bank for Reconstruction and Development (EIBRD). The University of Alicante was founded in 1974 and is one of the largest universities in the world.\n","\n","The University of Amsterdam is one of the oldest universities in the Netherlands. It is the only university in the Netherlands to be accredited by the European Commission. The University of Amsterdam is also one of the most prestigious universities in the Netherlands, with a total undergraduate enrollment of 1.5 million students. The university is also the only university\n","****************************************************************************************************\n","Sequence 3: The University of Alicante is a member of the European Union, the European Commission, the European Parliament, the European Council, the European Parliament of the United Kingdom, and the European Parliament. It is a member state of the European Economic Area (EEA), the European Economic Area of the European Union (EEA) and the EEA. It is also a member of the International Monetary Fund (IMF), the European Central Bank (ECB), the European Investment Bank (EIB) and the European Investment Bank for Reconstruction and Development (EIBRD). The University of Alicante was founded in 1974 and is one of the largest universities in the world.\n","\n","The University of Amsterdam is one of the oldest universities in the Netherlands. It is the only university in the Netherlands to be accredited by the European Commission. The University of Amsterdam is also one of the world's most prestigious universities.\n","\n","The university is one of the most prestigious universities in the Netherlands, with a total undergraduate enrollment\n","****************************************************************************************************\n"]}],"source":["input_ids = tokenizer(inputText, return_tensors=\"pt\").input_ids\n","output = model.generate(input_ids, max_length=max_length, num_beams=5, early_stopping=True, no_repeat_ngram_size=5, num_return_sequences=3)\n","\n","\n","for i, seqOutput in enumerate(output):\n","    print(f\"Sequence {i+1}: {tokenizer.decode(seqOutput, skip_special_tokens=True)}\")\n","    print('*'*100)"]},{"cell_type":"markdown","metadata":{"id":"50-ARxE_JZrO"},"source":["Como se puede observar, los textos que devuelven los diferentes ```beams``` son basante parecidos. Esto se debe a que, como se ha comentado anteriormente, se eligen las *k* palabras con mayor probabilidad, por lo que es normal que los caminos que se sigan sean parecidos.\n","\n","Continuamos probando con otros métodos de decodificación."]},{"cell_type":"markdown","metadata":{"id":"y8V6SXO7JZrO"},"source":["### Sampling"]},{"cell_type":"markdown","metadata":{"id":"laxnTzttJZrO"},"source":["El método de sampling (muestreo) consiste en elegir la siguiente palabra de forma aleatoria, teniendo en cuenta la distribución de probabilidad de las palabras.\n","\n","La distribución de probabilidad de las palabras se calcula usando la función softmax, la cual se define como:\n","\n","$$w_t \\sim P(w|w_{1:t-1})$$\n","\n","Donde $w_t$ es la palabra que se va a elegir en el paso $t$ y $P(w|w_{1:t-1})$ es la distribución de probabilidad de las palabras.\n","\n","Se muestra a continuación un ejemplo:\n","\n","![vanilla_sampling](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/sampling_search.png)\n","\n","En la imagen se puede observar la palabra de inicio, <span style=\"color:red\">*The*</span>, y las tres posibles palabras que se pueden elegir en el siguiente paso, <span style=\"color:red\">*nice*</span>, <span style=\"color:red\">*dog*</span> y <span style=\"color:red\">*car*</span>, con probabilidades 0.5, 0.4 y 0.1 respectivamente.\n","\n","En este caso, se eliga la palabra <span style=\"color:red\">*car*</span>, pero como se ha comentado anteriormente, la elección de la palabra se realiza de forma aleatoria, por lo que en otra ejecución podría haberse elegido otra palabra. Por tanto, este método se considera **no determinista**.\n","\n","Del mismo modo es elegida la siguiente palabra, <span style=\"color:red\">*drives*</span>."]},{"cell_type":"markdown","metadata":{"id":"O4Va5dJiJZrO"},"source":["Vista la teoría, se pasa a la práctica. Para usar el método de sampling, se define el parámetro ```do_sample``` a ```True```, desactivando el parámetro ```top_k``` (estableciéndolo a 0), el cual indica el número de palabras con mayor probabilidad que se considerarán en cada paso.\n","\n","Además, mediante el parámetro ```random_seed``` se puede establecer una semilla para que los resultados sean reproducibles."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"n3CPyzvEJZrO","executionInfo":{"status":"ok","timestamp":1705490585190,"user_tz":-60,"elapsed":10907,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"0cd86aec-2004-42c0-d813-f8c923af0290"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The University of Alicante is a public university interested in contributing tourism to its university. The center also offers high schools. The center offers national homunculus programmes and pre and post education. Designing a Modern Fort by Emile Guichon is at the University of Alicante. Extensive Kettling of Clances at Itamar Hinner is at Sungloan University. Foreign languages at seed universities Libraries and Schools Dolingṇhatra Saltamran, Chandmirindran, Raesagesiyahu, Bungo, Kafirsana, Maersnu Sekhara Centre Bay of Faculty Education Sexual Wetlands Sea-born Kinja PK-10 : Manganakvasamyaksonhatana Pinghiknder Campanungson Basics of Training Centre Medicine Volton Root Training Centre Research Promoting Forestry Dale Park in the University of Alicante Salimar Majkodan Gandana Valley Vegetation Shoulders, Beanstock Shimelangill Tin Na Cob O'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["torch.manual_seed(0)\n","\n","input_ids = tokenizer(inputText, return_tensors=\"pt\").input_ids\n","output = model.generate(input_ids, max_length=max_length, do_sample=True, top_k=0)\n","tokenizer.decode(output[0], skip_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"eey4onToJZrO"},"source":["En este caso, vemos como el texto producido no se repite. Ahora bien, conforme avanza la generación de texto, cada vez este tiene menos sentido.\n","\n","Para intentar paliar esta situación, se puede establecer un parámetro llamado ```temperature```, el cual indica la temperatura de la distribución de probabilidad de las palabras. El *truco* consiste en incrementar la posibilidad de elegir palabras con mayor probabilidad, así como reducir la posibilidad de elegir palabras con menor probabilidad, haciendo que la distrubución de probabilidad $P(w|w_{1:t-1})$ sea más fuerte.\n","\n","Esa temperatura se aplicará sobre la función softmax.\n","\n","Se muestra a continuación el ejemplo anterior, pero usando una temperatura de 0.7:\n","\n","![top_p_sampling](https://github.com/patrickvonplaten/scientific_images/blob/master/sampling_search_with_temp.png?raw=true)\n","\n","Ahora podemos ver como, en el primer caso, la palabra <span style=\"color:red\">*nice*</span>, la cual era la que tenía mayor probabilidad, ahora tiene aún mas probabilidad (pasa de 0.5 a 0.75). Por contra, la palabra <span style=\"color:red\">*car*</span>, la cual tenía una probabilidad de 0.1, ahora tiene una probabilidad de 0.02."]},{"cell_type":"markdown","metadata":{"id":"-WbiC2baJZrO"},"source":["Pasando a código, se prueba a generar texto usando este método, definiendo la temperatura a 0.7."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"GbiqSA61JZrO","executionInfo":{"status":"ok","timestamp":1705490595901,"user_tz":-60,"elapsed":10713,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"83d397ba-fd9e-4e12-a2df-8db2efac072c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The University of Alicante is a world renowned social research institute, providing a wide range of data to support the development of social research efforts.\\n\\nThe U.S. Department of State is a leading international research institute and an important player in the development of digital technologies.\\n\\nCzech Republic\\n\\nThe Czech Republic is an important partner in the region and contributes to the development of digital technologies.\\n\\nThe United States is another partner with the Czech Republic and is a key partner for the development of digital technologies.\\n\\nChina is a leading partner with the China National Science Foundation and is a key partner in the development of digital technologies.\\n\\nThe United Kingdom is a leading partner in the development of digital technologies and is a key partner for the development of digital technologies.\\n\\nMerkel is a key member of the European Union and is a key partner in the development of digital technologies.\\n\\nThe Netherlands is an important partner with the Dutch government and is a key partner in the'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}],"source":["torch.manual_seed(0)\n","\n","input_ids = tokenizer(inputText, return_tensors=\"pt\").input_ids\n","output = model.generate(input_ids, max_length=max_length, do_sample=True, top_k=0, temperature=0.7)\n","tokenizer.decode(output[0], skip_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"G3vmV74fJZrR"},"source":["Dada la salida, podemos ver como en este caso tampoco tenemos repeticions, si bien el texto generado contiene varias frases (vease los diferentes carácteres no imprimibles *\\n* que se generan), no teniendo mucha coherencia entre ellas.\n","\n","¿Y que pasaría si se establece una temperatura a prácticamente 0? Se prueba a continuación."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"-4UPMnyFJZrS","executionInfo":{"status":"ok","timestamp":1705490606608,"user_tz":-60,"elapsed":10709,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"48c4e7df-dd23-47d5-b373-f4a6bd043793"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The University of Alicante is a leading research university in the world. We are a leading research university in the world. We are a leading research university in the world.\\n\\nWe are a leading research university in the world. We are a leading research university in the world.\\n\\nWe are a leading research university in the world. We are a leading research university in the world.\\n\\nWe are a leading research university in the world. We are a leading research university in the world.\\n\\nWe are a leading research university in the world. We are a leading research university in the world.\\n\\nWe are a leading research university in the world. We are a leading research university in the world.\\n\\nWe are a leading research university in the world. We are a leading research university in the world.\\n\\nWe are a leading research university in the world. We are a leading research university in the world.\\n\\nWe are a leading research university in the world.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}],"source":["torch.manual_seed(0)\n","\n","input_ids = tokenizer(inputText, return_tensors=\"pt\").input_ids\n","output = model.generate(input_ids, max_length=max_length, do_sample=True, top_k=0, temperature=0.01)\n","tokenizer.decode(output[0], skip_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"kq5qZCTpJZrS"},"source":["Se ve como los problemas de repetición vuelven a aparecer, convirtiendose este método en similar al greedy search."]},{"cell_type":"markdown","metadata":{"id":"obi-sPXIJZrS"},"source":["### Top-K Sampling"]},{"cell_type":"markdown","metadata":{"id":"RW6eTVt3JZrS"},"source":["En el método de top-k sampling, se eligen las *k* palabras con mayor probabilidad.\n","\n","En la siguiente imagen se puede ver un ejemplo, en el que $K = 6$:\n","\n","![top_k_sampling](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/top_k_sampling.png)\n","\n","Se puede ver en la parte izquierda como se calcula la probabilidad para las posibles palabras que sucedan a *The*. En caso de elegir las 6 palabras con mayor probabilidad, el sumatorio de esa probabilida será de 0.68.\n","\n","Bastante más acusado es el segundo caso, cuando se tiene que decidir que palabra va después de *car*. En este caso, el sumatorio de las probabilidades de las 6 palabras con mayor probabilidad es de 0.99.\n","\n","Con este método se consiguen eliminar las palabras con menor probabilidad, las cuales suelen ser las que producen textos con menos sentido."]},{"cell_type":"markdown","metadata":{"id":"AYAhpIIBJZrS"},"source":["Viendo este método en código, se prueba a generar texto usando este método, definiendo el parámetro ```top_k``` a 50."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"YB6XhvbaJZrS","executionInfo":{"status":"ok","timestamp":1705490609727,"user_tz":-60,"elapsed":3122,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"a8182049-f19b-41de-9f51-678b4df7639d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The University of Alicante is a public university with an established campus, a high level of social responsibility, high achievement and a strong commitment to academic excellence.\\n\\nFaculty\\n\\nThe University of Alicante is a public university with an established campus, a high level of social responsibility, high achievement and a strong commitment to academic excellence.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["torch.manual_seed(0)\n","\n","input_ids = tokenizer(inputText, return_tensors=\"pt\").input_ids\n","output = model.generate(input_ids, max_length=max_length, do_sample=True, top_k=50)\n","tokenizer.decode(output[0], skip_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"MuUOZ6M1JZrS"},"source":["Podemos ver como el texto generado es bastante coherente. Por contra, podemos ver como al final el texto se repite.\n","\n","Vemos a continuación un método que surgió a partir de este."]},{"cell_type":"markdown","metadata":{"id":"I4UMuL1RJZrS"},"source":["### Top-p sampling"]},{"cell_type":"markdown","metadata":{"id":"uJtIgJ8QJZrS"},"source":["Como se veía en el caso anterior, el método de top-k sampling muestreaba solo las *k* palabras con mayor probabilidad.\n","\n","Por contra, ahora vemos el método de top-p sampling, el cual muestrea las palabras con mayor probabilidad hasta que la suma de las probabilidades de las palabras muestreadas sea mayor que un umbral dado.\n","\n","Veamos un ejemplo:\n","\n","![top_p_sampling](https://github.com/patrickvonplaten/scientific_images/blob/master/top_p_sampling.png?raw=true)\n","\n","Aquí, el umbral se establece a $p = 0.92$, por tanto, el método escogerá palabras hasta que la suma de sus probabilidad llegue a 0.92.\n","\n","Vemos que en el primer caso (el de la izquierda de la imagen), se eligen 9 palabras para poder alcanzar el umbral, mientras que en el segundo caso, eligiendo solo 3 se logra alcanzar el umbral.\n"]},{"cell_type":"markdown","metadata":{"id":"P6nktEGiJZrS"},"source":["Se prueba ahora con código a generar texto usando este método, definiendo el parámetro ```top_p``` a 0.92."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"yF9uHJ1TJZrS","executionInfo":{"status":"ok","timestamp":1705490621417,"user_tz":-60,"elapsed":11692,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"4ed6b848-0b64-49ee-f537-083dd97473db"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The University of Alicante is a public university with research and tourism interests as well as national foundations. No grants are received in this program. Funds are provided by Student Assistants Ltd. Cyprus Design and Design Dept. by the Faculty of Design and worked within the Policy and Management Department. Research addresses domains of study identified by ASC: public relations, research and communications technology, environmental transport, environment, energy, electronic media and risk awareness. In practice, mainly bilateral collaborations and traditional economic and social analyses are carried out. The number of questions asked is a reflection of the demand for research in ecommerce to be provided by ACIA and universities. The research methodology and ability to successfully integrate relevant research topics is critical. Some findings regarding ecommerce consumption are clearly stated. First, we found that ecommerce consumption at the high cost of other public universities suggests ecommerce in a economic/social and research context. Secondly, we found that per capita expenditures increase as the student body gains new opportunities to build capital in'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["torch.manual_seed(0)\n","\n","input_ids = tokenizer(inputText, return_tensors=\"pt\").input_ids\n","output = model.generate(input_ids, max_length=max_length, do_sample=True, top_k=0, top_p=0.92)\n","tokenizer.decode(output[0], skip_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"KV1dDYR5JZrS"},"source":["Vemos que ahora no se producen repeticiones, si bien como pasaba anteriormente, el texto va perdiendo sentido a medida que se va generando.\n","\n","¿Y si se combina este método Top-p con el método de Top-k? Se prueba a continuación. Así, se establece el parámetro ```top_k``` a 50 y el parámetro ```top_p``` a 0.92."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"9f4_vZwyJZrS","executionInfo":{"status":"ok","timestamp":1705490633219,"user_tz":-60,"elapsed":11805,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"2f35002c-4849-47b4-a5f9-8f9e9250642b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"The University of Alicante is a public university with an established campus, a high level of social responsibility, and a growing international presence. A proud member of the European Union and a member of the Organization of European Communities (OECD), Alicante is also a world leader in science, engineering, and mathematics.\\n\\nProfessor: It's not easy to imagine such a large-scale university with such an extensive base of alumni. Many of those who have gone on to earn their PhDs live here, while many in the other sectors have decided to relocate to the UK. What do you think this means for the UK?\\n\\nPete Wilschaft-Sebastien: Alicante has an alumni base that is large enough to meet demand and grow. But even with that the size of this university is not sufficient to meet demand in the academic workforce in general and the global workforce.\\n\\nProfessor: How did your university get to such an extent that it is attracting the most\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["torch.manual_seed(0)\n","\n","input_ids = tokenizer(inputText, return_tensors=\"pt\").input_ids\n","output = model.generate(input_ids, max_length=max_length, do_sample=True, top_k=50, top_p=0.92)\n","tokenizer.decode(output[0], skip_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"Y7A0OxxUJZrT"},"source":["Comparando este texto con el anterior, ahora podemos ver que tiene bastante más sentido que el anterior.\n","\n","Como vimos anteriormente, podemos generar varias secuencias de texto para probar diferentes caminos. Se prueba a continuación a generar 3 secuencias de texto."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d1c64UfJZrT","executionInfo":{"status":"ok","timestamp":1705490652557,"user_tz":-60,"elapsed":19340,"user":{"displayName":"Eduardo Grande","userId":"10166735779183621323"}},"outputId":"f9bb0e9d-a93c-4bba-d2cd-9e71a467135a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence 1: The University of Alicante is a public university with an established campus, a high level of social responsibility, and a growing international presence. A proud member of the European Union and a member of the Organization of European Communities (OECD), Alicante is also a world leader in science, engineering, and mathematics.\n","\n","Professor: It's not easy to imagine such a large-scale university with such an extensive base of alumni. Many of those who have gone on to earn their PhDs live here, while many in the other sectors have decided to relocate to the UK. What do you think this means for the UK?\n","\n","Pete Wilschaft-Sebastien: Alicante has an alumni base that is large enough to meet demand and grow. But even with that the size of this university is not sufficient to meet demand in the academic workforce in general and the global workforce.\n","\n","Professor: How did your university get to such an extent that it is attracting the most\n","****************************************************************************************************\n","Sequence 2: The University of Alicante is a team of astronomers who study the Earth's magnetosphere. In 2013, they led the way in finding a way to harness this energy, one that would lead to an unprecedented new view of the cosmos.\n","\n","One of the teams is the Netherlands-based team of researchers from the Netherlands Institute of Oceanography and Geophysics and the Institut de l'Oceanography (IMG). The research team focused on the location of the \"dark\" side of the magnetosphere, where it is located. This is one of several locations in the Earth's magnetic field that lie within the dark side of the magnetosphere. This dark side is also one of the regions of space called the \"Cirrus Belt\" that is the only area of space which has not been seen to have a black hole.\n","\n","In this work, the team discovered that the dark side of the magnetosphere is located deep within the Cirrus Belt. This dark side is extremely\n","****************************************************************************************************\n","Sequence 3: The University of Alicante is a very unique place for me to be. As such, it's perfect as a research space. The place is small and the staff are also knowledgeable about this field of science. As a study area, I want to be able to spend time with students from around the world who don't have access to any traditional academic activities. If you're looking for the best learning opportunity at UC Berkeley, you'll find it here.\n","\n","\n","I am now working in the lab for the summer and I'm eager to see how things evolve. The research I do on the other side of the world is really unique. It is not just because of the climate there, but also because it's not just about astronomy. I can also tell you about the way I work and this place is really exciting and fun. It's the same way that I learned calculus and physics when I was a student. My parents know the way to practice calculus in the lab because I use those techniques\n","****************************************************************************************************\n"]}],"source":["torch.manual_seed(0)\n","\n","input_ids = tokenizer(inputText, return_tensors=\"pt\").input_ids\n","output = model.generate(input_ids, max_length=max_length, do_sample=True, top_k=50, top_p=0.92, num_return_sequences=3)\n","\n","for i, seqOutput in enumerate(output):\n","    print(f\"Sequence {i+1}: {tokenizer.decode(seqOutput, skip_special_tokens=True)}\")\n","    print('*'*100)"]},{"cell_type":"markdown","metadata":{"id":"OseKdodzJZrT"},"source":["Vemos como las primeras frases que genera el modelo en cada una de las secuencias tienen bastante coherencia, perdiéndose esta en las sucecivas frases."]},{"cell_type":"markdown","metadata":{"id":"eP4PsEMdJZrT"},"source":["# Conclusiones"]},{"cell_type":"markdown","metadata":{"id":"Sp2EYgczJZrT"},"source":["A lo largo de este cuaderno se han visto diferentes formas de decodificar la salida de un modelo de generación de texto.\n","\n","Hemos visto principalmente dos problemas que tienen estos métodos, que son la repetición de texto y la pérdida de sentido del texto generado.\n","\n","Vistos todos ellos, podemos concluir que la combinación de los métodos de top-p sampling y top-k sampling es la que mejor resultados ofrece.\n","\n","Muchas investigaciones se están llevando a cabo para mejorar estos métodos y conseguir así que los textos generados sean más coherentes y tengan más sentido."]},{"cell_type":"markdown","metadata":{"id":"n29xnXS-JZrT"},"source":["¿Te ha gustado este cuaderno? Puedes ver en más detalle este problema en los siguientes *papers*:\n","\n","- [Learning to Break the Loop: Analyzing and Mitigating Repetitions for Neural Text Generation](https://arxiv.org/pdf/2206.02369.pdf)\n","- [NEURAL TEXT DEGENERATION WITH UNLIKELIHOOD TRAINING](https://arxiv.org/pdf/1908.04319.pdf)\n","- [Consistency of a Recurrent Language Model With Respect to Incomplete Decoding](https://arxiv.org/pdf/2002.02492.pdf)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f823da9f5efc454882b5405e52d79992":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e805c7eb1a184b93bfe2281f1a0bb39e","IPY_MODEL_f71d5d8bfb51435e910b502504d50981","IPY_MODEL_22e9ed0bf7954dae9731b4ef938b3f28"],"layout":"IPY_MODEL_8f28f93c63b64463abf7b6d98c8fb39e"}},"e805c7eb1a184b93bfe2281f1a0bb39e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6d91eb5f5964c5c87500dba26280364","placeholder":"​","style":"IPY_MODEL_f8206ae08c4a47219a5d7a8d8c65f06c","value":"vocab.json: 100%"}},"f71d5d8bfb51435e910b502504d50981":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_235de92e5e994b4082fb473fa30f8740","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52b210b3983c4e0fa2b62d13dc072e20","value":1042301}},"22e9ed0bf7954dae9731b4ef938b3f28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a63271b3f2484ac190ac520661954f3b","placeholder":"​","style":"IPY_MODEL_460f7e26f4424cbc9aeb537b1a3ff35d","value":" 1.04M/1.04M [00:00&lt;00:00, 7.80MB/s]"}},"8f28f93c63b64463abf7b6d98c8fb39e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6d91eb5f5964c5c87500dba26280364":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8206ae08c4a47219a5d7a8d8c65f06c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"235de92e5e994b4082fb473fa30f8740":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52b210b3983c4e0fa2b62d13dc072e20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a63271b3f2484ac190ac520661954f3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"460f7e26f4424cbc9aeb537b1a3ff35d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec57b836a0c5438f84b559a037b1e989":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c19628b4198d44889edb4af0e6f5b334","IPY_MODEL_580cac2617f04cde9954b8f754646a5c","IPY_MODEL_53e04aa6c3ed42bf814182ce38cd2019"],"layout":"IPY_MODEL_bef34984e3524d40bd764249efdedf3b"}},"c19628b4198d44889edb4af0e6f5b334":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a34413d63f5f487387d2bc557ec7f4c0","placeholder":"​","style":"IPY_MODEL_d0b1135dae714bdbb03ad66d44432ca2","value":"merges.txt: 100%"}},"580cac2617f04cde9954b8f754646a5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_550656ed4bf94b49909cd128b7d603fa","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0a4e74c7afd468487153c7c7e375bd5","value":456318}},"53e04aa6c3ed42bf814182ce38cd2019":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23d07e0400444edd9a64ae61cce9e169","placeholder":"​","style":"IPY_MODEL_5392766b662742aca59742c5dc8710d6","value":" 456k/456k [00:00&lt;00:00, 3.45MB/s]"}},"bef34984e3524d40bd764249efdedf3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a34413d63f5f487387d2bc557ec7f4c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0b1135dae714bdbb03ad66d44432ca2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"550656ed4bf94b49909cd128b7d603fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0a4e74c7afd468487153c7c7e375bd5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23d07e0400444edd9a64ae61cce9e169":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5392766b662742aca59742c5dc8710d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"579cacdb257c404db60fae8689959c21":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d238c2656f1c4b4ca3694dcfa8e93c12","IPY_MODEL_405c7e928fa24e1caf33bee018773ca1","IPY_MODEL_54885898c2464347abf761c711c371af"],"layout":"IPY_MODEL_94fe428f56904b67b9053d96b46e85cb"}},"d238c2656f1c4b4ca3694dcfa8e93c12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73554e0f655d47e6b67831f5ab4f8803","placeholder":"​","style":"IPY_MODEL_ef507f744f1c4fdba6ea73ae1df12d0c","value":"config.json: 100%"}},"405c7e928fa24e1caf33bee018773ca1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f13c57ec3f2748a3a2a48aa1c08d7384","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a84d3d7b032f4eb1a77d02f88e15cd80","value":665}},"54885898c2464347abf761c711c371af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b552649ee2543dcae050db9d9bfed59","placeholder":"​","style":"IPY_MODEL_c676850e489e4e8da63498f5d40d6685","value":" 665/665 [00:00&lt;00:00, 46.5kB/s]"}},"94fe428f56904b67b9053d96b46e85cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73554e0f655d47e6b67831f5ab4f8803":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef507f744f1c4fdba6ea73ae1df12d0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f13c57ec3f2748a3a2a48aa1c08d7384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a84d3d7b032f4eb1a77d02f88e15cd80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b552649ee2543dcae050db9d9bfed59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c676850e489e4e8da63498f5d40d6685":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"519c9d2d96744dd49af454a17b80d45d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_319f2fc174874958a0e1747e25c83b4f","IPY_MODEL_b75603bfd74b46678b1c109afbe857f7","IPY_MODEL_54d3c1dfb9d1456eba1ab18acd22d016"],"layout":"IPY_MODEL_69702990646d4e508f1d38f58f8ac773"}},"319f2fc174874958a0e1747e25c83b4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bc2f83af6754e19aff075619b535c14","placeholder":"​","style":"IPY_MODEL_60fffdf4171b474db6c3681ac99bcb1a","value":"model.safetensors: 100%"}},"b75603bfd74b46678b1c109afbe857f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3418dbbec57648759400988ba9eab39c","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1cd9aa0afa264226861ab928381d5bee","value":548105171}},"54d3c1dfb9d1456eba1ab18acd22d016":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f82958d7c10043c5af4a63fab8fe4ee0","placeholder":"​","style":"IPY_MODEL_418f0bec3e034c998357527b7bfe4936","value":" 548M/548M [00:06&lt;00:00, 63.1MB/s]"}},"69702990646d4e508f1d38f58f8ac773":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bc2f83af6754e19aff075619b535c14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60fffdf4171b474db6c3681ac99bcb1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3418dbbec57648759400988ba9eab39c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cd9aa0afa264226861ab928381d5bee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f82958d7c10043c5af4a63fab8fe4ee0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"418f0bec3e034c998357527b7bfe4936":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"879b239aa6ef46f1836a59c331510b97":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23e4d5018a874d4fbe63403f531437af","IPY_MODEL_0e87ff394f934eca90b5f0fec3dd9583","IPY_MODEL_2811af0856234946972765c516503f3d"],"layout":"IPY_MODEL_de08c5959f8941c7bb404e3ce6e12510"}},"23e4d5018a874d4fbe63403f531437af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4294e27bb7654a14ba1df57cd75f57f2","placeholder":"​","style":"IPY_MODEL_4a170a1e4848484e8fcb6583d5119890","value":"generation_config.json: 100%"}},"0e87ff394f934eca90b5f0fec3dd9583":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3a8cf3b08aa4e43bae57438bef119de","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb0ed0b82d9542b1bfb8655e4d69215c","value":124}},"2811af0856234946972765c516503f3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8708c9a1f8f0419d9da2d1b370a4019b","placeholder":"​","style":"IPY_MODEL_38fc59524ab04f97aa216eecf9955ccb","value":" 124/124 [00:00&lt;00:00, 2.23kB/s]"}},"de08c5959f8941c7bb404e3ce6e12510":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4294e27bb7654a14ba1df57cd75f57f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a170a1e4848484e8fcb6583d5119890":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3a8cf3b08aa4e43bae57438bef119de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb0ed0b82d9542b1bfb8655e4d69215c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8708c9a1f8f0419d9da2d1b370a4019b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38fc59524ab04f97aa216eecf9955ccb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}